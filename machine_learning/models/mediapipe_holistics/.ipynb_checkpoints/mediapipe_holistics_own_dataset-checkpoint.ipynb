{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741553511.508626 1361298 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741553511.596062 1361467 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.216.01), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1741553511.682196 1361402 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741553511.775364 1361404 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741553511.780178 1361404 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741553511.786350 1361418 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741553511.786372 1361405 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741553511.796239 1361421 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741553511.816052 1361394 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741553511.816399 1361408 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741553511.850545 1361412 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "  0%|                                                                                                                              | 1/8360 [00:07<18:28:21,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 50037_secretary_44.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                              | 2/8360 [00:20<24:45:11, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 00314_sleep_89.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                              | 3/8360 [00:27<20:48:56,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 08672_california_33_brightness.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                              | 4/8360 [00:36<21:07:27,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 03058_appointment_56_slow.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                              | 5/8360 [00:47<22:14:10,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 00128_from_68_flip.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                              | 6/8360 [00:56<22:24:15,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 22086_first_61_fast.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                              | 7/8360 [01:07<23:08:47,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 00149_have_72_noise.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                              | 8/8360 [01:20<24:59:56, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 40119_orange_88_slow.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                             | 9/8360 [01:31<25:29:14, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 38524_no_80_brightness.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                            | 10/8360 [01:41<24:36:47, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 00154_hesheit_65_flip.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                            | 11/8360 [01:49<23:12:12, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 00405_what_52.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                            | 12/8360 [02:02<25:12:47, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 10112_chat_93_flip.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                            | 13/8360 [02:12<24:36:07, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 00334_some_64_noise.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                            | 14/8360 [02:22<23:35:23, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 04898_banana_56_fast.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                            | 15/8360 [02:31<22:45:44,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 66532_son_59_flip.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                                                            | 16/8360 [02:42<23:52:24, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 65341_cheat_76_slow.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                            | 17/8360 [02:53<24:41:51, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 69302_drink_77.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                            | 18/8360 [03:03<23:58:40, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 13635_cousin_64.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                            | 19/8360 [03:10<21:24:44,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 13198_cool_31_fast.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                            | 20/8360 [03:18<20:27:16,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 60354_ugly_44_brightness.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                            | 21/8360 [03:24<18:51:20,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 41452_past_31_rotate.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                            | 22/8360 [03:32<18:51:26,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 48517_room_47.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                            | 23/8360 [03:41<19:02:54,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 51704_silly_49_flip.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                            | 24/8360 [03:51<20:40:48,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 00412_wish_70_blur.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                                            | 25/8360 [03:58<19:15:48,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 38124_new_33_slow.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                            | 26/8360 [04:05<18:24:45,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 56701_take_37_rotate.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                            | 27/8360 [04:14<18:58:54,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 51703_silly_54_slow.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                            | 28/8360 [04:27<22:07:24,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 00066_ask_91_rotate.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                            | 29/8360 [04:39<24:00:04, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 41449_past_86.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                            | 30/8360 [04:48<22:54:56,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 61978_vomit_53_blur.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                            | 31/8360 [04:54<20:27:30,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 23952_future_30_slow.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                            | 32/8360 [05:04<21:23:23,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 37086_move_68_flip.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                            | 33/8360 [05:17<23:23:10, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 14793_day_85_rotate.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                            | 34/8360 [05:24<21:40:27,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 32155_language_41_rotate.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                            | 35/8360 [05:32<20:44:14,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 38532_no_45_noise.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                            | 36/8360 [05:43<22:04:44,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 26976_hearing_77_brightness.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▌                                                                                                                            | 37/8360 [05:50<20:21:00,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved keypoints for 32163_language_37.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "# MediaPipe Holistic Model\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Directories\n",
    "PROCESSED_DIR = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/processed_npy\"\n",
    "KEYPOINTS_DIR = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/keypoints_npy\"\n",
    "os.makedirs(KEYPOINTS_DIR, exist_ok=True)\n",
    "\n",
    "# Load MediaPipe Holistic\n",
    "holistic = mp_holistic.Holistic(static_image_mode=False, model_complexity=2)\n",
    "\n",
    "# Function to extract keypoints from a frame\n",
    "def extract_keypoints(frame):\n",
    "    frame_rgb = cv2.cvtColor(frame.astype(np.uint8), cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(frame_rgb)\n",
    "    \n",
    "    keypoints = []\n",
    "    \n",
    "    # Face landmarks\n",
    "    if results.face_landmarks:\n",
    "        keypoints.extend([[p.x, p.y, p.z] for p in results.face_landmarks.landmark])\n",
    "    else:\n",
    "        keypoints.extend([[0, 0, 0]] * 468)\n",
    "    \n",
    "   # Pose landmarks \n",
    "    if results.pose_landmarks:\n",
    "        keypoints.extend([[p.x, p.y, p.z, p.visibility] for p in results.pose_landmarks.landmark])\n",
    "    else:\n",
    "        keypoints.extend([[0, 0, 0, 0]] * 33)\n",
    "\n",
    "    \n",
    "    # Hand landmarks (left & right)\n",
    "    for hand_landmarks in [results.left_hand_landmarks, results.right_hand_landmarks]:\n",
    "        if hand_landmarks:\n",
    "            keypoints.extend([[p.x, p.y, p.z] for p in hand_landmarks.landmark])\n",
    "        else:\n",
    "            keypoints.extend([[0, 0, 0]] * 21)\n",
    "    \n",
    "    return np.array(keypoints).flatten()\n",
    "\n",
    "# Process all .npy videos\n",
    "for npy_file in tqdm(os.listdir(PROCESSED_DIR)):\n",
    "    if not npy_file.endswith(\".npy\"):\n",
    "        continue\n",
    "    \n",
    "    video_path = os.path.join(PROCESSED_DIR, npy_file)\n",
    "    frames = np.load(video_path)\n",
    "    \n",
    "    keypoints_sequence = []\n",
    "    \n",
    "    for frame in frames:\n",
    "        frame = frame.transpose(1, 2, 0)  # Convert [C, H, W] -> [H, W, C]\n",
    "        keypoints = extract_keypoints(frame)\n",
    "        keypoints_sequence.append(keypoints)\n",
    "    \n",
    "    keypoints_sequence = np.array(keypoints_sequence)\n",
    "    \n",
    "    # Save keypoints\n",
    "    keypoints_path = os.path.join(KEYPOINTS_DIR, npy_file)\n",
    "    np.save(keypoints_path, keypoints_sequence)\n",
    "    print(f\"✅ Saved keypoints for {npy_file}\")\n",
    "\n",
    "print(\"🚀 Keypoints extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (asl_detection)",
   "language": "python",
   "name": "asl_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
