{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Verwende Ger√§t f√ºr Tensor-Speicherung: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741303805.278241 3238377 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1741303805.311250 3238633 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.216.01), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1741303805.400354 3238568 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741303805.447134 3238575 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741303805.450499 3238583 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741303805.457480 3238597 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741303805.457856 3238592 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741303805.473324 3238575 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741303805.478316 3238582 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741303805.480157 3238581 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1741303805.490333 3238571 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Keypoints gespeichert f√ºr 63208_white_37_speedup.npy.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 50037_secretary_44.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 05090_bar_81_flip.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 05233_basketball_71_contrast.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 13325_corn_81_slowdown.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 21172_fast_22_slowdown.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 66532_son_59_flip.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 69302_drink_77.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 13635_cousin_64.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 56838_tall_60_speedup.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 62965_what_74_speedup.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 04511_baby_53_speedup.npy.npy\n",
      "‚úÖ Keypoints gespeichert f√ºr 48517_room_47.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Directories\n",
    "processed_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_processed\"\n",
    "keypoints_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/keypoints_gpu\"\n",
    "os.makedirs(keypoints_folder, exist_ok=True)\n",
    "\n",
    "# Initialize CUDA device (for tensor storage only, MediaPipe remains on CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üîπ Using device for tensor storage: {device}\")\n",
    "\n",
    "# Initialize MediaPipe Holistic (runs ONLY on CPU!)\n",
    "mp_holistic = mp.solutions.holistic.Holistic(\n",
    "    static_image_mode=False, model_complexity=1, smooth_landmarks=True, enable_segmentation=False\n",
    ")\n",
    "\n",
    "# Function to extract keypoints (Pose + Hands)\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 3)\n",
    "    left_hand = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    right_hand = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "    \n",
    "    return np.concatenate([pose, left_hand, right_hand])  # Total: 99 keypoints per frame\n",
    "\n",
    "# Function to process a video (GPU for storage, CPU for MediaPipe)\n",
    "def process_video(video_path, save_path):\n",
    "    try:\n",
    "        frames = np.load(video_path).astype(np.uint8)  # Convert to uint8\n",
    "\n",
    "        keypoints_seq = []\n",
    "        for frame in frames:\n",
    "            frame_np = frame if isinstance(frame, np.ndarray) else frame.cpu().numpy()\n",
    "            if frame_np.shape[0] == 3 and frame_np.shape[-1] != 3:\n",
    "                frame_np = frame_np.transpose(1, 2, 0)  # [3, 224, 224] ‚Üí [224, 224, 3]\n",
    "\n",
    "            results = mp_holistic.process(frame_np)\n",
    "            keypoints = extract_keypoints(results)\n",
    "            keypoints_seq.append(keypoints)\n",
    "\n",
    "        np.save(save_path, np.array(keypoints_seq))\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {video_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Process all videos\n",
    "for video_file in os.listdir(processed_folder):\n",
    "    if not video_file.endswith(\".npy\"):\n",
    "        continue\n",
    "\n",
    "    video_path = os.path.join(processed_folder, video_file)\n",
    "    keypoint_path = os.path.join(keypoints_folder, video_file)\n",
    "\n",
    "    if os.path.exists(keypoint_path):\n",
    "        print(f\"‚è≠Ô∏è  Skipping {video_file} (already processed)\")\n",
    "        continue\n",
    "\n",
    "    success = process_video(video_path, keypoint_path)\n",
    "\n",
    "    if success:\n",
    "        print(f\"‚úÖ Keypoints saved for {video_file}\")\n",
    "\n",
    "print(\"üöÄ Keypoint extraction completed! (Processed only missing files)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (asl_detection)",
   "language": "python",
   "name": "asl_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
