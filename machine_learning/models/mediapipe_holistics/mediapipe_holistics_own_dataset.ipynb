{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# Directories\n",
    "processed_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/processed_npy\"\n",
    "keypoints_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/keypoints_gpu\"\n",
    "os.makedirs(keypoints_folder, exist_ok=True)\n",
    "\n",
    "# Initialize CUDA device (for tensor storage only, MediaPipe remains on CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üîπ Using device for tensor storage: {device}\")\n",
    "\n",
    "# Initialize MediaPipe Holistic (runs ONLY on CPU!)\n",
    "mp_holistic = mp.solutions.holistic.Holistic(\n",
    "    static_image_mode=False, model_complexity=1, smooth_landmarks=True, enable_segmentation=False\n",
    ")\n",
    "\n",
    "# Function to extract keypoints (Pose + Hands)\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33 * 3)\n",
    "    left_hand = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21 * 3)\n",
    "    right_hand = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21 * 3)\n",
    "    \n",
    "    return np.concatenate([pose, left_hand, right_hand])  # Total: 99 keypoints per frame\n",
    "\n",
    "# Function to process a video (GPU for storage, CPU for MediaPipe)\n",
    "def process_video(video_path, save_path):\n",
    "    try:\n",
    "        frames = np.load(video_path).astype(np.uint8)  # Convert to uint8\n",
    "\n",
    "        keypoints_seq = []\n",
    "        for frame in frames:\n",
    "            frame_np = frame if isinstance(frame, np.ndarray) else frame.cpu().numpy()\n",
    "            if frame_np.shape[0] == 3 and frame_np.shape[-1] != 3:\n",
    "                frame_np = frame_np.transpose(1, 2, 0)  # [3, 224, 224] ‚Üí [224, 224, 3]\n",
    "\n",
    "            results = mp_holistic.process(frame_np)\n",
    "            keypoints = extract_keypoints(results)\n",
    "            keypoints_seq.append(keypoints)\n",
    "\n",
    "        np.save(save_path, np.array(keypoints_seq))\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {video_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Process all videos\n",
    "for video_file in os.listdir(processed_folder):\n",
    "    if not video_file.endswith(\".npy\"):\n",
    "        continue\n",
    "\n",
    "    video_path = os.path.join(processed_folder, video_file)\n",
    "    keypoint_path = os.path.join(keypoints_folder, video_file)\n",
    "\n",
    "    if os.path.exists(keypoint_path):\n",
    "        print(f\"‚è≠Ô∏è  Skipping {video_file} (already processed)\")\n",
    "        continue\n",
    "\n",
    "    success = process_video(video_path, keypoint_path)\n",
    "\n",
    "    if success:\n",
    "        print(f\"‚úÖ Keypoints saved for {video_file}\")\n",
    "\n",
    "print(\"üöÄ Keypoint extraction completed! (Processed only missing files)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (asl_detection)",
   "language": "python",
   "name": "asl_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
