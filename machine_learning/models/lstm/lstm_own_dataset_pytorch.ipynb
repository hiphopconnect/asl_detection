{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 5.3592, Accuracy: 1.82%\n",
      "✅ Best model saved at epoch 1 with loss 5.3592\n",
      "Epoch [2/500], Loss: 5.0650, Accuracy: 3.66%\n",
      "✅ Best model saved at epoch 2 with loss 5.0650\n",
      "Epoch [3/500], Loss: 4.8988, Accuracy: 4.88%\n",
      "✅ Best model saved at epoch 3 with loss 4.8988\n",
      "Epoch [4/500], Loss: 4.7245, Accuracy: 6.34%\n",
      "✅ Best model saved at epoch 4 with loss 4.7245\n",
      "Epoch [5/500], Loss: 4.6128, Accuracy: 8.36%\n",
      "✅ Best model saved at epoch 5 with loss 4.6128\n",
      "Epoch [6/500], Loss: 4.5133, Accuracy: 9.72%\n",
      "✅ Best model saved at epoch 6 with loss 4.5133\n",
      "Epoch [7/500], Loss: 4.4213, Accuracy: 11.36%\n",
      "✅ Best model saved at epoch 7 with loss 4.4213\n",
      "Epoch [8/500], Loss: 4.3367, Accuracy: 13.01%\n",
      "✅ Best model saved at epoch 8 with loss 4.3367\n",
      "Epoch [9/500], Loss: 4.2610, Accuracy: 14.43%\n",
      "✅ Best model saved at epoch 9 with loss 4.2610\n",
      "Epoch [10/500], Loss: 4.1952, Accuracy: 15.86%\n",
      "✅ Best model saved at epoch 10 with loss 4.1952\n",
      "Epoch [11/500], Loss: 4.1380, Accuracy: 16.46%\n",
      "✅ Best model saved at epoch 11 with loss 4.1380\n",
      "Epoch [12/500], Loss: 4.0766, Accuracy: 17.80%\n",
      "✅ Best model saved at epoch 12 with loss 4.0766\n",
      "Epoch [13/500], Loss: 4.0191, Accuracy: 19.06%\n",
      "✅ Best model saved at epoch 13 with loss 4.0191\n",
      "Epoch [14/500], Loss: 3.9677, Accuracy: 20.36%\n",
      "✅ Best model saved at epoch 14 with loss 3.9677\n",
      "Epoch [15/500], Loss: 3.9197, Accuracy: 21.15%\n",
      "✅ Best model saved at epoch 15 with loss 3.9197\n",
      "Epoch [16/500], Loss: 3.8518, Accuracy: 23.01%\n",
      "✅ Best model saved at epoch 16 with loss 3.8518\n",
      "Epoch [17/500], Loss: 3.8065, Accuracy: 23.40%\n",
      "✅ Best model saved at epoch 17 with loss 3.8065\n",
      "Epoch [18/500], Loss: 3.7556, Accuracy: 25.02%\n",
      "✅ Best model saved at epoch 18 with loss 3.7556\n",
      "Epoch [19/500], Loss: 3.7119, Accuracy: 25.69%\n",
      "✅ Best model saved at epoch 19 with loss 3.7119\n",
      "Epoch [20/500], Loss: 3.6465, Accuracy: 27.17%\n",
      "✅ Best model saved at epoch 20 with loss 3.6465\n",
      "Epoch [21/500], Loss: 3.5942, Accuracy: 28.50%\n",
      "✅ Best model saved at epoch 21 with loss 3.5942\n",
      "Epoch [22/500], Loss: 3.5389, Accuracy: 29.44%\n",
      "✅ Best model saved at epoch 22 with loss 3.5389\n",
      "Epoch [23/500], Loss: 3.4729, Accuracy: 30.60%\n",
      "✅ Best model saved at epoch 23 with loss 3.4729\n",
      "Epoch [24/500], Loss: 3.3897, Accuracy: 32.54%\n",
      "✅ Best model saved at epoch 24 with loss 3.3897\n",
      "Epoch [25/500], Loss: 3.2607, Accuracy: 34.94%\n",
      "✅ Best model saved at epoch 25 with loss 3.2607\n",
      "Epoch [26/500], Loss: 3.1460, Accuracy: 38.30%\n",
      "✅ Best model saved at epoch 26 with loss 3.1460\n",
      "Epoch [27/500], Loss: 3.0742, Accuracy: 39.87%\n",
      "✅ Best model saved at epoch 27 with loss 3.0742\n",
      "Epoch [28/500], Loss: 2.9628, Accuracy: 41.89%\n",
      "✅ Best model saved at epoch 28 with loss 2.9628\n",
      "Epoch [29/500], Loss: 2.8518, Accuracy: 44.44%\n",
      "✅ Best model saved at epoch 29 with loss 2.8518\n",
      "Epoch [30/500], Loss: 2.7152, Accuracy: 48.09%\n",
      "✅ Best model saved at epoch 30 with loss 2.7152\n",
      "Epoch [31/500], Loss: 2.5741, Accuracy: 51.32%\n",
      "✅ Best model saved at epoch 31 with loss 2.5741\n",
      "Epoch [32/500], Loss: 2.4601, Accuracy: 54.83%\n",
      "✅ Best model saved at epoch 32 with loss 2.4601\n",
      "Epoch [33/500], Loss: 2.3329, Accuracy: 58.09%\n",
      "✅ Best model saved at epoch 33 with loss 2.3329\n",
      "Epoch [34/500], Loss: 2.1908, Accuracy: 62.50%\n",
      "✅ Best model saved at epoch 34 with loss 2.1908\n",
      "Epoch [35/500], Loss: 2.0727, Accuracy: 66.04%\n",
      "✅ Best model saved at epoch 35 with loss 2.0727\n",
      "Epoch [36/500], Loss: 2.0057, Accuracy: 68.27%\n",
      "✅ Best model saved at epoch 36 with loss 2.0057\n",
      "Epoch [37/500], Loss: 1.8823, Accuracy: 72.40%\n",
      "✅ Best model saved at epoch 37 with loss 1.8823\n",
      "Epoch [38/500], Loss: 1.7973, Accuracy: 75.33%\n",
      "✅ Best model saved at epoch 38 with loss 1.7973\n",
      "Epoch [39/500], Loss: 1.7042, Accuracy: 77.95%\n",
      "✅ Best model saved at epoch 39 with loss 1.7042\n",
      "Epoch [40/500], Loss: 1.6492, Accuracy: 79.83%\n",
      "✅ Best model saved at epoch 40 with loss 1.6492\n",
      "Epoch [41/500], Loss: 1.5855, Accuracy: 82.22%\n",
      "✅ Best model saved at epoch 41 with loss 1.5855\n",
      "Epoch [42/500], Loss: 1.5242, Accuracy: 84.09%\n",
      "✅ Best model saved at epoch 42 with loss 1.5242\n",
      "Epoch [43/500], Loss: 1.4608, Accuracy: 86.56%\n",
      "✅ Best model saved at epoch 43 with loss 1.4608\n",
      "Epoch [44/500], Loss: 1.4153, Accuracy: 88.10%\n",
      "✅ Best model saved at epoch 44 with loss 1.4153\n",
      "Epoch [45/500], Loss: 1.3988, Accuracy: 88.54%\n",
      "✅ Best model saved at epoch 45 with loss 1.3988\n",
      "Epoch [46/500], Loss: 1.3765, Accuracy: 89.29%\n",
      "✅ Best model saved at epoch 46 with loss 1.3765\n",
      "Epoch [47/500], Loss: 1.3119, Accuracy: 91.88%\n",
      "✅ Best model saved at epoch 47 with loss 1.3119\n",
      "Epoch [48/500], Loss: 1.3325, Accuracy: 90.43%\n",
      "Epoch [49/500], Loss: 1.2848, Accuracy: 92.11%\n",
      "✅ Best model saved at epoch 49 with loss 1.2848\n",
      "Epoch [50/500], Loss: 1.2611, Accuracy: 92.81%\n",
      "✅ Best model saved at epoch 50 with loss 1.2611\n",
      "Epoch [51/500], Loss: 1.2337, Accuracy: 93.46%\n",
      "✅ Best model saved at epoch 51 with loss 1.2337\n",
      "Epoch [52/500], Loss: 1.2254, Accuracy: 93.95%\n",
      "✅ Best model saved at epoch 52 with loss 1.2254\n",
      "Epoch [53/500], Loss: 1.2099, Accuracy: 94.07%\n",
      "✅ Best model saved at epoch 53 with loss 1.2099\n",
      "Epoch [54/500], Loss: 1.2019, Accuracy: 94.47%\n",
      "✅ Best model saved at epoch 54 with loss 1.2019\n",
      "Epoch [55/500], Loss: 1.1963, Accuracy: 94.32%\n",
      "✅ Best model saved at epoch 55 with loss 1.1963\n",
      "Epoch [56/500], Loss: 1.1805, Accuracy: 94.76%\n",
      "✅ Best model saved at epoch 56 with loss 1.1805\n",
      "Epoch [57/500], Loss: 1.1777, Accuracy: 94.76%\n",
      "✅ Best model saved at epoch 57 with loss 1.1777\n",
      "Epoch [58/500], Loss: 1.1720, Accuracy: 94.76%\n",
      "✅ Best model saved at epoch 58 with loss 1.1720\n",
      "Epoch [59/500], Loss: 1.1345, Accuracy: 95.90%\n",
      "✅ Best model saved at epoch 59 with loss 1.1345\n",
      "Epoch [60/500], Loss: 1.1576, Accuracy: 95.07%\n",
      "Epoch [61/500], Loss: 1.1644, Accuracy: 94.96%\n",
      "Epoch [62/500], Loss: 1.1604, Accuracy: 95.18%\n",
      "Epoch [63/500], Loss: 1.1282, Accuracy: 95.84%\n",
      "✅ Best model saved at epoch 63 with loss 1.1282\n",
      "Epoch [64/500], Loss: 1.1115, Accuracy: 96.27%\n",
      "✅ Best model saved at epoch 64 with loss 1.1115\n",
      "Epoch [65/500], Loss: 1.0729, Accuracy: 97.39%\n",
      "✅ Best model saved at epoch 65 with loss 1.0729\n",
      "Epoch [66/500], Loss: 1.1261, Accuracy: 95.80%\n",
      "Epoch [67/500], Loss: 1.1141, Accuracy: 96.30%\n",
      "Epoch [68/500], Loss: 1.0745, Accuracy: 96.95%\n",
      "Epoch [69/500], Loss: 1.1352, Accuracy: 94.98%\n",
      "Epoch [70/500], Loss: 1.0331, Accuracy: 98.13%\n",
      "✅ Best model saved at epoch 70 with loss 1.0331\n",
      "Epoch [71/500], Loss: 1.0025, Accuracy: 98.56%\n",
      "✅ Best model saved at epoch 71 with loss 1.0025\n",
      "Epoch [72/500], Loss: 0.9930, Accuracy: 98.73%\n",
      "✅ Best model saved at epoch 72 with loss 0.9930\n",
      "Epoch [73/500], Loss: 0.9933, Accuracy: 98.68%\n",
      "Epoch [74/500], Loss: 0.9884, Accuracy: 98.72%\n",
      "✅ Best model saved at epoch 74 with loss 0.9884\n",
      "Epoch [75/500], Loss: 0.9844, Accuracy: 98.78%\n",
      "✅ Best model saved at epoch 75 with loss 0.9844\n",
      "Epoch [76/500], Loss: 0.9820, Accuracy: 98.67%\n",
      "✅ Best model saved at epoch 76 with loss 0.9820\n",
      "Epoch [77/500], Loss: 0.9866, Accuracy: 98.59%\n",
      "Epoch [78/500], Loss: 0.9965, Accuracy: 98.31%\n",
      "Epoch [79/500], Loss: 0.9944, Accuracy: 98.33%\n",
      "Epoch [80/500], Loss: 0.9895, Accuracy: 98.66%\n",
      "Epoch [81/500], Loss: 0.9745, Accuracy: 98.80%\n",
      "✅ Best model saved at epoch 81 with loss 0.9745\n",
      "Epoch [82/500], Loss: 0.9648, Accuracy: 98.94%\n",
      "✅ Best model saved at epoch 82 with loss 0.9648\n",
      "Epoch [83/500], Loss: 0.9627, Accuracy: 98.85%\n",
      "✅ Best model saved at epoch 83 with loss 0.9627\n",
      "Epoch [84/500], Loss: 0.9620, Accuracy: 98.80%\n",
      "✅ Best model saved at epoch 84 with loss 0.9620\n",
      "Epoch [85/500], Loss: 0.9608, Accuracy: 98.74%\n",
      "✅ Best model saved at epoch 85 with loss 0.9608\n",
      "Epoch [86/500], Loss: 0.9588, Accuracy: 98.79%\n",
      "✅ Best model saved at epoch 86 with loss 0.9588\n",
      "Epoch [87/500], Loss: 0.9616, Accuracy: 98.61%\n",
      "Epoch [88/500], Loss: 0.9577, Accuracy: 98.85%\n",
      "✅ Best model saved at epoch 88 with loss 0.9577\n",
      "Epoch [89/500], Loss: 0.9583, Accuracy: 98.80%\n",
      "Epoch [90/500], Loss: 0.9584, Accuracy: 98.67%\n",
      "Epoch [91/500], Loss: 0.9568, Accuracy: 98.91%\n",
      "✅ Best model saved at epoch 91 with loss 0.9568\n",
      "Epoch [92/500], Loss: 0.9547, Accuracy: 98.79%\n",
      "✅ Best model saved at epoch 92 with loss 0.9547\n",
      "Epoch [93/500], Loss: 0.9554, Accuracy: 98.71%\n",
      "Epoch [94/500], Loss: 0.9549, Accuracy: 98.80%\n",
      "Epoch [95/500], Loss: 0.9529, Accuracy: 98.74%\n",
      "✅ Best model saved at epoch 95 with loss 0.9529\n",
      "Epoch [96/500], Loss: 0.9520, Accuracy: 98.82%\n",
      "✅ Best model saved at epoch 96 with loss 0.9520\n",
      "Epoch [97/500], Loss: 0.9544, Accuracy: 98.78%\n",
      "Epoch [98/500], Loss: 0.9531, Accuracy: 98.79%\n",
      "Epoch [99/500], Loss: 0.9506, Accuracy: 98.85%\n",
      "✅ Best model saved at epoch 99 with loss 0.9506\n",
      "Epoch [100/500], Loss: 0.9543, Accuracy: 98.66%\n",
      "Epoch [101/500], Loss: 0.9488, Accuracy: 98.78%\n",
      "✅ Best model saved at epoch 101 with loss 0.9488\n",
      "Epoch [102/500], Loss: 0.9475, Accuracy: 98.83%\n",
      "✅ Best model saved at epoch 102 with loss 0.9475\n",
      "Epoch [103/500], Loss: 0.9480, Accuracy: 98.76%\n",
      "Epoch [104/500], Loss: 0.9492, Accuracy: 98.74%\n",
      "Epoch [105/500], Loss: 0.9471, Accuracy: 98.73%\n",
      "✅ Best model saved at epoch 105 with loss 0.9471\n",
      "Epoch [106/500], Loss: 0.9487, Accuracy: 98.79%\n",
      "Epoch [107/500], Loss: 0.9439, Accuracy: 98.82%\n",
      "✅ Best model saved at epoch 107 with loss 0.9439\n",
      "Epoch [108/500], Loss: 0.9436, Accuracy: 98.82%\n",
      "✅ Best model saved at epoch 108 with loss 0.9436\n",
      "Epoch [109/500], Loss: 0.9473, Accuracy: 98.76%\n",
      "Epoch [110/500], Loss: 0.9416, Accuracy: 98.83%\n",
      "✅ Best model saved at epoch 110 with loss 0.9416\n",
      "Epoch [111/500], Loss: 0.9443, Accuracy: 98.79%\n",
      "Epoch [112/500], Loss: 0.9386, Accuracy: 98.92%\n",
      "✅ Best model saved at epoch 112 with loss 0.9386\n",
      "Epoch [113/500], Loss: 0.9430, Accuracy: 98.84%\n",
      "Epoch [114/500], Loss: 0.9391, Accuracy: 98.86%\n",
      "Epoch [115/500], Loss: 0.9431, Accuracy: 98.78%\n",
      "Epoch [116/500], Loss: 0.9397, Accuracy: 98.84%\n",
      "Epoch [117/500], Loss: 0.9345, Accuracy: 98.85%\n",
      "✅ Best model saved at epoch 117 with loss 0.9345\n",
      "Epoch [118/500], Loss: 0.9329, Accuracy: 98.88%\n",
      "✅ Best model saved at epoch 118 with loss 0.9329\n",
      "Epoch [119/500], Loss: 0.9324, Accuracy: 98.86%\n",
      "✅ Best model saved at epoch 119 with loss 0.9324\n",
      "Epoch [120/500], Loss: 0.9306, Accuracy: 98.96%\n",
      "✅ Best model saved at epoch 120 with loss 0.9306\n",
      "Epoch [121/500], Loss: 0.9314, Accuracy: 98.92%\n",
      "Epoch [122/500], Loss: 0.9296, Accuracy: 98.97%\n",
      "✅ Best model saved at epoch 122 with loss 0.9296\n",
      "Epoch [123/500], Loss: 0.9309, Accuracy: 98.95%\n",
      "Epoch [124/500], Loss: 0.9308, Accuracy: 98.89%\n",
      "Epoch [125/500], Loss: 0.9299, Accuracy: 98.90%\n",
      "Epoch [126/500], Loss: 0.9312, Accuracy: 98.84%\n",
      "Epoch [127/500], Loss: 0.9275, Accuracy: 98.88%\n",
      "✅ Best model saved at epoch 127 with loss 0.9275\n",
      "Epoch [128/500], Loss: 0.9269, Accuracy: 99.00%\n",
      "✅ Best model saved at epoch 128 with loss 0.9269\n",
      "Epoch [129/500], Loss: 0.9266, Accuracy: 99.07%\n",
      "✅ Best model saved at epoch 129 with loss 0.9266\n",
      "Epoch [130/500], Loss: 0.9272, Accuracy: 98.92%\n",
      "Epoch [131/500], Loss: 0.9271, Accuracy: 98.91%\n",
      "Epoch [132/500], Loss: 0.9267, Accuracy: 98.86%\n",
      "Epoch [133/500], Loss: 0.9272, Accuracy: 98.86%\n",
      "Epoch [134/500], Loss: 0.9254, Accuracy: 98.94%\n",
      "✅ Best model saved at epoch 134 with loss 0.9254\n",
      "Epoch [135/500], Loss: 0.9248, Accuracy: 99.02%\n",
      "✅ Best model saved at epoch 135 with loss 0.9248\n",
      "Epoch [136/500], Loss: 0.9242, Accuracy: 99.01%\n",
      "✅ Best model saved at epoch 136 with loss 0.9242\n",
      "Epoch [137/500], Loss: 0.9250, Accuracy: 98.95%\n",
      "Epoch [138/500], Loss: 0.9239, Accuracy: 99.07%\n",
      "✅ Best model saved at epoch 138 with loss 0.9239\n",
      "Epoch [139/500], Loss: 0.9242, Accuracy: 99.01%\n",
      "Epoch [140/500], Loss: 0.9249, Accuracy: 98.94%\n",
      "Epoch [141/500], Loss: 0.9244, Accuracy: 98.98%\n",
      "Epoch [142/500], Loss: 0.9239, Accuracy: 99.00%\n",
      "✅ Best model saved at epoch 142 with loss 0.9239\n",
      "Epoch [143/500], Loss: 0.9231, Accuracy: 99.06%\n",
      "✅ Best model saved at epoch 143 with loss 0.9231\n",
      "Epoch [144/500], Loss: 0.9232, Accuracy: 98.95%\n",
      "Epoch [145/500], Loss: 0.9225, Accuracy: 99.06%\n",
      "✅ Best model saved at epoch 145 with loss 0.9225\n",
      "Epoch [146/500], Loss: 0.9218, Accuracy: 99.13%\n",
      "✅ Best model saved at epoch 146 with loss 0.9218\n",
      "Epoch [147/500], Loss: 0.9235, Accuracy: 98.92%\n",
      "Epoch [148/500], Loss: 0.9236, Accuracy: 98.95%\n",
      "Epoch [149/500], Loss: 0.9225, Accuracy: 99.00%\n",
      "Epoch [150/500], Loss: 0.9223, Accuracy: 99.01%\n",
      "Epoch [151/500], Loss: 0.9234, Accuracy: 98.97%\n",
      "Early stopping triggered.\n",
      "Training completed! Best model saved at: /home/haggenmueller/asl_detection/machine_learning/models/lstm/best_lstm_model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Paths\n",
    "LABELS_PATH = \"/home/haggenmueller/asl_detection/machine_learning/models/lstm/label_to_index.json\"\n",
    "DATA_DIR = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/keypoints\"\n",
    "MODEL_PATH = \"/home/haggenmueller/asl_detection/machine_learning/models/lstm/best_lstm_model.pth\"\n",
    "\n",
    "# Parameters\n",
    "SEQUENCE_LENGTH = 102  # Number of frames per sequence\n",
    "INPUT_SIZE = 225  # Adjusted to include face keypoints\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "LR = 0.0001\n",
    "PATIENCE = 5  # Early stopping patience\n",
    "\n",
    "# Load labels\n",
    "with open(LABELS_PATH, \"r\") as f:\n",
    "    label_to_index = json.load(f)\n",
    "    index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "    NUM_CLASSES = len(label_to_index)\n",
    "\n",
    "# Dataset class\n",
    "class ASLDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels_map, sequence_length):\n",
    "        self.data_dir = data_dir\n",
    "        self.sequence_length = sequence_length\n",
    "        self.samples = []\n",
    "        \n",
    "        for file in os.listdir(data_dir):\n",
    "            if file.endswith(\".npy\"):\n",
    "                filename_parts = file.split(\"_\")\n",
    "                label_name = filename_parts[1]  # Extract label from filename structure\n",
    "                if label_name in labels_map:\n",
    "                    self.samples.append((os.path.join(data_dir, file), labels_map[label_name]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        keypoints = np.load(file_path)\n",
    "        \n",
    "        # Ensure all sequences are of the same length\n",
    "        if keypoints.shape[0] < self.sequence_length:\n",
    "            pad = np.zeros((self.sequence_length - keypoints.shape[0], keypoints.shape[1]))\n",
    "            keypoints = np.vstack((keypoints, pad))\n",
    "        else:\n",
    "            keypoints = keypoints[:self.sequence_length]\n",
    "        \n",
    "        return torch.tensor(keypoints, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "# LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)  # Batch Normalization\n",
    "        self.dropout = nn.Dropout(0.3)  # Dropout to prevent overfitting\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.batch_norm(out[:, -1, :])  # Apply Batch Normalization\n",
    "        out = self.dropout(out)  # Apply Dropout\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Load data\n",
    "dataset = ASLDataset(DATA_DIR, label_to_index, SEQUENCE_LENGTH)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMModel(input_size=INPUT_SIZE, hidden_size=512, num_layers=3, num_classes=NUM_CLASSES)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Apply Xavier Initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# Early stopping\n",
    "best_loss = float(\"inf\")\n",
    "stopping_counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for keypoints, labels in dataloader:\n",
    "        keypoints, labels = keypoints.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(keypoints)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100 * correct / float(total)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Adjust learning rate\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Save best model if it improves\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        stopping_counter = 0\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"✅ Best model saved at epoch {epoch+1} with loss {avg_loss:.4f}\")\n",
    "    else:\n",
    "        stopping_counter += 1\n",
    "        if stopping_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Training completed! Best model saved at:\", MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: sick\n",
      "Predicted Label: sick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2894548/3936693878.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))\n"
     ]
    }
   ],
   "source": [
    "# Testing cell\n",
    "def test_model():\n",
    "    \"\"\"Load the trained model and test on a random sample from the dataset.\"\"\"\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.eval()\n",
    "    \n",
    "    sample, label = dataset[0]\n",
    "    sample = sample.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(sample)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    print(f\"Actual Label: {index_to_label[label.item()]}\")\n",
    "    print(f\"Predicted Label: {index_to_label[predicted_class]}\")\n",
    "\n",
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
