{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 5.2043, Accuracy: 0.93%\n",
      "✅ Best model saved at epoch 1 with loss 5.2043\n",
      "Epoch [2/500], Loss: 5.0715, Accuracy: 1.15%\n",
      "✅ Best model saved at epoch 2 with loss 5.0715\n",
      "Epoch [3/500], Loss: 4.9832, Accuracy: 1.21%\n",
      "✅ Best model saved at epoch 3 with loss 4.9832\n",
      "Epoch [4/500], Loss: 4.9157, Accuracy: 1.78%\n",
      "✅ Best model saved at epoch 4 with loss 4.9157\n",
      "Epoch [5/500], Loss: 4.9164, Accuracy: 1.71%\n",
      "Epoch [6/500], Loss: 4.8909, Accuracy: 1.65%\n",
      "✅ Best model saved at epoch 6 with loss 4.8909\n",
      "Epoch [7/500], Loss: 4.7905, Accuracy: 1.87%\n",
      "✅ Best model saved at epoch 7 with loss 4.7905\n",
      "Epoch [8/500], Loss: 4.7034, Accuracy: 2.69%\n",
      "✅ Best model saved at epoch 8 with loss 4.7034\n",
      "Epoch [9/500], Loss: 4.6477, Accuracy: 2.98%\n",
      "✅ Best model saved at epoch 9 with loss 4.6477\n",
      "Epoch [10/500], Loss: 4.9025, Accuracy: 1.95%\n",
      "Epoch [11/500], Loss: 4.6362, Accuracy: 2.94%\n",
      "✅ Best model saved at epoch 11 with loss 4.6362\n",
      "Epoch [12/500], Loss: 4.5678, Accuracy: 3.44%\n",
      "✅ Best model saved at epoch 12 with loss 4.5678\n",
      "Epoch [13/500], Loss: 4.5195, Accuracy: 4.03%\n",
      "✅ Best model saved at epoch 13 with loss 4.5195\n",
      "Epoch [14/500], Loss: 4.4609, Accuracy: 4.55%\n",
      "✅ Best model saved at epoch 14 with loss 4.4609\n",
      "Epoch [15/500], Loss: 4.4010, Accuracy: 4.92%\n",
      "✅ Best model saved at epoch 15 with loss 4.4010\n",
      "Epoch [16/500], Loss: 4.3450, Accuracy: 5.75%\n",
      "✅ Best model saved at epoch 16 with loss 4.3450\n",
      "Epoch [17/500], Loss: 4.2692, Accuracy: 6.64%\n",
      "✅ Best model saved at epoch 17 with loss 4.2692\n",
      "Epoch [18/500], Loss: 4.2414, Accuracy: 6.73%\n",
      "✅ Best model saved at epoch 18 with loss 4.2414\n",
      "Epoch [19/500], Loss: 4.1970, Accuracy: 7.57%\n",
      "✅ Best model saved at epoch 19 with loss 4.1970\n",
      "Epoch [20/500], Loss: 4.1662, Accuracy: 8.35%\n",
      "✅ Best model saved at epoch 20 with loss 4.1662\n",
      "Epoch [21/500], Loss: 4.0462, Accuracy: 9.56%\n",
      "✅ Best model saved at epoch 21 with loss 4.0462\n",
      "Epoch [22/500], Loss: 3.9612, Accuracy: 11.14%\n",
      "✅ Best model saved at epoch 22 with loss 3.9612\n",
      "Epoch [23/500], Loss: 3.8978, Accuracy: 12.61%\n",
      "✅ Best model saved at epoch 23 with loss 3.8978\n",
      "Epoch [24/500], Loss: 3.8660, Accuracy: 12.32%\n",
      "✅ Best model saved at epoch 24 with loss 3.8660\n",
      "Epoch [25/500], Loss: 3.7621, Accuracy: 14.71%\n",
      "✅ Best model saved at epoch 25 with loss 3.7621\n",
      "Epoch [26/500], Loss: 3.6883, Accuracy: 15.97%\n",
      "✅ Best model saved at epoch 26 with loss 3.6883\n",
      "Epoch [27/500], Loss: 3.6137, Accuracy: 18.34%\n",
      "✅ Best model saved at epoch 27 with loss 3.6137\n",
      "Epoch [28/500], Loss: 3.5605, Accuracy: 19.94%\n",
      "✅ Best model saved at epoch 28 with loss 3.5605\n",
      "Epoch [29/500], Loss: 3.4714, Accuracy: 21.70%\n",
      "✅ Best model saved at epoch 29 with loss 3.4714\n",
      "Epoch [30/500], Loss: 3.4125, Accuracy: 23.11%\n",
      "✅ Best model saved at epoch 30 with loss 3.4125\n",
      "Epoch [31/500], Loss: 3.3212, Accuracy: 26.05%\n",
      "✅ Best model saved at epoch 31 with loss 3.3212\n",
      "Epoch [32/500], Loss: 3.2408, Accuracy: 28.31%\n",
      "✅ Best model saved at epoch 32 with loss 3.2408\n",
      "Epoch [33/500], Loss: 3.1711, Accuracy: 29.88%\n",
      "✅ Best model saved at epoch 33 with loss 3.1711\n",
      "Epoch [34/500], Loss: 3.1117, Accuracy: 31.22%\n",
      "✅ Best model saved at epoch 34 with loss 3.1117\n",
      "Epoch [35/500], Loss: 3.0223, Accuracy: 34.13%\n",
      "✅ Best model saved at epoch 35 with loss 3.0223\n",
      "Epoch [36/500], Loss: 2.9640, Accuracy: 34.98%\n",
      "✅ Best model saved at epoch 36 with loss 2.9640\n",
      "Epoch [37/500], Loss: 2.8763, Accuracy: 38.04%\n",
      "✅ Best model saved at epoch 37 with loss 2.8763\n",
      "Epoch [38/500], Loss: 2.8655, Accuracy: 37.89%\n",
      "✅ Best model saved at epoch 38 with loss 2.8655\n",
      "Epoch [39/500], Loss: 2.7746, Accuracy: 41.29%\n",
      "✅ Best model saved at epoch 39 with loss 2.7746\n",
      "Epoch [40/500], Loss: 2.7096, Accuracy: 43.09%\n",
      "✅ Best model saved at epoch 40 with loss 2.7096\n",
      "Epoch [41/500], Loss: 2.6291, Accuracy: 45.74%\n",
      "✅ Best model saved at epoch 41 with loss 2.6291\n",
      "Epoch [42/500], Loss: 2.5662, Accuracy: 47.31%\n",
      "✅ Best model saved at epoch 42 with loss 2.5662\n",
      "Epoch [43/500], Loss: 2.5196, Accuracy: 49.99%\n",
      "✅ Best model saved at epoch 43 with loss 2.5196\n",
      "Epoch [44/500], Loss: 2.4425, Accuracy: 52.55%\n",
      "✅ Best model saved at epoch 44 with loss 2.4425\n",
      "Epoch [45/500], Loss: 2.3888, Accuracy: 53.84%\n",
      "✅ Best model saved at epoch 45 with loss 2.3888\n",
      "Epoch [46/500], Loss: 2.3554, Accuracy: 54.93%\n",
      "✅ Best model saved at epoch 46 with loss 2.3554\n",
      "Epoch [47/500], Loss: 2.2807, Accuracy: 57.24%\n",
      "✅ Best model saved at epoch 47 with loss 2.2807\n",
      "Epoch [48/500], Loss: 2.2754, Accuracy: 57.54%\n",
      "✅ Best model saved at epoch 48 with loss 2.2754\n",
      "Epoch [49/500], Loss: 2.1703, Accuracy: 60.90%\n",
      "✅ Best model saved at epoch 49 with loss 2.1703\n",
      "Epoch [50/500], Loss: 2.1199, Accuracy: 62.75%\n",
      "✅ Best model saved at epoch 50 with loss 2.1199\n",
      "Epoch [51/500], Loss: 2.0968, Accuracy: 63.88%\n",
      "✅ Best model saved at epoch 51 with loss 2.0968\n",
      "Epoch [52/500], Loss: 2.0642, Accuracy: 64.34%\n",
      "✅ Best model saved at epoch 52 with loss 2.0642\n",
      "Epoch [53/500], Loss: 1.9838, Accuracy: 66.66%\n",
      "✅ Best model saved at epoch 53 with loss 1.9838\n",
      "Epoch [54/500], Loss: 1.9530, Accuracy: 68.68%\n",
      "✅ Best model saved at epoch 54 with loss 1.9530\n",
      "Epoch [55/500], Loss: 1.9024, Accuracy: 70.31%\n",
      "✅ Best model saved at epoch 55 with loss 1.9024\n",
      "Epoch [56/500], Loss: 1.9118, Accuracy: 69.80%\n",
      "Epoch [57/500], Loss: 1.8257, Accuracy: 72.34%\n",
      "✅ Best model saved at epoch 57 with loss 1.8257\n",
      "Epoch [58/500], Loss: 1.7927, Accuracy: 73.60%\n",
      "✅ Best model saved at epoch 58 with loss 1.7927\n",
      "Epoch [59/500], Loss: 1.7525, Accuracy: 75.20%\n",
      "✅ Best model saved at epoch 59 with loss 1.7525\n",
      "Epoch [60/500], Loss: 1.7843, Accuracy: 74.02%\n",
      "Epoch [61/500], Loss: 1.7844, Accuracy: 73.31%\n",
      "Epoch [62/500], Loss: 1.7691, Accuracy: 73.92%\n",
      "Epoch [63/500], Loss: 1.7112, Accuracy: 76.15%\n",
      "✅ Best model saved at epoch 63 with loss 1.7112\n",
      "Epoch [64/500], Loss: 1.6338, Accuracy: 78.94%\n",
      "✅ Best model saved at epoch 64 with loss 1.6338\n",
      "Epoch [65/500], Loss: 1.5875, Accuracy: 80.47%\n",
      "✅ Best model saved at epoch 65 with loss 1.5875\n",
      "Epoch [66/500], Loss: 1.6066, Accuracy: 79.86%\n",
      "Epoch [67/500], Loss: 1.5872, Accuracy: 79.98%\n",
      "✅ Best model saved at epoch 67 with loss 1.5872\n",
      "Epoch [68/500], Loss: 1.5366, Accuracy: 82.44%\n",
      "✅ Best model saved at epoch 68 with loss 1.5366\n",
      "Epoch [69/500], Loss: 1.5249, Accuracy: 82.46%\n",
      "✅ Best model saved at epoch 69 with loss 1.5249\n",
      "Epoch [70/500], Loss: 1.4984, Accuracy: 83.61%\n",
      "✅ Best model saved at epoch 70 with loss 1.4984\n",
      "Epoch [71/500], Loss: 1.4435, Accuracy: 85.55%\n",
      "✅ Best model saved at epoch 71 with loss 1.4435\n",
      "Epoch [72/500], Loss: 1.4682, Accuracy: 84.15%\n",
      "Epoch [73/500], Loss: 1.4362, Accuracy: 85.60%\n",
      "✅ Best model saved at epoch 73 with loss 1.4362\n",
      "Epoch [74/500], Loss: 1.4674, Accuracy: 84.32%\n",
      "Epoch [75/500], Loss: 1.4338, Accuracy: 85.42%\n",
      "✅ Best model saved at epoch 75 with loss 1.4338\n",
      "Epoch [76/500], Loss: 1.3785, Accuracy: 87.80%\n",
      "✅ Best model saved at epoch 76 with loss 1.3785\n",
      "Epoch [77/500], Loss: 1.3823, Accuracy: 87.25%\n",
      "Epoch [78/500], Loss: 1.4197, Accuracy: 85.91%\n",
      "Epoch [79/500], Loss: 1.3713, Accuracy: 87.52%\n",
      "✅ Best model saved at epoch 79 with loss 1.3713\n",
      "Epoch [80/500], Loss: 1.3834, Accuracy: 86.67%\n",
      "Epoch [81/500], Loss: 1.3386, Accuracy: 89.01%\n",
      "✅ Best model saved at epoch 81 with loss 1.3386\n",
      "Epoch [82/500], Loss: 1.3043, Accuracy: 90.06%\n",
      "✅ Best model saved at epoch 82 with loss 1.3043\n",
      "Epoch [83/500], Loss: 1.3057, Accuracy: 89.82%\n",
      "Epoch [84/500], Loss: 1.2886, Accuracy: 90.44%\n",
      "✅ Best model saved at epoch 84 with loss 1.2886\n",
      "Epoch [85/500], Loss: 1.3355, Accuracy: 88.29%\n",
      "Epoch [86/500], Loss: 1.2925, Accuracy: 89.95%\n",
      "Epoch [87/500], Loss: 1.2738, Accuracy: 90.68%\n",
      "✅ Best model saved at epoch 87 with loss 1.2738\n",
      "Epoch [88/500], Loss: 1.2367, Accuracy: 91.91%\n",
      "✅ Best model saved at epoch 88 with loss 1.2367\n",
      "Epoch [89/500], Loss: 1.2853, Accuracy: 89.78%\n",
      "Epoch [90/500], Loss: 1.2460, Accuracy: 91.30%\n",
      "Epoch [91/500], Loss: 1.2311, Accuracy: 91.97%\n",
      "✅ Best model saved at epoch 91 with loss 1.2311\n",
      "Epoch [92/500], Loss: 1.2126, Accuracy: 92.60%\n",
      "✅ Best model saved at epoch 92 with loss 1.2126\n",
      "Epoch [93/500], Loss: 1.2155, Accuracy: 92.48%\n",
      "Epoch [94/500], Loss: 1.2162, Accuracy: 92.52%\n",
      "Epoch [95/500], Loss: 1.2064, Accuracy: 92.70%\n",
      "✅ Best model saved at epoch 95 with loss 1.2064\n",
      "Epoch [96/500], Loss: 1.2185, Accuracy: 92.26%\n",
      "Epoch [97/500], Loss: 1.1692, Accuracy: 93.91%\n",
      "✅ Best model saved at epoch 97 with loss 1.1692\n",
      "Epoch [98/500], Loss: 1.1789, Accuracy: 93.46%\n",
      "Epoch [99/500], Loss: 1.1761, Accuracy: 93.46%\n",
      "Epoch [100/500], Loss: 1.1506, Accuracy: 94.40%\n",
      "✅ Best model saved at epoch 100 with loss 1.1506\n",
      "Epoch [101/500], Loss: 1.1615, Accuracy: 94.00%\n",
      "Epoch [102/500], Loss: 1.1346, Accuracy: 94.90%\n",
      "✅ Best model saved at epoch 102 with loss 1.1346\n",
      "Epoch [103/500], Loss: 1.1269, Accuracy: 95.11%\n",
      "✅ Best model saved at epoch 103 with loss 1.1269\n",
      "Epoch [104/500], Loss: 1.1590, Accuracy: 94.07%\n",
      "Epoch [105/500], Loss: 1.1627, Accuracy: 93.71%\n",
      "Epoch [106/500], Loss: 1.1548, Accuracy: 94.14%\n",
      "Epoch [107/500], Loss: 1.1764, Accuracy: 93.53%\n",
      "Epoch [108/500], Loss: 1.0895, Accuracy: 96.29%\n",
      "✅ Best model saved at epoch 108 with loss 1.0895\n",
      "Epoch [109/500], Loss: 1.0503, Accuracy: 97.51%\n",
      "✅ Best model saved at epoch 109 with loss 1.0503\n",
      "Epoch [110/500], Loss: 1.0362, Accuracy: 97.76%\n",
      "✅ Best model saved at epoch 110 with loss 1.0362\n",
      "Epoch [111/500], Loss: 1.0336, Accuracy: 97.82%\n",
      "✅ Best model saved at epoch 111 with loss 1.0336\n",
      "Epoch [112/500], Loss: 1.0282, Accuracy: 98.04%\n",
      "✅ Best model saved at epoch 112 with loss 1.0282\n",
      "Epoch [113/500], Loss: 1.0222, Accuracy: 98.05%\n",
      "✅ Best model saved at epoch 113 with loss 1.0222\n",
      "Epoch [114/500], Loss: 1.0193, Accuracy: 98.19%\n",
      "✅ Best model saved at epoch 114 with loss 1.0193\n",
      "Epoch [115/500], Loss: 1.0192, Accuracy: 98.01%\n",
      "✅ Best model saved at epoch 115 with loss 1.0192\n",
      "Epoch [116/500], Loss: 1.0240, Accuracy: 97.60%\n",
      "Epoch [117/500], Loss: 1.0336, Accuracy: 97.42%\n",
      "Epoch [118/500], Loss: 1.0415, Accuracy: 97.32%\n",
      "Epoch [119/500], Loss: 1.0342, Accuracy: 97.52%\n",
      "Epoch [120/500], Loss: 1.0042, Accuracy: 98.31%\n",
      "✅ Best model saved at epoch 120 with loss 1.0042\n",
      "Epoch [121/500], Loss: 0.9948, Accuracy: 98.49%\n",
      "✅ Best model saved at epoch 121 with loss 0.9948\n",
      "Epoch [122/500], Loss: 0.9932, Accuracy: 98.47%\n",
      "✅ Best model saved at epoch 122 with loss 0.9932\n",
      "Epoch [123/500], Loss: 0.9991, Accuracy: 98.30%\n",
      "Epoch [124/500], Loss: 0.9887, Accuracy: 98.65%\n",
      "✅ Best model saved at epoch 124 with loss 0.9887\n",
      "Epoch [125/500], Loss: 0.9852, Accuracy: 98.73%\n",
      "✅ Best model saved at epoch 125 with loss 0.9852\n",
      "Epoch [126/500], Loss: 0.9842, Accuracy: 98.49%\n",
      "✅ Best model saved at epoch 126 with loss 0.9842\n",
      "Epoch [127/500], Loss: 0.9827, Accuracy: 98.60%\n",
      "✅ Best model saved at epoch 127 with loss 0.9827\n",
      "Epoch [128/500], Loss: 0.9816, Accuracy: 98.61%\n",
      "✅ Best model saved at epoch 128 with loss 0.9816\n",
      "Epoch [129/500], Loss: 0.9789, Accuracy: 98.70%\n",
      "✅ Best model saved at epoch 129 with loss 0.9789\n",
      "Epoch [130/500], Loss: 0.9789, Accuracy: 98.72%\n",
      "Epoch [131/500], Loss: 0.9800, Accuracy: 98.59%\n",
      "Epoch [132/500], Loss: 0.9817, Accuracy: 98.50%\n",
      "Epoch [133/500], Loss: 0.9828, Accuracy: 98.36%\n",
      "Epoch [134/500], Loss: 0.9755, Accuracy: 98.66%\n",
      "✅ Best model saved at epoch 134 with loss 0.9755\n",
      "Epoch [135/500], Loss: 0.9727, Accuracy: 98.67%\n",
      "✅ Best model saved at epoch 135 with loss 0.9727\n",
      "Epoch [136/500], Loss: 0.9709, Accuracy: 98.71%\n",
      "✅ Best model saved at epoch 136 with loss 0.9709\n",
      "Epoch [137/500], Loss: 0.9697, Accuracy: 98.67%\n",
      "✅ Best model saved at epoch 137 with loss 0.9697\n",
      "Epoch [138/500], Loss: 0.9673, Accuracy: 98.94%\n",
      "✅ Best model saved at epoch 138 with loss 0.9673\n",
      "Epoch [139/500], Loss: 0.9682, Accuracy: 98.65%\n",
      "Epoch [140/500], Loss: 0.9672, Accuracy: 98.64%\n",
      "✅ Best model saved at epoch 140 with loss 0.9672\n",
      "Epoch [141/500], Loss: 0.9670, Accuracy: 98.71%\n",
      "✅ Best model saved at epoch 141 with loss 0.9670\n",
      "Epoch [142/500], Loss: 0.9654, Accuracy: 98.78%\n",
      "✅ Best model saved at epoch 142 with loss 0.9654\n",
      "Epoch [143/500], Loss: 0.9669, Accuracy: 98.73%\n",
      "Epoch [144/500], Loss: 0.9666, Accuracy: 98.66%\n",
      "Epoch [145/500], Loss: 0.9647, Accuracy: 98.67%\n",
      "✅ Best model saved at epoch 145 with loss 0.9647\n",
      "Epoch [146/500], Loss: 0.9633, Accuracy: 98.82%\n",
      "✅ Best model saved at epoch 146 with loss 0.9633\n",
      "Epoch [147/500], Loss: 0.9630, Accuracy: 98.79%\n",
      "✅ Best model saved at epoch 147 with loss 0.9630\n",
      "Epoch [148/500], Loss: 0.9619, Accuracy: 98.68%\n",
      "✅ Best model saved at epoch 148 with loss 0.9619\n",
      "Epoch [149/500], Loss: 0.9629, Accuracy: 98.72%\n",
      "Epoch [150/500], Loss: 0.9617, Accuracy: 98.78%\n",
      "✅ Best model saved at epoch 150 with loss 0.9617\n",
      "Epoch [151/500], Loss: 0.9623, Accuracy: 98.68%\n",
      "Epoch [152/500], Loss: 0.9624, Accuracy: 98.82%\n",
      "Epoch [153/500], Loss: 0.9648, Accuracy: 98.62%\n",
      "Epoch [154/500], Loss: 0.9620, Accuracy: 98.90%\n",
      "Epoch [155/500], Loss: 0.9584, Accuracy: 98.89%\n",
      "✅ Best model saved at epoch 155 with loss 0.9584\n",
      "Epoch [156/500], Loss: 0.9565, Accuracy: 98.98%\n",
      "✅ Best model saved at epoch 156 with loss 0.9565\n",
      "Epoch [157/500], Loss: 0.9578, Accuracy: 98.79%\n",
      "Epoch [158/500], Loss: 0.9571, Accuracy: 98.85%\n",
      "Epoch [159/500], Loss: 0.9570, Accuracy: 98.88%\n",
      "Epoch [160/500], Loss: 0.9574, Accuracy: 98.72%\n",
      "Epoch [161/500], Loss: 0.9551, Accuracy: 98.82%\n",
      "✅ Best model saved at epoch 161 with loss 0.9551\n",
      "Epoch [162/500], Loss: 0.9539, Accuracy: 98.80%\n",
      "✅ Best model saved at epoch 162 with loss 0.9539\n",
      "Epoch [163/500], Loss: 0.9533, Accuracy: 98.97%\n",
      "✅ Best model saved at epoch 163 with loss 0.9533\n",
      "Epoch [164/500], Loss: 0.9548, Accuracy: 98.88%\n",
      "Epoch [165/500], Loss: 0.9545, Accuracy: 98.85%\n",
      "Epoch [166/500], Loss: 0.9539, Accuracy: 98.94%\n",
      "Epoch [167/500], Loss: 0.9532, Accuracy: 98.96%\n",
      "✅ Best model saved at epoch 167 with loss 0.9532\n",
      "Epoch [168/500], Loss: 0.9549, Accuracy: 98.86%\n",
      "Epoch [169/500], Loss: 0.9532, Accuracy: 98.88%\n",
      "✅ Best model saved at epoch 169 with loss 0.9532\n",
      "Epoch [170/500], Loss: 0.9521, Accuracy: 99.04%\n",
      "✅ Best model saved at epoch 170 with loss 0.9521\n",
      "Epoch [171/500], Loss: 0.9523, Accuracy: 99.08%\n",
      "Epoch [172/500], Loss: 0.9516, Accuracy: 98.90%\n",
      "✅ Best model saved at epoch 172 with loss 0.9516\n",
      "Epoch [173/500], Loss: 0.9518, Accuracy: 99.03%\n",
      "Epoch [174/500], Loss: 0.9524, Accuracy: 98.96%\n",
      "Epoch [175/500], Loss: 0.9522, Accuracy: 98.88%\n",
      "Epoch [176/500], Loss: 0.9533, Accuracy: 98.94%\n",
      "Epoch [177/500], Loss: 0.9516, Accuracy: 98.95%\n",
      "✅ Best model saved at epoch 177 with loss 0.9516\n",
      "Epoch [178/500], Loss: 0.9516, Accuracy: 99.00%\n",
      "Epoch [179/500], Loss: 0.9522, Accuracy: 98.94%\n",
      "Epoch [180/500], Loss: 0.9520, Accuracy: 98.88%\n",
      "Epoch [181/500], Loss: 0.9511, Accuracy: 98.97%\n",
      "✅ Best model saved at epoch 181 with loss 0.9511\n",
      "Epoch [182/500], Loss: 0.9511, Accuracy: 99.07%\n",
      "Epoch [183/500], Loss: 0.9503, Accuracy: 98.95%\n",
      "✅ Best model saved at epoch 183 with loss 0.9503\n",
      "Epoch [184/500], Loss: 0.9499, Accuracy: 99.08%\n",
      "✅ Best model saved at epoch 184 with loss 0.9499\n",
      "Epoch [185/500], Loss: 0.9508, Accuracy: 99.10%\n",
      "Epoch [186/500], Loss: 0.9500, Accuracy: 99.01%\n",
      "Epoch [187/500], Loss: 0.9510, Accuracy: 98.97%\n",
      "Epoch [188/500], Loss: 0.9516, Accuracy: 99.00%\n",
      "Epoch [189/500], Loss: 0.9510, Accuracy: 99.06%\n",
      "Early stopping triggered.\n",
      "Training completed! Best model saved at: /home/haggenmueller/asl_detection/machine_learning/models/lstm/best_lstm_model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Paths\n",
    "LABELS_PATH = \"/home/haggenmueller/asl_detection/machine_learning/models/lstm/label_to_index.json\"\n",
    "DATA_DIR = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/keypoints\"\n",
    "MODEL_PATH = \"/home/haggenmueller/asl_detection/machine_learning/models/lstm/best_lstm_model.pth\"\n",
    "\n",
    "# Parameters\n",
    "SEQUENCE_LENGTH = 102  # Number of frames per sequence\n",
    "INPUT_SIZE = 225  # Adjusted to include face keypoints\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "LR = 0.0001\n",
    "PATIENCE = 5  # Early stopping patience\n",
    "\n",
    "# Load labels\n",
    "with open(LABELS_PATH, \"r\") as f:\n",
    "    label_to_index = json.load(f)\n",
    "    index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "    NUM_CLASSES = len(label_to_index)\n",
    "\n",
    "# Dataset class\n",
    "class ASLDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels_map, sequence_length):\n",
    "        self.data_dir = data_dir\n",
    "        self.sequence_length = sequence_length\n",
    "        self.samples = []\n",
    "        \n",
    "        for file in os.listdir(data_dir):\n",
    "            if file.endswith(\".npy\"):\n",
    "                filename_parts = file.split(\"_\")\n",
    "                label_name = filename_parts[1]  # Extract label from filename structure\n",
    "                if label_name in labels_map:\n",
    "                    self.samples.append((os.path.join(data_dir, file), labels_map[label_name]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        keypoints = np.load(file_path)\n",
    "        \n",
    "        # Ensure all sequences are of the same length\n",
    "        if keypoints.shape[0] < self.sequence_length:\n",
    "            pad = np.zeros((self.sequence_length - keypoints.shape[0], keypoints.shape[1]))\n",
    "            keypoints = np.vstack((keypoints, pad))\n",
    "        else:\n",
    "            keypoints = keypoints[:self.sequence_length]\n",
    "        \n",
    "        return torch.tensor(keypoints, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "    \n",
    "# LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)  # Dropout to prevent overfitting\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.dropout(out[:, -1, :])  # Apply Dropout\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Load data\n",
    "dataset = ASLDataset(DATA_DIR, label_to_index, SEQUENCE_LENGTH)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMModel(input_size=INPUT_SIZE, hidden_size=512, num_layers=3, num_classes=NUM_CLASSES)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Apply Xavier Initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param.data)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# Early stopping\n",
    "best_loss = float(\"inf\")\n",
    "stopping_counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for keypoints, labels in dataloader:\n",
    "        keypoints, labels = keypoints.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(keypoints)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100 * correct / float(total)\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    # Adjust learning rate\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Save best model if it improves\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        stopping_counter = 0\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"✅ Best model saved at epoch {epoch+1} with loss {avg_loss:.4f}\")\n",
    "    else:\n",
    "        stopping_counter += 1\n",
    "        if stopping_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Training completed! Best model saved at:\", MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2930592/3936693878.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/haggenmueller/asl_detection/machine_learning/models/lstm/best_lstm_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_to_label[label\u001b[38;5;241m.\u001b[39mitem()]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_to_label[predicted_class]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtest_model\u001b[39m():\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the trained model and test on a random sample from the dataset.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m     sample, label \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/asl_detection/lib/python3.10/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/asl_detection/lib/python3.10/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/asl_detection/lib/python3.10/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/haggenmueller/asl_detection/machine_learning/models/lstm/best_lstm_model.pth'"
     ]
    }
   ],
   "source": [
    "# Testing cell\n",
    "def test_model():\n",
    "    \"\"\"Load the trained model and test on a random sample from the dataset.\"\"\"\n",
    "    model.load_state_dict(torch.load(\"/home/haggenmueller/asl_detection/machine_learning/models/lstm/no_batch_norm_lstm_model.pth\"))\n",
    "    model.eval()\n",
    "    \n",
    "    sample, label = dataset[0]\n",
    "    sample = sample.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(sample)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    print(f\"Actual Label: {index_to_label[label.item()]}\")\n",
    "    print(f\"Predicted Label: {index_to_label[predicted_class]}\")\n",
    "\n",
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
