{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate informations for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def compute_train_stats(folder_path):\n",
    "    \"\"\"Loads all .npy files in the folder and calculates the mean and standard deviation.\"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            data = np.load(file_path)\n",
    "\n",
    "            if data.ndim == 1:  \n",
    "                data = data.reshape(1, -1)\n",
    "\n",
    "            all_data.append(data)\n",
    "\n",
    "    if not all_data:\n",
    "        raise ValueError(\"No .npy files found in the folder!\")\n",
    "\n",
    "    all_data = np.vstack(all_data)\n",
    "\n",
    "    train_mean = np.mean(all_data, axis=0)\n",
    "    train_std = np.std(all_data, axis=0)\n",
    "\n",
    "    # Speicherort neben dem \"keypoints\" Ordner\n",
    "    parent_folder = os.path.dirname(folder_path)\n",
    "\n",
    "    np.save(os.path.join(parent_folder, \"train_mean.npy\"), train_mean)\n",
    "    np.save(os.path.join(parent_folder, \"train_std.npy\"), train_std)\n",
    "\n",
    "    print(\"✅ Mean & standard deviation saved next to the keypoints folder!\")\n",
    "\n",
    "# Example call:\n",
    "compute_train_stats(\"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/keypoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Loss: 5.2108, Accuracy: 0.96%\n",
      "✅ Best model saved at epoch 1 with loss 5.2108\n",
      "Epoch [2/150], Loss: 4.9958, Accuracy: 1.35%\n",
      "✅ Best model saved at epoch 2 with loss 4.9958\n",
      "Epoch [3/150], Loss: 4.8688, Accuracy: 1.90%\n",
      "✅ Best model saved at epoch 3 with loss 4.8688\n",
      "Epoch [4/150], Loss: 4.7694, Accuracy: 1.88%\n",
      "✅ Best model saved at epoch 4 with loss 4.7694\n",
      "Epoch [5/150], Loss: 4.7017, Accuracy: 2.80%\n",
      "✅ Best model saved at epoch 5 with loss 4.7017\n",
      "Epoch [6/150], Loss: 4.6590, Accuracy: 2.90%\n",
      "✅ Best model saved at epoch 6 with loss 4.6590\n",
      "Epoch [7/150], Loss: 4.6275, Accuracy: 3.67%\n",
      "✅ Best model saved at epoch 7 with loss 4.6275\n",
      "Epoch [8/150], Loss: 4.5462, Accuracy: 4.15%\n",
      "✅ Best model saved at epoch 8 with loss 4.5462\n",
      "Epoch [9/150], Loss: 4.4820, Accuracy: 4.43%\n",
      "✅ Best model saved at epoch 9 with loss 4.4820\n",
      "Epoch [10/150], Loss: 4.4108, Accuracy: 4.78%\n",
      "✅ Best model saved at epoch 10 with loss 4.4108\n",
      "Epoch [11/150], Loss: 4.3609, Accuracy: 5.88%\n",
      "✅ Best model saved at epoch 11 with loss 4.3609\n",
      "Epoch [12/150], Loss: 4.3000, Accuracy: 6.48%\n",
      "✅ Best model saved at epoch 12 with loss 4.3000\n",
      "Epoch [13/150], Loss: 4.2446, Accuracy: 6.70%\n",
      "✅ Best model saved at epoch 13 with loss 4.2446\n",
      "Epoch [14/150], Loss: 4.2132, Accuracy: 6.89%\n",
      "✅ Best model saved at epoch 14 with loss 4.2132\n",
      "Epoch [15/150], Loss: 4.2093, Accuracy: 6.94%\n",
      "✅ Best model saved at epoch 15 with loss 4.2093\n",
      "Epoch [16/150], Loss: 4.1358, Accuracy: 7.78%\n",
      "✅ Best model saved at epoch 16 with loss 4.1358\n",
      "Epoch [17/150], Loss: 4.0969, Accuracy: 9.01%\n",
      "✅ Best model saved at epoch 17 with loss 4.0969\n",
      "Epoch [18/150], Loss: 4.0494, Accuracy: 8.92%\n",
      "✅ Best model saved at epoch 18 with loss 4.0494\n",
      "Epoch [19/150], Loss: 4.0349, Accuracy: 9.52%\n",
      "✅ Best model saved at epoch 19 with loss 4.0349\n",
      "Epoch [20/150], Loss: 3.9636, Accuracy: 10.70%\n",
      "✅ Best model saved at epoch 20 with loss 3.9636\n",
      "Epoch [21/150], Loss: 3.9269, Accuracy: 11.59%\n",
      "✅ Best model saved at epoch 21 with loss 3.9269\n",
      "Epoch [22/150], Loss: 3.8629, Accuracy: 12.00%\n",
      "✅ Best model saved at epoch 22 with loss 3.8629\n",
      "Epoch [23/150], Loss: 3.8213, Accuracy: 13.28%\n",
      "✅ Best model saved at epoch 23 with loss 3.8213\n",
      "Epoch [24/150], Loss: 3.7864, Accuracy: 14.18%\n",
      "✅ Best model saved at epoch 24 with loss 3.7864\n",
      "Epoch [25/150], Loss: 3.7399, Accuracy: 14.73%\n",
      "✅ Best model saved at epoch 25 with loss 3.7399\n",
      "Epoch [26/150], Loss: 3.7052, Accuracy: 15.00%\n",
      "✅ Best model saved at epoch 26 with loss 3.7052\n",
      "Epoch [27/150], Loss: 3.6584, Accuracy: 15.74%\n",
      "✅ Best model saved at epoch 27 with loss 3.6584\n",
      "Epoch [28/150], Loss: 3.6364, Accuracy: 16.39%\n",
      "✅ Best model saved at epoch 28 with loss 3.6364\n",
      "Epoch [29/150], Loss: 3.5804, Accuracy: 17.72%\n",
      "✅ Best model saved at epoch 29 with loss 3.5804\n",
      "Epoch [30/150], Loss: 3.5360, Accuracy: 18.76%\n",
      "✅ Best model saved at epoch 30 with loss 3.5360\n",
      "Epoch [31/150], Loss: 3.4761, Accuracy: 20.56%\n",
      "✅ Best model saved at epoch 31 with loss 3.4761\n",
      "Epoch [32/150], Loss: 3.4811, Accuracy: 21.05%\n",
      "Epoch [33/150], Loss: 3.4425, Accuracy: 21.07%\n",
      "✅ Best model saved at epoch 33 with loss 3.4425\n",
      "Epoch [34/150], Loss: 3.4433, Accuracy: 22.08%\n",
      "Epoch [35/150], Loss: 3.3895, Accuracy: 22.92%\n",
      "✅ Best model saved at epoch 35 with loss 3.3895\n",
      "Epoch [36/150], Loss: 3.3290, Accuracy: 24.06%\n",
      "✅ Best model saved at epoch 36 with loss 3.3290\n",
      "Epoch [37/150], Loss: 3.2960, Accuracy: 25.12%\n",
      "✅ Best model saved at epoch 37 with loss 3.2960\n",
      "Epoch [38/150], Loss: 3.2704, Accuracy: 25.77%\n",
      "✅ Best model saved at epoch 38 with loss 3.2704\n",
      "Epoch [39/150], Loss: 3.2656, Accuracy: 24.91%\n",
      "✅ Best model saved at epoch 39 with loss 3.2656\n",
      "Epoch [40/150], Loss: 3.1930, Accuracy: 27.36%\n",
      "✅ Best model saved at epoch 40 with loss 3.1930\n",
      "Epoch [41/150], Loss: 3.1356, Accuracy: 29.15%\n",
      "✅ Best model saved at epoch 41 with loss 3.1356\n",
      "Epoch [42/150], Loss: 3.1495, Accuracy: 28.76%\n",
      "Epoch [43/150], Loss: 3.1234, Accuracy: 29.53%\n",
      "✅ Best model saved at epoch 43 with loss 3.1234\n",
      "Epoch [44/150], Loss: 3.0597, Accuracy: 31.36%\n",
      "✅ Best model saved at epoch 44 with loss 3.0597\n",
      "Epoch [45/150], Loss: 3.0110, Accuracy: 32.79%\n",
      "✅ Best model saved at epoch 45 with loss 3.0110\n",
      "Epoch [46/150], Loss: 2.9941, Accuracy: 33.42%\n",
      "✅ Best model saved at epoch 46 with loss 2.9941\n",
      "Epoch [47/150], Loss: 2.9687, Accuracy: 34.11%\n",
      "✅ Best model saved at epoch 47 with loss 2.9687\n",
      "Epoch [48/150], Loss: 2.9509, Accuracy: 34.13%\n",
      "✅ Best model saved at epoch 48 with loss 2.9509\n",
      "Epoch [49/150], Loss: 2.9168, Accuracy: 35.68%\n",
      "✅ Best model saved at epoch 49 with loss 2.9168\n",
      "Epoch [50/150], Loss: 2.8821, Accuracy: 37.22%\n",
      "✅ Best model saved at epoch 50 with loss 2.8821\n",
      "Epoch [51/150], Loss: 2.8771, Accuracy: 37.24%\n",
      "✅ Best model saved at epoch 51 with loss 2.8771\n",
      "Epoch [52/150], Loss: 2.8327, Accuracy: 38.38%\n",
      "✅ Best model saved at epoch 52 with loss 2.8327\n",
      "Epoch [53/150], Loss: 2.7733, Accuracy: 40.65%\n",
      "✅ Best model saved at epoch 53 with loss 2.7733\n",
      "Epoch [54/150], Loss: 2.7177, Accuracy: 41.18%\n",
      "✅ Best model saved at epoch 54 with loss 2.7177\n",
      "Epoch [55/150], Loss: 2.6827, Accuracy: 43.52%\n",
      "✅ Best model saved at epoch 55 with loss 2.6827\n",
      "Epoch [56/150], Loss: 2.6448, Accuracy: 45.56%\n",
      "✅ Best model saved at epoch 56 with loss 2.6448\n",
      "Epoch [57/150], Loss: 2.6211, Accuracy: 45.13%\n",
      "✅ Best model saved at epoch 57 with loss 2.6211\n",
      "Epoch [58/150], Loss: 2.5766, Accuracy: 45.69%\n",
      "✅ Best model saved at epoch 58 with loss 2.5766\n",
      "Epoch [59/150], Loss: 2.5803, Accuracy: 47.30%\n",
      "Epoch [60/150], Loss: 2.5480, Accuracy: 46.86%\n",
      "✅ Best model saved at epoch 60 with loss 2.5480\n",
      "Epoch [61/150], Loss: 2.4942, Accuracy: 50.09%\n",
      "✅ Best model saved at epoch 61 with loss 2.4942\n",
      "Epoch [62/150], Loss: 2.4889, Accuracy: 50.26%\n",
      "✅ Best model saved at epoch 62 with loss 2.4889\n",
      "Epoch [63/150], Loss: 2.4234, Accuracy: 53.02%\n",
      "✅ Best model saved at epoch 63 with loss 2.4234\n",
      "Epoch [64/150], Loss: 2.4022, Accuracy: 53.55%\n",
      "✅ Best model saved at epoch 64 with loss 2.4022\n",
      "Epoch [65/150], Loss: 2.3320, Accuracy: 54.78%\n",
      "✅ Best model saved at epoch 65 with loss 2.3320\n",
      "Epoch [66/150], Loss: 2.3422, Accuracy: 54.99%\n",
      "Epoch [67/150], Loss: 2.3177, Accuracy: 56.25%\n",
      "✅ Best model saved at epoch 67 with loss 2.3177\n",
      "Epoch [68/150], Loss: 2.2875, Accuracy: 56.48%\n",
      "✅ Best model saved at epoch 68 with loss 2.2875\n",
      "Epoch [69/150], Loss: 2.2386, Accuracy: 58.54%\n",
      "✅ Best model saved at epoch 69 with loss 2.2386\n",
      "Epoch [70/150], Loss: 2.2223, Accuracy: 58.25%\n",
      "✅ Best model saved at epoch 70 with loss 2.2223\n",
      "Epoch [71/150], Loss: 2.1724, Accuracy: 61.02%\n",
      "✅ Best model saved at epoch 71 with loss 2.1724\n",
      "Epoch [72/150], Loss: 2.1793, Accuracy: 60.71%\n",
      "Epoch [73/150], Loss: 2.1435, Accuracy: 61.76%\n",
      "✅ Best model saved at epoch 73 with loss 2.1435\n",
      "Epoch [74/150], Loss: 2.1053, Accuracy: 64.23%\n",
      "✅ Best model saved at epoch 74 with loss 2.1053\n",
      "Epoch [75/150], Loss: 2.0686, Accuracy: 65.05%\n",
      "✅ Best model saved at epoch 75 with loss 2.0686\n",
      "Epoch [76/150], Loss: 2.0357, Accuracy: 65.62%\n",
      "✅ Best model saved at epoch 76 with loss 2.0357\n",
      "Epoch [77/150], Loss: 1.9974, Accuracy: 66.63%\n",
      "✅ Best model saved at epoch 77 with loss 1.9974\n",
      "Epoch [78/150], Loss: 2.0079, Accuracy: 66.90%\n",
      "Epoch [79/150], Loss: 1.9546, Accuracy: 67.75%\n",
      "✅ Best model saved at epoch 79 with loss 1.9546\n",
      "Epoch [80/150], Loss: 1.9373, Accuracy: 69.14%\n",
      "✅ Best model saved at epoch 80 with loss 1.9373\n",
      "Epoch [81/150], Loss: 1.8885, Accuracy: 71.70%\n",
      "✅ Best model saved at epoch 81 with loss 1.8885\n",
      "Epoch [82/150], Loss: 1.8662, Accuracy: 72.33%\n",
      "✅ Best model saved at epoch 82 with loss 1.8662\n",
      "Epoch [83/150], Loss: 1.8570, Accuracy: 72.42%\n",
      "✅ Best model saved at epoch 83 with loss 1.8570\n",
      "Epoch [84/150], Loss: 1.8331, Accuracy: 73.03%\n",
      "✅ Best model saved at epoch 84 with loss 1.8331\n",
      "Epoch [85/150], Loss: 1.8093, Accuracy: 74.23%\n",
      "✅ Best model saved at epoch 85 with loss 1.8093\n",
      "Epoch [86/150], Loss: 1.7698, Accuracy: 75.63%\n",
      "✅ Best model saved at epoch 86 with loss 1.7698\n",
      "Epoch [87/150], Loss: 1.7664, Accuracy: 75.85%\n",
      "✅ Best model saved at epoch 87 with loss 1.7664\n",
      "Epoch [88/150], Loss: 1.7307, Accuracy: 77.05%\n",
      "✅ Best model saved at epoch 88 with loss 1.7307\n",
      "Epoch [89/150], Loss: 1.6974, Accuracy: 78.32%\n",
      "✅ Best model saved at epoch 89 with loss 1.6974\n",
      "Epoch [90/150], Loss: 1.6810, Accuracy: 78.79%\n",
      "✅ Best model saved at epoch 90 with loss 1.6810\n",
      "Epoch [91/150], Loss: 1.6640, Accuracy: 79.44%\n",
      "✅ Best model saved at epoch 91 with loss 1.6640\n",
      "Epoch [92/150], Loss: 1.6390, Accuracy: 80.69%\n",
      "✅ Best model saved at epoch 92 with loss 1.6390\n",
      "Epoch [93/150], Loss: 1.6282, Accuracy: 80.18%\n",
      "✅ Best model saved at epoch 93 with loss 1.6282\n",
      "Epoch [94/150], Loss: 1.6023, Accuracy: 81.66%\n",
      "✅ Best model saved at epoch 94 with loss 1.6023\n",
      "Epoch [95/150], Loss: 1.5969, Accuracy: 81.63%\n",
      "✅ Best model saved at epoch 95 with loss 1.5969\n",
      "Epoch [96/150], Loss: 1.5620, Accuracy: 83.53%\n",
      "✅ Best model saved at epoch 96 with loss 1.5620\n",
      "Epoch [97/150], Loss: 1.5285, Accuracy: 84.52%\n",
      "✅ Best model saved at epoch 97 with loss 1.5285\n",
      "Epoch [98/150], Loss: 1.5147, Accuracy: 85.05%\n",
      "✅ Best model saved at epoch 98 with loss 1.5147\n",
      "Epoch [99/150], Loss: 1.4945, Accuracy: 85.54%\n",
      "✅ Best model saved at epoch 99 with loss 1.4945\n",
      "Epoch [100/150], Loss: 1.4937, Accuracy: 85.41%\n",
      "✅ Best model saved at epoch 100 with loss 1.4937\n",
      "Epoch [101/150], Loss: 1.4662, Accuracy: 86.71%\n",
      "✅ Best model saved at epoch 101 with loss 1.4662\n",
      "Epoch [102/150], Loss: 1.4508, Accuracy: 86.69%\n",
      "✅ Best model saved at epoch 102 with loss 1.4508\n",
      "Epoch [103/150], Loss: 1.4430, Accuracy: 87.47%\n",
      "✅ Best model saved at epoch 103 with loss 1.4430\n",
      "Epoch [104/150], Loss: 1.4220, Accuracy: 87.80%\n",
      "✅ Best model saved at epoch 104 with loss 1.4220\n",
      "Epoch [105/150], Loss: 1.4066, Accuracy: 88.31%\n",
      "✅ Best model saved at epoch 105 with loss 1.4066\n",
      "Epoch [106/150], Loss: 1.4020, Accuracy: 89.13%\n",
      "✅ Best model saved at epoch 106 with loss 1.4020\n",
      "Epoch [107/150], Loss: 1.3852, Accuracy: 89.35%\n",
      "✅ Best model saved at epoch 107 with loss 1.3852\n",
      "Epoch [108/150], Loss: 1.3676, Accuracy: 90.38%\n",
      "✅ Best model saved at epoch 108 with loss 1.3676\n",
      "Epoch [109/150], Loss: 1.3516, Accuracy: 90.60%\n",
      "✅ Best model saved at epoch 109 with loss 1.3516\n",
      "Epoch [110/150], Loss: 1.3341, Accuracy: 91.75%\n",
      "✅ Best model saved at epoch 110 with loss 1.3341\n",
      "Epoch [111/150], Loss: 1.3260, Accuracy: 91.08%\n",
      "✅ Best model saved at epoch 111 with loss 1.3260\n",
      "Epoch [112/150], Loss: 1.3217, Accuracy: 91.56%\n",
      "✅ Best model saved at epoch 112 with loss 1.3217\n",
      "Epoch [113/150], Loss: 1.3005, Accuracy: 92.29%\n",
      "✅ Best model saved at epoch 113 with loss 1.3005\n",
      "Epoch [114/150], Loss: 1.2960, Accuracy: 92.77%\n",
      "✅ Best model saved at epoch 114 with loss 1.2960\n",
      "Epoch [115/150], Loss: 1.2851, Accuracy: 92.86%\n",
      "✅ Best model saved at epoch 115 with loss 1.2851\n",
      "Epoch [116/150], Loss: 1.2709, Accuracy: 93.25%\n",
      "✅ Best model saved at epoch 116 with loss 1.2709\n",
      "Epoch [117/150], Loss: 1.2583, Accuracy: 93.57%\n",
      "✅ Best model saved at epoch 117 with loss 1.2583\n",
      "Epoch [118/150], Loss: 1.2525, Accuracy: 93.85%\n",
      "✅ Best model saved at epoch 118 with loss 1.2525\n",
      "Epoch [119/150], Loss: 1.2408, Accuracy: 94.12%\n",
      "✅ Best model saved at epoch 119 with loss 1.2408\n",
      "Epoch [120/150], Loss: 1.2338, Accuracy: 94.48%\n",
      "✅ Best model saved at epoch 120 with loss 1.2338\n",
      "Epoch [121/150], Loss: 1.2241, Accuracy: 94.81%\n",
      "✅ Best model saved at epoch 121 with loss 1.2241\n",
      "Epoch [122/150], Loss: 1.2126, Accuracy: 95.39%\n",
      "✅ Best model saved at epoch 122 with loss 1.2126\n",
      "Epoch [123/150], Loss: 1.2068, Accuracy: 95.06%\n",
      "✅ Best model saved at epoch 123 with loss 1.2068\n",
      "Epoch [124/150], Loss: 1.1987, Accuracy: 95.97%\n",
      "✅ Best model saved at epoch 124 with loss 1.1987\n",
      "Epoch [125/150], Loss: 1.1945, Accuracy: 95.73%\n",
      "✅ Best model saved at epoch 125 with loss 1.1945\n",
      "Epoch [126/150], Loss: 1.1860, Accuracy: 95.97%\n",
      "✅ Best model saved at epoch 126 with loss 1.1860\n",
      "Epoch [127/150], Loss: 1.1773, Accuracy: 96.41%\n",
      "✅ Best model saved at epoch 127 with loss 1.1773\n",
      "Epoch [128/150], Loss: 1.1737, Accuracy: 96.27%\n",
      "✅ Best model saved at epoch 128 with loss 1.1737\n",
      "Epoch [129/150], Loss: 1.1658, Accuracy: 96.86%\n",
      "✅ Best model saved at epoch 129 with loss 1.1658\n",
      "Epoch [130/150], Loss: 1.1635, Accuracy: 96.58%\n",
      "✅ Best model saved at epoch 130 with loss 1.1635\n",
      "Epoch [131/150], Loss: 1.1620, Accuracy: 96.51%\n",
      "✅ Best model saved at epoch 131 with loss 1.1620\n",
      "Epoch [132/150], Loss: 1.1570, Accuracy: 96.92%\n",
      "✅ Best model saved at epoch 132 with loss 1.1570\n",
      "Epoch [133/150], Loss: 1.1524, Accuracy: 96.80%\n",
      "✅ Best model saved at epoch 133 with loss 1.1524\n",
      "Epoch [134/150], Loss: 1.1479, Accuracy: 97.10%\n",
      "✅ Best model saved at epoch 134 with loss 1.1479\n",
      "Epoch [135/150], Loss: 1.1434, Accuracy: 97.44%\n",
      "✅ Best model saved at epoch 135 with loss 1.1434\n",
      "Epoch [136/150], Loss: 1.1398, Accuracy: 97.30%\n",
      "✅ Best model saved at epoch 136 with loss 1.1398\n",
      "Epoch [137/150], Loss: 1.1439, Accuracy: 97.21%\n",
      "Epoch [138/150], Loss: 1.1418, Accuracy: 97.40%\n",
      "Epoch [139/150], Loss: 1.1333, Accuracy: 97.32%\n",
      "✅ Best model saved at epoch 139 with loss 1.1333\n",
      "Epoch [140/150], Loss: 1.1319, Accuracy: 97.44%\n",
      "✅ Best model saved at epoch 140 with loss 1.1319\n",
      "Epoch [141/150], Loss: 1.1278, Accuracy: 97.74%\n",
      "✅ Best model saved at epoch 141 with loss 1.1278\n",
      "Epoch [142/150], Loss: 1.1291, Accuracy: 97.66%\n",
      "Epoch [143/150], Loss: 1.1276, Accuracy: 97.80%\n",
      "✅ Best model saved at epoch 143 with loss 1.1276\n",
      "Epoch [144/150], Loss: 1.1272, Accuracy: 97.81%\n",
      "✅ Best model saved at epoch 144 with loss 1.1272\n",
      "Epoch [145/150], Loss: 1.1251, Accuracy: 97.62%\n",
      "✅ Best model saved at epoch 145 with loss 1.1251\n",
      "Epoch [146/150], Loss: 1.1268, Accuracy: 97.81%\n",
      "Epoch [147/150], Loss: 1.1284, Accuracy: 97.59%\n",
      "Epoch [148/150], Loss: 1.1278, Accuracy: 97.45%\n",
      "Epoch [149/150], Loss: 1.1253, Accuracy: 97.71%\n",
      "Epoch [150/150], Loss: 1.1248, Accuracy: 97.64%\n",
      "✅ Best model saved at epoch 150 with loss 1.1248\n",
      "Training completed! Best model saved at: /home/haggenmueller/asl_detection/machine_learning/models/lstm/best_lstm_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3023638/562655487.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set: Loss = 1.7860, Accuracy = 76.00%\n",
      "Test Set: Loss = 1.7130, Accuracy = 76.24%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "\n",
    "# Paths\n",
    "LABELS_PATH = \"/home/haggenmueller/asl_detection/machine_learning/models/lstm/label_to_index.json\"\n",
    "DATA_DIR = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/keypoints\"\n",
    "MODEL_PATH = \"/home/haggenmueller/asl_detection/machine_learning/models/lstm/best_lstm_model.pth\"\n",
    "\n",
    "# Parameters\n",
    "SEQUENCE_LENGTH = 102\n",
    "INPUT_SIZE = 225\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 150  \n",
    "LR = 0.001  \n",
    "PATIENCE = 5\n",
    "\n",
    "# Load labels\n",
    "with open(LABELS_PATH, \"r\") as f:\n",
    "    label_to_index = json.load(f)\n",
    "    index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "    NUM_CLASSES = len(label_to_index)\n",
    "\n",
    "# Dataset class\n",
    "class ASLDataset(Dataset):\n",
    "    def __init__(self, samples, sequence_length):\n",
    "        self.samples = samples\n",
    "        self.sequence_length = sequence_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path, label = self.samples[idx]\n",
    "        keypoints = np.load(file_path)\n",
    "        \n",
    "        if keypoints.shape[0] < self.sequence_length:\n",
    "            pad = np.zeros((self.sequence_length - keypoints.shape[0], keypoints.shape[1]))\n",
    "            keypoints = np.vstack((keypoints, pad))\n",
    "        else:\n",
    "            keypoints = keypoints[:self.sequence_length]\n",
    "        \n",
    "        # Normalize keypoints\n",
    "        keypoints = (keypoints - keypoints.mean()) / keypoints.std()\n",
    "        \n",
    "        return torch.tensor(keypoints, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# Load and split dataset\n",
    "label_samples = defaultdict(list)\n",
    "for file in os.listdir(DATA_DIR):\n",
    "    if file.endswith(\".npy\"):\n",
    "        filename_parts = file.split(\"_\")\n",
    "        label_name = filename_parts[1]\n",
    "        if label_name in label_to_index:\n",
    "            label_samples[label_name].append(os.path.join(DATA_DIR, file))\n",
    "\n",
    "train_samples, val_samples, test_samples = [], [], []\n",
    "\n",
    "for label, files in label_samples.items():\n",
    "    np.random.shuffle(files)\n",
    "    num_total = len(files)\n",
    "    \n",
    "    num_train = int(0.70 * num_total)\n",
    "    num_val = int(0.15 * num_total)\n",
    "    num_test = num_total - num_train - num_val\n",
    "\n",
    "    train_samples.extend([(f, label_to_index[label]) for f in files[:num_train]])\n",
    "    val_samples.extend([(f, label_to_index[label]) for f in files[num_train:num_train + num_val]])\n",
    "    test_samples.extend([(f, label_to_index[label]) for f in files[num_train + num_val:]])\n",
    "\n",
    "train_dataset = ASLDataset(train_samples, SEQUENCE_LENGTH)\n",
    "val_dataset = ASLDataset(val_samples, SEQUENCE_LENGTH)\n",
    "test_dataset = ASLDataset(test_samples, SEQUENCE_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.dropout(out[:, -1, :])  # Extract last time step\n",
    "        return self.fc(out)\n",
    "\n",
    "# Initialize model\n",
    "model = LSTMModel(input_size=INPUT_SIZE, hidden_size=256, num_layers=2, num_classes=NUM_CLASSES)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.1)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if \"weight_ih\" in name or \"weight_hh\" in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif \"bias\" in name:\n",
    "                nn.init.constant_(param, 0.1)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "# Training loop\n",
    "best_loss = float(\"inf\")\n",
    "stopping_counter = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    for keypoints, labels in train_loader:\n",
    "        keypoints, labels = keypoints.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(keypoints)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(torch.softmax(outputs, dim=1), 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    scheduler.step()\n",
    "    \n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        stopping_counter = 0\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"✅ Best model saved at epoch {epoch+1} with loss {avg_loss:.4f}\")\n",
    "    else:\n",
    "        stopping_counter += 1\n",
    "        if stopping_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Training completed! Best model saved at:\", MODEL_PATH)\n",
    "\n",
    "# Testing the model\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "def evaluate(loader, name):\n",
    "    correct, total, loss = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for keypoints, labels in loader:\n",
    "            keypoints, labels = keypoints.to(device), labels.to(device)\n",
    "            outputs = model(keypoints)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(torch.softmax(outputs, dim=1), 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"{name} Set: Loss = {loss / len(loader):.4f}, Accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "evaluate(val_loader, \"Validation\")\n",
    "evaluate(test_loader, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(os.listdir(DATA_DIR)):\n",
    "    if file.endswith(\".npy\") and i < 10:\n",
    "        filename_parts = file.split(\"_\")\n",
    "        print(f\"File: {file} → Extracted Label: {filename_parts[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'I': 0, 'about': 1, 'accident': 2, 'add': 3, 'africa': 4, 'after': 5, 'ago': 6, 'alone': 7, 'always': 8, 'animal': 9, 'any': 10, 'apple': 11, 'appointment': 12, 'argue': 13, 'ask': 14, 'australia': 15, 'baby': 16, 'bad': 17, 'balance': 18, 'banana': 19, 'bar': 20, 'barely': 21, 'basketball': 22, 'beard': 23, 'bed': 24, 'before': 25, 'between': 26, 'bird': 27, 'black': 28, 'bowling': 29, 'brother': 30, 'buy': 31, 'california': 32, 'call': 33, 'can': 34, 'candy': 35, 'careful': 36, 'carrot': 37, 'cat': 38, 'champion': 39, 'change': 40, 'chat': 41, 'cheat': 42, 'check': 43, 'city': 44, 'cold': 45, 'computer': 46, 'convince': 47, 'cool': 48, 'corn': 49, 'cousin': 50, 'cow': 51, 'cry': 52, 'dark': 53, 'daughter': 54, 'day': 55, 'deaf': 56, 'decide': 57, 'decorate': 58, 'delay': 59, 'delicious': 60, 'dive': 61, 'dog': 62, 'drink': 63, 'drop': 64, 'eat': 65, 'environment': 66, 'family': 67, 'far': 68, 'fast': 69, 'fat': 70, 'fault': 71, 'feel': 72, 'few': 73, 'finish': 74, 'first': 75, 'fish': 76, 'follow': 77, 'for': 78, 'from': 79, 'full': 80, 'future': 81, 'girl': 82, 'give': 83, 'glasses': 84, 'go': 85, 'good': 86, 'government': 87, 'graduate': 88, 'grammar': 89, 'great': 90, 'happy': 91, 'have': 92, 'headache': 93, 'hear': 94, 'hearing': 95, 'help': 96, 'hesheit': 97, 'hope': 98, 'hot': 99, 'how': 100, 'improve': 101, 'inform': 102, 'interest': 103, 'know': 104, 'language': 105, 'last': 106, 'later': 107, 'laugh': 108, 'learn': 109, 'leave': 110, 'letter': 111, 'like': 112, 'list': 113, 'look': 114, 'love': 115, 'make': 116, 'man': 117, 'many': 118, 'me': 119, 'meet': 120, 'more': 121, 'most': 122, 'mother': 123, 'move': 124, 'near': 125, 'necklace': 126, 'need': 127, 'never': 128, 'new': 129, 'no': 130, 'now': 131, 'office': 132, 'on': 133, 'orange': 134, 'party': 135, 'past': 136, 'perspective': 137, 'pink': 138, 'pizza': 139, 'play': 140, 'postpone': 141, 'presentation': 142, 'president': 143, 'pull': 144, 'ready': 145, 'room': 146, 'same': 147, 'sandwich': 148, 'say': 149, 'school': 150, 'score': 151, 'secretary': 152, 'see': 153, 'shirt': 154, 'short': 155, 'show': 156, 'sick': 157, 'silly': 158, 'sleep': 159, 'some': 160, 'son': 161, 'speech': 162, 'spin': 163, 'stay': 164, 'study': 165, 'sweet': 166, 'take': 167, 'tall': 168, 'tell': 169, 'thanksgiving': 170, 'their': 171, 'thin': 172, 'think': 173, 'thursday': 174, 'tiger': 175, 'toast': 176, 'today': 177, 'trade': 178, 'try': 179, 'ugly': 180, 'under': 181, 'upset': 182, 'very': 183, 'visit': 184, 'vomit': 185, 'wait': 186, 'walk': 187, 'want': 188, 'water': 189, 'we': 190, 'week': 191, 'wet': 192, 'what': 193, 'white': 194, 'who': 195, 'why': 196, 'wish': 197, 'with': 198, 'woman': 199, 'wonderfull': 200, 'work': 201, 'wow': 202, 'write': 203, 'year': 204, 'yes': 205, 'yesterday': 206, 'you': 207, 'your': 208}\n"
     ]
    }
   ],
   "source": [
    "print(\"Label Mapping:\", label_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0: Shape = torch.Size([102, 225]), Label = 157\n",
      "Sample 1: Shape = torch.Size([102, 225]), Label = 157\n",
      "Sample 2: Shape = torch.Size([102, 225]), Label = 157\n",
      "Sample 3: Shape = torch.Size([102, 225]), Label = 157\n",
      "Sample 4: Shape = torch.Size([102, 225]), Label = 157\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    sample, label = train_dataset[i]\n",
    "    print(f\"Sample {i}: Shape = {sample.shape}, Label = {label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
