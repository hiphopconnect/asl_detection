{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global expected lengths: {'pose': 0, 'face': 0, 'left_hand': 0, 'right_hand': 0}\n",
      "Number of files loaded: 0\n"
     ]
    }
   ],
   "source": [
    "# Set folder path containing JSON files\n",
    "folder_path = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/keypoints\" \n",
    "\n",
    "# List all JSON files in the folder\n",
    "json_files = glob.glob(os.path.join(folder_path, \"*.json\"))\n",
    "\n",
    "# Function to get maximum length for a part within keypoints of one file\n",
    "def get_max_length(keypoints, part):\n",
    "    lengths = []\n",
    "    for kp in keypoints:\n",
    "        if kp.get(part) is not None:\n",
    "            lengths.append(np.array(kp[part]).flatten().shape[0])\n",
    "    return max(lengths) if lengths else 0\n",
    "\n",
    "# Compute global expected lengths for each part across all files\n",
    "parts = ['pose', 'face', 'left_hand', 'right_hand']\n",
    "global_expected = {part: 0 for part in parts}\n",
    "all_data = []\n",
    "all_labels = []\n",
    "for file in json_files:\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    all_data.append(data)\n",
    "    all_labels.append(data[\"gloss\"])\n",
    "    for part in parts:\n",
    "        max_len = get_max_length(data[\"keypoints\"], part)\n",
    "        if max_len > global_expected[part]:\n",
    "            global_expected[part] = max_len\n",
    "\n",
    "print(\"Global expected lengths:\", global_expected)\n",
    "print(\"Number of files loaded:\", len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "received an empty list of sequences",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     filtered_labels\u001b[38;5;241m.\u001b[39mappend(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgloss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Pad sequences (batch, seq, feature)\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m X_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPadded features shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_tensor\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Normalize features (using overall mean and std)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/asl_detection/lib/python3.10/site-packages/torch/nn/utils/rnn.py:478\u001b[0m, in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value, padding_side)\u001b[0m\n\u001b[1;32m    474\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: received an empty list of sequences"
     ]
    }
   ],
   "source": [
    "# Extract features from keypoints using global expected lengths\n",
    "def extract_features(keypoints, expected_lengths):\n",
    "    features = []\n",
    "    for kp in keypoints:\n",
    "        frame_features = []\n",
    "        for part in parts:\n",
    "            # Check if the part exists and is non-empty\n",
    "            if kp.get(part) is not None and len(kp[part]) > 0:\n",
    "                vals = np.array(kp[part]).flatten().tolist()\n",
    "                frame_features.extend(vals)\n",
    "            else:\n",
    "                frame_features.extend([0] * expected_lengths[part])\n",
    "        features.append(frame_features)\n",
    "    return np.array(features)\n",
    "\n",
    "# Process each file to get a list of feature tensors (timesteps x feature_dim)\n",
    "feature_list = []\n",
    "filtered_labels = []\n",
    "for data in all_data:\n",
    "    if not data[\"keypoints\"]:\n",
    "        continue\n",
    "    features = extract_features(data[\"keypoints\"], global_expected)\n",
    "    if features.size == 0:\n",
    "        continue\n",
    "    tensor_feat = torch.tensor(features, dtype=torch.float32)\n",
    "    feature_list.append(tensor_feat)\n",
    "    filtered_labels.append(data[\"gloss\"])\n",
    "\n",
    "# Pad sequences (batch, seq, feature)\n",
    "X_tensor = pad_sequence(feature_list, batch_first=True)\n",
    "print(\"Padded features shape:\", X_tensor.shape)\n",
    "\n",
    "# Normalize features (using overall mean and std)\n",
    "mean = X_tensor.mean()\n",
    "std = X_tensor.std() + 1e-5  # avoid division by zero\n",
    "X_tensor = (X_tensor - mean) / std\n",
    "print(\"Feature tensor normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels from filtered files\n",
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(filtered_labels)\n",
    "y_tensor = torch.tensor(labels_encoded, dtype=torch.long)\n",
    "print(\"Encoded labels:\", labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # out: (batch, timesteps, hidden_size)\n",
    "        # Use the output from the last timestep\n",
    "        out = out[:, -1, :]\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "input_size = X_tensor.shape[2]\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = len(le.classes_)\n",
    "model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# Use a higher learning rate to see faster changes (adjust as needed)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "num_epochs = 30\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Calculate accuracy\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == y_tensor).sum().item()\n",
    "    accuracy = correct / y_tensor.size(0)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"lstm_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(X_tensor)\n",
    "    predicted_classes = torch.argmax(pred, dim=1).numpy()\n",
    "    predicted_labels = le.inverse_transform(predicted_classes)\n",
    "    print(\"Predicted labels:\", predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
