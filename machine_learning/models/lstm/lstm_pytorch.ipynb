{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training via Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"GPU {}: {}\".format(i, torch.cuda.get_device_name(i)))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----- 1. Load Data -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "data_dir = \"/home/haggenmueller/asl_detection/machine_learning/datasets/how2sign/keypoints\"\n",
    "train_json_dir = os.path.join(data_dir, \"train/openpose_output/json\")\n",
    "val_json_dir = os.path.join(data_dir, \"val/openpose_output/json\")\n",
    "test_json_dir = os.path.join(data_dir, \"test/openpose_output/json\")\n",
    "\n",
    "csv_path = \"/home/haggenmueller/asl_detection/machine_learning/datasets/how2sign/english_translation\"\n",
    "train_labels_csv = os.path.join(csv_path, \"how2sign_realigned_train.csv\")\n",
    "val_labels_csv = os.path.join(csv_path, \"how2sign_realigned_val.csv\")\n",
    "test_labels_csv = os.path.join(csv_path, \"how2sign_realigned_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# ----- Training Labels -----\n",
    "train_label_df = pd.read_csv(train_labels_csv, delimiter=\"\\t\")\n",
    "\n",
    "# Create a sorted list of unique SENTENCE_ID values for training\n",
    "unique_train_sentences = sorted(set(train_label_df[\"SENTENCE_ID\"]))\n",
    "# Map original SENTENCE_IDs to 0-indexed IDs for training\n",
    "sentence_to_id_train = {sentence: idx for idx, sentence in enumerate(unique_train_sentences)}\n",
    "\n",
    "# Create mapping: SENTENCE_NAME -> 0-indexed SENTENCE_ID for training\n",
    "label_mapping_train = {\n",
    "    name: sentence_to_id_train[sentence_id] \n",
    "    for name, sentence_id in zip(train_label_df[\"SENTENCE_NAME\"], train_label_df[\"SENTENCE_ID\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Validation Labels -----\n",
    "val_label_df = pd.read_csv(val_labels_csv, delimiter=\"\\t\")\n",
    "\n",
    "# Create a sorted list of unique SENTENCE_ID values for validation\n",
    "unique_val_sentences = sorted(set(val_label_df[\"SENTENCE_ID\"]))\n",
    "# Map original SENTENCE_IDs to 0-indexed IDs for validation\n",
    "sentence_to_id_val = {sentence: idx for idx, sentence in enumerate(unique_val_sentences)}\n",
    "\n",
    "# Create mapping: SENTENCE_NAME -> 0-indexed SENTENCE_ID for validation\n",
    "label_mapping_val = {\n",
    "    name: sentence_to_id_val[sentence_id] \n",
    "    for name, sentence_id in zip(val_label_df[\"SENTENCE_NAME\"], val_label_df[\"SENTENCE_ID\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Test Labels -----\n",
    "test_label_df = pd.read_csv(test_labels_csv, delimiter=\"\\t\")\n",
    "\n",
    "# Create a sorted list of unique SENTENCE_ID values for test\n",
    "unique_test_sentences = sorted(set(test_label_df[\"SENTENCE_ID\"]))\n",
    "# Map original SENTENCE_IDs to 0-indexed IDs for test\n",
    "sentence_to_id_test = {sentence: idx for idx, sentence in enumerate(unique_test_sentences)}\n",
    "\n",
    "# Create mapping: SENTENCE_NAME -> 0-indexed SENTENCE_ID for test\n",
    "label_mapping_test = {\n",
    "    name: sentence_to_id_test[sentence_id] \n",
    "    for name, sentence_id in zip(test_label_df[\"SENTENCE_NAME\"], test_label_df[\"SENTENCE_ID\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Print examples to check the mappings\n",
    "print(\"Train mapping example:\", list(label_mapping_train.items())[:5])\n",
    "print(\"Val mapping example:\", list(label_mapping_val.items())[:5])\n",
    "print(\"Test mapping example:\", list(label_mapping_test.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def load_keypoints(json_folder, max_frames=100):\n",
    "    \"\"\"\n",
    "    Load keypoints from JSON files and return a padded sequence as a tensor.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Shape (max_frames, feature_dim)\n",
    "    \"\"\"\n",
    "    keypoints_sequence = []\n",
    "    required_dim = 411  # Fixed feature dimension\n",
    "\n",
    "    for frame_file in sorted(os.listdir(json_folder)):\n",
    "        frame_path = os.path.join(json_folder, frame_file)\n",
    "        with open(frame_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if \"people\" in data and len(data[\"people\"]) > 0:\n",
    "            person = data[\"people\"][0]  # First detected person\n",
    "\n",
    "            # Extract keypoints from different parts\n",
    "            pose = person.get(\"pose_keypoints_2d\", [])\n",
    "            face = person.get(\"face_keypoints_2d\", [])\n",
    "            left_hand = person.get(\"hand_left_keypoints_2d\", [])\n",
    "            right_hand = person.get(\"hand_right_keypoints_2d\", [])\n",
    "            \n",
    "            # Combine all keypoints\n",
    "            full_keypoints = pose + face + left_hand + right_hand\n",
    "            \n",
    "            # Pad or truncate to required_dim\n",
    "            if len(full_keypoints) < required_dim:\n",
    "                full_keypoints += [0.0] * (required_dim - len(full_keypoints))\n",
    "            else:\n",
    "                full_keypoints = full_keypoints[:required_dim]\n",
    "            \n",
    "            keypoints_tensor = torch.tensor(full_keypoints, dtype=torch.float32)\n",
    "            keypoints_sequence.append(keypoints_tensor)\n",
    "    \n",
    "    # If no frames were loaded, return zeros\n",
    "    if not keypoints_sequence:\n",
    "        return torch.zeros((max_frames, required_dim), dtype=torch.float32)\n",
    "    \n",
    "    # Stack tensors: (num_frames, feature_dim)\n",
    "    seq_tensor = torch.stack(keypoints_sequence)\n",
    "    \n",
    "    # Pad or truncate to max_frames\n",
    "    if seq_tensor.shape[0] < max_frames:\n",
    "        padded_sequence = torch.zeros((max_frames, required_dim), dtype=torch.float32)\n",
    "        padded_sequence[:seq_tensor.shape[0]] = seq_tensor\n",
    "    else:\n",
    "        padded_sequence = seq_tensor[:max_frames]\n",
    "    \n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Maximum number of frames per sequence (set based on dataset analysis)\n",
    "MAX_FRAMES = 200  \n",
    "\n",
    "def pad_or_truncate(sequence, max_frames=MAX_FRAMES):\n",
    "    \"\"\"Pads or truncates the sequence tensor to ensure a fixed length.\"\"\"\n",
    "    num_frames, num_features = sequence.shape\n",
    "    if num_frames < max_frames:\n",
    "        pad = torch.zeros((max_frames - num_frames, num_features),\n",
    "                          dtype=sequence.dtype, device=sequence.device)\n",
    "        sequence = torch.cat((sequence, pad), dim=0)\n",
    "    else:\n",
    "        sequence = sequence[:max_frames]\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(json_dir, mapping, sentence_to_id, max_frames=MAX_FRAMES):\n",
    "    X_data, y_labels = [], []\n",
    "    for sentence_name in os.listdir(json_dir):\n",
    "        sentence_folder = os.path.join(json_dir, sentence_name)\n",
    "        if os.path.isdir(sentence_folder) and sentence_name in mapping:\n",
    "            keypoints_sequence = load_keypoints(sentence_folder)\n",
    "            keypoints_sequence = pad_or_truncate(keypoints_sequence, max_frames)\n",
    "            X_data.append(keypoints_sequence)\n",
    "            \n",
    "            label = mapping.get(sentence_name, None)\n",
    "            if str(label) in sentence_to_id:\n",
    "                y_labels.append(sentence_to_id[label])\n",
    "    if not X_data:\n",
    "        print(f\"No data found in {json_dir}\")\n",
    "    X_data = torch.stack(X_data)\n",
    "    y_labels = torch.tensor(y_labels, dtype=torch.long)\n",
    "    return X_data, y_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----- 2. Prepare Data for PyTorch -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data for training\n",
    "X_train, y_train = process_data(train_json_dir, label_mapping_train, sentence_to_id_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train samples:\", X_train.shape[0])\n",
    "print(\"y_train samples:\", len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data for validation \n",
    "X_val, y_val = process_data(val_json_dir, label_mapping_val, sentence_to_id_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data for testing\n",
    "X_test, y_test = process_data(test_json_dir, label_mapping_test, sentence_to_id_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for batch processing\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val, y_val), batch_size=16, shuffle=False)\n",
    "test_loader  = DataLoader(TensorDataset(X_test, y_test), batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----- 3. Define LSTM Model -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Define an LSTM-based model for sequence classification\n",
    "class SignLanguageLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=411, hidden_dim=256, num_layers=2, output_dim=30814, dropout=0.3):\n",
    "        super(SignLanguageLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Dropout check (PyTorch does not allow dropout for a single-layer LSTM)\n",
    "        dropout = dropout if num_layers > 1 else 0\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        if lengths is not None:\n",
    "            # Pack the sequence to ignore padded frames\n",
    "            packed_input = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "            packed_output, _ = self.lstm(packed_input)\n",
    "            lstm_out, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "            # Extract the last valid output for each sequence\n",
    "            last_outputs = torch.stack([lstm_out[i, length-1, :] for i, length in enumerate(lengths)])\n",
    "        else:\n",
    "            lstm_out, _ = self.lstm(x)\n",
    "            last_outputs = lstm_out[:, -1, :]\n",
    "            \n",
    "        return self.fc(last_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_dim = 411            # Number of keypoints per frame\n",
    "hidden_dim = 256           # Number of hidden units in LSTM\n",
    "num_layers = 2             # Number of LSTM layers\n",
    "output_dim = len(set(label_mapping_train))  # Number of classes (0-indexed)\n",
    "dropout = 0.3              # Dropout for regularization\n",
    "\n",
    "# Optionally disable cuDNN for debugging purposes\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "# Create model and move to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"device: \", device)\n",
    "# device = torch.device(\"cpu\")\n",
    "model = SignLanguageLSTM(input_dim, hidden_dim, num_layers, output_dim, dropout).to(device)\n",
    "\n",
    "# Define loss function (CrossEntropyLoss for classification)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer (Adam works well for LSTMs)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Initialize LR scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a single batch before training\n",
    "X_batch, y_batch = next(iter(train_loader))\n",
    "X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "print(\"y_batch min:\", y_batch.min().item(), \"y_batch max:\", y_batch.max().item())\n",
    "outputs = model(X_batch)\n",
    "print(\"Output shape:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----- 4. Training -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "num_epochs = 200  # Adjust as needed\n",
    "patience = 10   # Early stopping patience\n",
    "best_val_loss = float('inf')\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # Validierungsschleife (vorausgesetzt, du hast einen val_loader)\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_val, y_val in val_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            outputs_val = model(X_val)\n",
    "            loss_val = criterion(outputs_val, y_val)\n",
    "            total_val_loss += loss_val.item()\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    # LR-Scheduler: Update based on Validation Loss\n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    # Early Stopping: Prüfe, ob sich der Validierungs-Loss verbessert hat\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----- 5. Save Model & Evaluate -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Save only state_dict\n",
    "torch.save(model.state_dict(), \"sign_language_lstm_state.pth\")\n",
    "\n",
    "# Then later load it into a model instance\n",
    "model = SignLanguageLSTM(input_dim, hidden_dim, num_layers, output_dim, dropout).to(device)\n",
    "model.load_state_dict(torch.load(\"sign_language_lstm_state.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----- 6. Testing & Inference -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sample_input):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Ensure input is a PyTorch tensor\n",
    "    if not isinstance(sample_input, torch.Tensor):\n",
    "        sample_input = torch.tensor(sample_input, dtype=torch.float32)\n",
    "    \n",
    "    sample_input = sample_input.unsqueeze(0).to(device)  # Add batch dimension and move to correct device\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        output = model(sample_input)\n",
    "        predicted_label = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Example usage with test data\n",
    "# Ensure that X_test is not empty; here we take the first sample\n",
    "sample_idx = 0  # or any valid index in the test set\n",
    "sample_input = X_test[sample_idx]\n",
    "predicted_label = predict(model, sample_input)\n",
    "print(f\"Predicted Label (Test Data): {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
