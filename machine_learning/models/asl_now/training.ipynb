{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Daten...\n",
      "Initialisiere Modell auf cpu...\n",
      "Training mit neuem Modell gestartet.\n",
      "Starte Training...\n",
      "Neues bestes Modell gespeichert mit Accuracy: 99.00%\n",
      "Epoch 1/30:\n",
      "Train Loss: 0.4618, Train Acc: 90.86%\n",
      "Val Loss: 0.0833, Val Acc: 99.00%\n",
      "--------------------------------------------------\n",
      "Epoch 2/30:\n",
      "Train Loss: 0.0730, Train Acc: 98.47%\n",
      "Val Loss: 0.4325, Val Acc: 84.86%\n",
      "--------------------------------------------------\n",
      "Epoch 3/30:\n",
      "Train Loss: 0.0610, Train Acc: 98.37%\n",
      "Val Loss: 0.2643, Val Acc: 91.96%\n",
      "--------------------------------------------------\n",
      "Epoch 4/30:\n",
      "Train Loss: 0.0455, Train Acc: 98.75%\n",
      "Val Loss: 0.9039, Val Acc: 76.33%\n",
      "--------------------------------------------------\n",
      "Neues bestes Modell gespeichert mit Accuracy: 99.73%\n",
      "Epoch 5/30:\n",
      "Train Loss: 0.0524, Train Acc: 98.48%\n",
      "Val Loss: 0.0203, Val Acc: 99.73%\n",
      "--------------------------------------------------\n",
      "Epoch 6/30:\n",
      "Train Loss: 0.0433, Train Acc: 98.76%\n",
      "Val Loss: 0.0485, Val Acc: 98.17%\n",
      "--------------------------------------------------\n",
      "Epoch 7/30:\n",
      "Train Loss: 0.0435, Train Acc: 98.62%\n",
      "Val Loss: 0.0134, Val Acc: 99.63%\n",
      "--------------------------------------------------\n",
      "Epoch 8/30:\n",
      "Train Loss: 0.0423, Train Acc: 98.64%\n",
      "Val Loss: 0.0505, Val Acc: 98.47%\n",
      "--------------------------------------------------\n",
      "Epoch 9/30:\n",
      "Train Loss: 0.0318, Train Acc: 99.01%\n",
      "Val Loss: 0.0693, Val Acc: 97.10%\n",
      "--------------------------------------------------\n",
      "Epoch 10/30:\n",
      "Train Loss: 0.0431, Train Acc: 98.60%\n",
      "Val Loss: 0.0098, Val Acc: 99.73%\n",
      "--------------------------------------------------\n",
      "Epoch 11/30:\n",
      "Train Loss: 0.0428, Train Acc: 98.66%\n",
      "Val Loss: 0.2201, Val Acc: 93.53%\n",
      "--------------------------------------------------\n",
      "Neues bestes Modell gespeichert mit Accuracy: 99.97%\n",
      "Epoch 12/30:\n",
      "Train Loss: 0.0432, Train Acc: 98.51%\n",
      "Val Loss: 0.0020, Val Acc: 99.97%\n",
      "--------------------------------------------------\n",
      "Epoch 13/30:\n",
      "Train Loss: 0.0418, Train Acc: 98.60%\n",
      "Val Loss: 0.0060, Val Acc: 99.73%\n",
      "--------------------------------------------------\n",
      "Epoch 14/30:\n",
      "Train Loss: 0.0461, Train Acc: 98.51%\n",
      "Val Loss: 0.0031, Val Acc: 99.97%\n",
      "--------------------------------------------------\n",
      "Epoch 15/30:\n",
      "Train Loss: 0.0451, Train Acc: 98.46%\n",
      "Val Loss: 1.9538, Val Acc: 59.92%\n",
      "--------------------------------------------------\n",
      "Epoch 16/30:\n",
      "Train Loss: 0.0445, Train Acc: 98.48%\n",
      "Val Loss: 0.0234, Val Acc: 99.33%\n",
      "--------------------------------------------------\n",
      "Epoch 17/30:\n",
      "Train Loss: 0.0509, Train Acc: 98.30%\n",
      "Val Loss: 0.0315, Val Acc: 98.57%\n",
      "--------------------------------------------------\n",
      "Epoch 18/30:\n",
      "Train Loss: 0.0473, Train Acc: 98.29%\n",
      "Val Loss: 0.0083, Val Acc: 99.77%\n",
      "--------------------------------------------------\n",
      "Epoch 19/30:\n",
      "Train Loss: 0.0435, Train Acc: 98.61%\n",
      "Val Loss: 0.0010, Val Acc: 99.97%\n",
      "--------------------------------------------------\n",
      "Epoch 20/30:\n",
      "Train Loss: 0.0339, Train Acc: 98.91%\n",
      "Val Loss: 0.0028, Val Acc: 99.83%\n",
      "--------------------------------------------------\n",
      "Neues bestes Modell gespeichert mit Accuracy: 100.00%\n",
      "Epoch 21/30:\n",
      "Train Loss: 0.0364, Train Acc: 98.80%\n",
      "Val Loss: 0.0002, Val Acc: 100.00%\n",
      "--------------------------------------------------\n",
      "Epoch 22/30:\n",
      "Train Loss: 0.0359, Train Acc: 98.80%\n",
      "Val Loss: 0.0269, Val Acc: 99.07%\n",
      "--------------------------------------------------\n",
      "Epoch 23/30:\n",
      "Train Loss: 0.0284, Train Acc: 99.08%\n",
      "Val Loss: 0.0012, Val Acc: 99.93%\n",
      "--------------------------------------------------\n",
      "Epoch 24/30:\n",
      "Train Loss: 0.0341, Train Acc: 98.82%\n",
      "Val Loss: 0.0007, Val Acc: 99.97%\n",
      "--------------------------------------------------\n",
      "Epoch 25/30:\n",
      "Train Loss: 0.0382, Train Acc: 98.66%\n",
      "Val Loss: 0.0018, Val Acc: 99.90%\n",
      "--------------------------------------------------\n",
      "Epoch 26/30:\n",
      "Train Loss: 0.0348, Train Acc: 98.82%\n",
      "Val Loss: 0.0007, Val Acc: 99.97%\n",
      "--------------------------------------------------\n",
      "Epoch 27/30:\n",
      "Train Loss: 0.0319, Train Acc: 98.92%\n",
      "Val Loss: 0.0015, Val Acc: 99.97%\n",
      "--------------------------------------------------\n",
      "Epoch 28/30:\n",
      "Train Loss: 0.0287, Train Acc: 99.12%\n",
      "Val Loss: 0.0011, Val Acc: 99.97%\n",
      "--------------------------------------------------\n",
      "Epoch 29/30:\n",
      "Train Loss: 0.0318, Train Acc: 98.94%\n",
      "Val Loss: 0.0008, Val Acc: 99.97%\n",
      "--------------------------------------------------\n",
      "Epoch 30/30:\n",
      "Train Loss: 0.0334, Train Acc: 98.87%\n",
      "Val Loss: 0.0003, Val Acc: 100.00%\n",
      "--------------------------------------------------\n",
      "Lade bestes Modell für finale Evaluation...\n",
      "\n",
      "Beste Validierungs-Accuracy: 100.00%\n",
      "Verbesserung gegenüber initialem Modell: +100.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Konstanten\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_PATH = '/home/geiger/asl_detection/machine_learning/models/asl_now/best_model.pth'  # Pfad zum bestehenden Modell\n",
    "\n",
    "# Dataset-Klasse\n",
    "class HandSignDataset(Dataset):\n",
    "    def __init__(self, keypoints, labels):\n",
    "        self.keypoints = torch.FloatTensor(keypoints)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keypoints)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.keypoints[idx], self.labels[idx]\n",
    "\n",
    "# Modell-Definition\n",
    "class HandSignNet(nn.Module):\n",
    "    def __init__(self, num_classes=24):\n",
    "        super(HandSignNet, self).__init__()\n",
    "        \n",
    "        # Feature Extraction Blocks\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(63, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train')\n",
    "    plt.plot(val_accs, label='Validation')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "def main(load_model=True):\n",
    "    # Setze Seeds für Reproduzierbarkeit\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    # Alphabet-Definition\n",
    "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n",
    "    \n",
    "    # Lade Daten\n",
    "    print(\"Lade Daten...\")\n",
    "    data = np.load('/home/geiger/asl_detection/machine_learning/datasets/asl_now/Keypoints_3/asl_keypoints.npz')\n",
    "    keypoints = data['keypoints']\n",
    "    labels = data['labels']\n",
    "    \n",
    "    # Split Daten\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        keypoints, labels, test_size=0.2, random_state=RANDOM_SEED, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # Erstelle DataLoader\n",
    "    train_dataset = HandSignDataset(X_train, y_train)\n",
    "    val_dataset = HandSignDataset(X_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # Initialisiere Modell und lade vortrainiertes Modell, falls gewünscht\n",
    "    print(f\"Initialisiere Modell auf {DEVICE}...\")\n",
    "    model = HandSignNet().to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "    \n",
    "    initial_val_acc = 0\n",
    "    if load_model and os.path.exists(MODEL_PATH):\n",
    "        print(f\"Lade vortrainiertes Modell von {MODEL_PATH}...\")\n",
    "        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "        print(\"Vortrainiertes Modell erfolgreich geladen!\")\n",
    "        \n",
    "        # Führe eine Validierung mit dem geladenen Modell durch\n",
    "        print(\"Validiere geladenes Modell...\")\n",
    "        initial_val_loss, initial_val_acc, _, _ = validate(model, val_loader, criterion, DEVICE)\n",
    "        print(f\"Initiale Validierungs-Genauigkeit: {initial_val_acc:.2f}%\")\n",
    "    else:\n",
    "        if load_model:\n",
    "            print(f\"Kein vortrainiertes Modell gefunden unter {MODEL_PATH}. Starte mit neuem Modell.\")\n",
    "        else:\n",
    "            print(\"Training mit neuem Modell gestartet.\")\n",
    "    \n",
    "    best_val_acc = initial_val_acc\n",
    "    \n",
    "    # Training\n",
    "    print(\"Starte Training...\")\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion, DEVICE)\n",
    "        \n",
    "        # Learning Rate Anpassung\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Speichere Metriken\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Speichere bestes Modell\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"Neues bestes Modell gespeichert mit Accuracy: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Ausgabe\n",
    "        print(f'Epoch {epoch+1}/{EPOCHS}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    # Lade bestes Modell für finale Evaluation, aber nur wenn es existiert\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        print(\"Lade bestes Modell für finale Evaluation...\")\n",
    "        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "        _, final_acc, final_preds, final_labels = validate(model, val_loader, criterion, DEVICE)\n",
    "        \n",
    "        # Plotte Ergebnisse\n",
    "        plot_training_history(train_losses, val_losses, train_accs, val_accs)\n",
    "        plot_confusion_matrix(final_labels, final_preds, alphabet)\n",
    "    else:\n",
    "        print(\"Kein gespeichertes Modell gefunden. Überspringe finale Evaluation.\")\n",
    "        # Verwende die Ergebnisse der letzten Epoche für die Plots\n",
    "        final_preds = val_preds\n",
    "        final_labels = val_labels\n",
    "        plot_training_history(train_losses, val_losses, train_accs, val_accs)\n",
    "        if len(final_labels) > 0:  # Nur wenn wir Validierungsdaten haben\n",
    "            plot_confusion_matrix(final_labels, final_preds, alphabet)\n",
    "    \n",
    "    print(f\"\\nBeste Validierungs-Accuracy: {best_val_acc:.2f}%\")\n",
    "    if best_val_acc > initial_val_acc:\n",
    "        print(f\"Verbesserung gegenüber initialem Modell: +{best_val_acc - initial_val_acc:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Prüfe, ob ein Kommandozeilenargument übergeben wurde\n",
    "    load_model = False  # Standard: Lade vorhandenes Modell\n",
    "    \n",
    "    main(load_model) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl_detection_mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
