{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lade Daten...\n",
      "Initialisiere Modell auf cpu...\n",
      "Training mit neuem Modell gestartet.\n",
      "Starte Training...\n",
      "Neues bestes Modell gespeichert mit Accuracy: 91.56%\n",
      "Epoch 1/40:\n",
      "Train Loss: 2.2902, Train Acc: 39.06%\n",
      "Val Loss: 1.2998, Val Acc: 91.56%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Neues bestes Modell gespeichert mit Accuracy: 96.93%\n",
      "Epoch 2/40:\n",
      "Train Loss: 1.6296, Train Acc: 64.05%\n",
      "Val Loss: 1.0288, Val Acc: 96.93%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 3/40:\n",
      "Train Loss: 1.4668, Train Acc: 70.50%\n",
      "Val Loss: 0.9412, Val Acc: 94.33%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Neues bestes Modell gespeichert mit Accuracy: 97.70%\n",
      "Epoch 4/40:\n",
      "Train Loss: 1.3850, Train Acc: 74.37%\n",
      "Val Loss: 0.9111, Val Acc: 97.70%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Neues bestes Modell gespeichert mit Accuracy: 98.17%\n",
      "Epoch 5/40:\n",
      "Train Loss: 1.3255, Train Acc: 76.44%\n",
      "Val Loss: 0.8503, Val Acc: 98.17%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Neues bestes Modell gespeichert mit Accuracy: 99.17%\n",
      "Epoch 6/40:\n",
      "Train Loss: 1.3140, Train Acc: 76.64%\n",
      "Val Loss: 0.8328, Val Acc: 99.17%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Neues bestes Modell gespeichert mit Accuracy: 99.53%\n",
      "Epoch 7/40:\n",
      "Train Loss: 1.2808, Train Acc: 77.93%\n",
      "Val Loss: 0.8155, Val Acc: 99.53%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 8/40:\n",
      "Train Loss: 1.2690, Train Acc: 78.42%\n",
      "Val Loss: 0.8211, Val Acc: 99.13%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 9/40:\n",
      "Train Loss: 1.2635, Train Acc: 77.97%\n",
      "Val Loss: 0.8078, Val Acc: 96.20%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 10/40:\n",
      "Train Loss: 1.2582, Train Acc: 78.91%\n",
      "Val Loss: 0.7860, Val Acc: 99.13%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 11/40:\n",
      "Train Loss: 1.2479, Train Acc: 79.27%\n",
      "Val Loss: 0.8131, Val Acc: 98.23%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 12/40:\n",
      "Train Loss: 1.2460, Train Acc: 78.47%\n",
      "Val Loss: 0.7852, Val Acc: 99.47%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 13/40:\n",
      "Train Loss: 1.2453, Train Acc: 78.64%\n",
      "Val Loss: 0.7847, Val Acc: 99.17%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 14/40:\n",
      "Train Loss: 1.2459, Train Acc: 78.71%\n",
      "Val Loss: 0.8040, Val Acc: 97.60%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Neues bestes Modell gespeichert mit Accuracy: 99.60%\n",
      "Epoch 15/40:\n",
      "Train Loss: 1.2455, Train Acc: 78.56%\n",
      "Val Loss: 0.7937, Val Acc: 99.60%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 16/40:\n",
      "Train Loss: 1.2478, Train Acc: 78.90%\n",
      "Val Loss: 0.7792, Val Acc: 99.60%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 17/40:\n",
      "Train Loss: 1.2348, Train Acc: 79.05%\n",
      "Val Loss: 0.7837, Val Acc: 99.47%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 18/40:\n",
      "Train Loss: 1.2498, Train Acc: 78.71%\n",
      "Val Loss: 0.7852, Val Acc: 98.93%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 19/40:\n",
      "Train Loss: 1.2672, Train Acc: 77.88%\n",
      "Val Loss: 0.8044, Val Acc: 99.20%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 20/40:\n",
      "Train Loss: 1.2582, Train Acc: 78.20%\n",
      "Val Loss: 0.7986, Val Acc: 99.37%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Neues bestes Modell gespeichert mit Accuracy: 99.70%\n",
      "Epoch 21/40:\n",
      "Train Loss: 1.2477, Train Acc: 78.23%\n",
      "Val Loss: 0.7734, Val Acc: 99.70%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 22/40:\n",
      "Train Loss: 1.2561, Train Acc: 78.16%\n",
      "Val Loss: 0.7891, Val Acc: 99.27%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 23/40:\n",
      "Train Loss: 1.2571, Train Acc: 78.13%\n",
      "Val Loss: 0.7899, Val Acc: 99.30%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 24/40:\n",
      "Train Loss: 1.2619, Train Acc: 78.23%\n",
      "Val Loss: 0.7869, Val Acc: 97.00%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 25/40:\n",
      "Train Loss: 1.2584, Train Acc: 77.55%\n",
      "Val Loss: 0.7912, Val Acc: 99.57%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 26/40:\n",
      "Train Loss: 1.2659, Train Acc: 77.81%\n",
      "Val Loss: 0.8173, Val Acc: 98.63%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 27/40:\n",
      "Train Loss: 1.2610, Train Acc: 78.15%\n",
      "Val Loss: 0.7998, Val Acc: 99.20%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 28/40:\n",
      "Train Loss: 1.2690, Train Acc: 77.51%\n",
      "Val Loss: 0.8312, Val Acc: 94.20%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 29/40:\n",
      "Train Loss: 1.2574, Train Acc: 78.28%\n",
      "Val Loss: 0.7867, Val Acc: 97.60%\n",
      "LR: 0.000500\n",
      "--------------------------------------------------\n",
      "Epoch 30/40:\n",
      "Train Loss: 1.2848, Train Acc: 76.99%\n",
      "Val Loss: 0.8144, Val Acc: 96.80%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Epoch 31/40:\n",
      "Train Loss: 1.2575, Train Acc: 78.05%\n",
      "Val Loss: 0.7715, Val Acc: 99.40%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Epoch 32/40:\n",
      "Train Loss: 1.2563, Train Acc: 78.18%\n",
      "Val Loss: 0.7634, Val Acc: 98.97%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Epoch 33/40:\n",
      "Train Loss: 1.2476, Train Acc: 78.50%\n",
      "Val Loss: 0.7697, Val Acc: 99.53%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Epoch 34/40:\n",
      "Train Loss: 1.2508, Train Acc: 78.30%\n",
      "Val Loss: 0.7809, Val Acc: 97.13%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Epoch 35/40:\n",
      "Train Loss: 1.2505, Train Acc: 78.33%\n",
      "Val Loss: 0.7689, Val Acc: 99.43%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Epoch 36/40:\n",
      "Train Loss: 1.2491, Train Acc: 78.36%\n",
      "Val Loss: 0.7548, Val Acc: 99.70%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Epoch 37/40:\n",
      "Train Loss: 1.2475, Train Acc: 78.20%\n",
      "Val Loss: 0.7706, Val Acc: 99.53%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Epoch 38/40:\n",
      "Train Loss: 1.2489, Train Acc: 78.10%\n",
      "Val Loss: 0.7624, Val Acc: 99.43%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Epoch 39/40:\n",
      "Train Loss: 1.2431, Train Acc: 78.43%\n",
      "Val Loss: 0.7637, Val Acc: 99.47%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Epoch 40/40:\n",
      "Train Loss: 1.2330, Train Acc: 78.76%\n",
      "Val Loss: 0.7610, Val Acc: 97.77%\n",
      "LR: 0.000250\n",
      "--------------------------------------------------\n",
      "Lade bestes Modell für finale Evaluation...\n",
      "\n",
      "Beste Validierungs-Accuracy: 99.70%\n",
      "Verbesserung gegenüber initialem Modell: +99.70%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Konstanten\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "LEARNING_RATE = 0.0005  # Reduzierte Learning Rate\n",
    "WEIGHT_DECAY = 0.01     # L2 Regularisierung hinzugefügt\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_PATH = '/home/geiger/asl_detection/machine_learning/models/asl_now/best_model.pth'  # Pfad zum bestehenden Modell\n",
    "NOISE_LEVEL = 0.05      # Rauschen für Daten-Augmentation\n",
    "\n",
    "# Dataset-Klasse mit Daten-Augmentation\n",
    "class HandSignDataset(Dataset):\n",
    "    def __init__(self, keypoints, labels, augment=False):\n",
    "        self.keypoints = torch.FloatTensor(keypoints)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.keypoints)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        keypoints = self.keypoints[idx]\n",
    "        \n",
    "        # Daten-Augmentation mit zufälligem Rauschen (nur für Trainingsdaten)\n",
    "        if self.augment:\n",
    "            # Füge zufälliges Rauschen zu den Keypoints hinzu\n",
    "            noise = torch.randn_like(keypoints) * NOISE_LEVEL\n",
    "            keypoints = keypoints + noise\n",
    "            \n",
    "            # Zufällige kleine Rotation (simuliere leichte Handdrehung)\n",
    "            if torch.rand(1).item() > 0.5:\n",
    "                # Reshape für die 21 Landmarken mit jeweils 3 Koordinaten\n",
    "                points = keypoints.view(-1, 3)\n",
    "                \n",
    "                # Zufälliger kleiner Rotationswinkel\n",
    "                angle = torch.rand(1).item() * 0.2 - 0.1  # ±0.1 Radiant (ca. ±5.7°)\n",
    "                \n",
    "                # Einfache 2D-Rotation in der x-y-Ebene\n",
    "                cos_a, sin_a = torch.cos(torch.tensor(angle)), torch.sin(torch.tensor(angle))\n",
    "                rotation = torch.tensor([[cos_a, -sin_a, 0], \n",
    "                                        [sin_a, cos_a, 0],\n",
    "                                        [0, 0, 1]])\n",
    "                \n",
    "                # Rotiere die Punkte\n",
    "                rotated_points = torch.matmul(points, rotation)\n",
    "                keypoints = rotated_points.view(-1)\n",
    "        \n",
    "        return keypoints, self.labels[idx]\n",
    "\n",
    "# Verbesserte Modell-Definition mit stärkerem Dropout\n",
    "class HandSignNet(nn.Module):\n",
    "    def __init__(self, num_classes=24):\n",
    "        super(HandSignNet, self).__init__()\n",
    "        \n",
    "        # Feature Extraction Blocks mit erhöhtem Dropout\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(63, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.5),  # Erhöhter Dropout\n",
    "            \n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.5),  # Erhöhter Dropout\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.5)   # Erhöhter Dropout\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train')\n",
    "    plt.plot(val_accs, label='Validation')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "def main(load_model=True):\n",
    "    # Setze Seeds für Reproduzierbarkeit\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    # Alphabet-Definition\n",
    "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n",
    "    \n",
    "    # Lade Daten\n",
    "    print(\"Lade Daten...\")\n",
    "    data = np.load('/home/geiger/asl_detection/machine_learning/datasets/asl_now/Keypoints_3/asl_keypoints.npz')\n",
    "    keypoints = data['keypoints']\n",
    "    labels = data['labels']\n",
    "    \n",
    "    # Split Daten\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        keypoints, labels, test_size=0.2, random_state=RANDOM_SEED, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # Erstelle DataLoader mit Daten-Augmentation für Training\n",
    "    train_dataset = HandSignDataset(X_train, y_train, augment=True)  # Augmentation aktiviert\n",
    "    val_dataset = HandSignDataset(X_val, y_val, augment=False)       # Keine Augmentation für Val\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # Initialisiere Modell und lade vortrainiertes Modell, falls gewünscht\n",
    "    print(f\"Initialisiere Modell auf {DEVICE}...\")\n",
    "    model = HandSignNet().to(DEVICE)\n",
    "    \n",
    "    # Cross-Entropy mit Label Smoothing\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label Smoothing hinzugefügt\n",
    "    \n",
    "    # Optimizer mit Weight Decay\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # Angepasster Scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=8, factor=0.5)\n",
    "    \n",
    "    initial_val_acc = 0\n",
    "    if load_model and os.path.exists(MODEL_PATH):\n",
    "        print(f\"Lade vortrainiertes Modell von {MODEL_PATH}...\")\n",
    "        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "        print(\"Vortrainiertes Modell erfolgreich geladen!\")\n",
    "        \n",
    "        # Führe eine Validierung mit dem geladenen Modell durch\n",
    "        print(\"Validiere geladenes Modell...\")\n",
    "        initial_val_loss, initial_val_acc, _, _ = validate(model, val_loader, criterion, DEVICE)\n",
    "        print(f\"Initiale Validierungs-Genauigkeit: {initial_val_acc:.2f}%\")\n",
    "    else:\n",
    "        if load_model:\n",
    "            print(f\"Kein vortrainiertes Modell gefunden unter {MODEL_PATH}. Starte mit neuem Modell.\")\n",
    "        else:\n",
    "            print(\"Training mit neuem Modell gestartet.\")\n",
    "    \n",
    "    best_val_acc = initial_val_acc\n",
    "    \n",
    "    # Training\n",
    "    print(\"Starte Training...\")\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion, DEVICE)\n",
    "        \n",
    "        # Learning Rate Anpassung\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Speichere Metriken\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Speichere bestes Modell\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(f\"Neues bestes Modell gespeichert mit Accuracy: {val_acc:.2f}%\")\n",
    "        \n",
    "        # Ausgabe\n",
    "        print(f'Epoch {epoch+1}/{EPOCHS}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "        print('-' * 50)\n",
    "    \n",
    "    # Lade bestes Modell für finale Evaluation, aber nur wenn es existiert\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        print(\"Lade bestes Modell für finale Evaluation...\")\n",
    "        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "        _, final_acc, final_preds, final_labels = validate(model, val_loader, criterion, DEVICE)\n",
    "        \n",
    "        # Plotte Ergebnisse\n",
    "        plot_training_history(train_losses, val_losses, train_accs, val_accs)\n",
    "        plot_confusion_matrix(final_labels, final_preds, alphabet)\n",
    "    else:\n",
    "        print(\"Kein gespeichertes Modell gefunden. Überspringe finale Evaluation.\")\n",
    "        # Verwende die Ergebnisse der letzten Epoche für die Plots\n",
    "        final_preds = val_preds\n",
    "        final_labels = val_labels\n",
    "        plot_training_history(train_losses, val_losses, train_accs, val_accs)\n",
    "        if len(final_labels) > 0:  # Nur wenn wir Validierungsdaten haben\n",
    "            plot_confusion_matrix(final_labels, final_preds, alphabet)\n",
    "    \n",
    "    print(f\"\\nBeste Validierungs-Accuracy: {best_val_acc:.2f}%\")\n",
    "    if best_val_acc > initial_val_acc:\n",
    "        print(f\"Verbesserung gegenüber initialem Modell: +{best_val_acc - initial_val_acc:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Prüfe, ob ein Kommandozeilenargument übergeben wurde\n",
    "    load_model = False  # Standard: Starte mit neuem Modell\n",
    "    \n",
    "    main(load_model) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl_detection_mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
