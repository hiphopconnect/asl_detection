{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# MediaPipe Hands initialisieren\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Pfade konfigurieren\n",
    "DATASET_PATH = \"/workspaces/asl_detection/machine_learning/datasets/asl_now/Combined_Dataset\"\n",
    "OUTPUT_PATH = \"/workspaces/asl_detection/machine_learning/datasets/asl_now/Combined_Keypoints\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "def extract_hand_keypoints(results):\n",
    "    \"\"\"\n",
    "    Extrahiert Keypoints der signierenden Hand (rechte Hand aus Sicht des Betrachters)\n",
    "    \"\"\"\n",
    "    # Initialisiere Array für die signierende Hand (21 Keypoints mit x, y, z)\n",
    "    hand_keypoints = np.zeros(21 * 3)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        # Wenn mehrere Hände erkannt wurden, finde die richtige Hand\n",
    "        for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            # Die Hand-Klassifikation ist aus Sicht der Kamera\n",
    "            handedness = results.multi_handedness[hand_idx].classification[0].label\n",
    "            if handedness == \"Right\":  # Wir suchen die rechte Hand aus Sicht der Kamera\n",
    "                hand_keypoints = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]).flatten()\n",
    "                break\n",
    "        # Falls keine rechte Hand gefunden wurde, nimm die erste erkannte Hand\n",
    "        if np.all(hand_keypoints == 0) and results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            hand_keypoints = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]).flatten()\n",
    "    \n",
    "    return hand_keypoints\n",
    "\n",
    "def process_image(image_path, hands):\n",
    "    \"\"\"\n",
    "    Verarbeitet ein einzelnes Bild und extrahiert Hand-Keypoints\n",
    "    \"\"\"\n",
    "    # Bild laden\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Fehler beim Laden des Bildes: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Farbraum für MediaPipe konvertieren (ohne weitere Transformationen)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Keypoints mit MediaPipe Hands extrahieren\n",
    "    results = hands.process(image_rgb)\n",
    "    \n",
    "    # Wenn keine Hand erkannt wurde, versuche es mit gespiegeltem Bild\n",
    "    if not results.multi_hand_landmarks:\n",
    "        image_flipped = cv2.flip(image_rgb, 1)\n",
    "        results = hands.process(image_flipped)\n",
    "    \n",
    "    # Extrahiere Hand-Keypoints\n",
    "    keypoints = extract_hand_keypoints(results)\n",
    "    \n",
    "    return keypoints, results\n",
    "\n",
    "def save_visualization(image_path, results, letter, idx):\n",
    "    \"\"\"\n",
    "    Speichert eine Visualisierung der Handerkennung\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    # Speichere das visualisierte Bild\n",
    "    vis_dir = os.path.join(OUTPUT_PATH, \"visualizations\", letter)\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    output_path = os.path.join(vis_dir, f\"{idx:04d}.png\")\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "def main(visualize=False):\n",
    "    # Alphabet mit allen Buchstaben außer 'j' und 'z'\n",
    "    alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "    \n",
    "    # Liste für die extrahierten Keypoints\n",
    "    all_keypoints = []\n",
    "    # Dictionary für Statistiken\n",
    "    stats = {letter: {'total': 0, 'not_detected': 0} for letter in alphabet}\n",
    "    \n",
    "    # MediaPipe Hands mit angepasster Erkennungsgenauigkeit initialisieren\n",
    "    with mp_hands.Hands(\n",
    "            static_image_mode=True,\n",
    "            max_num_hands=2,\n",
    "            min_detection_confidence=0.2,\n",
    "            min_tracking_confidence=0.2) as hands:\n",
    "        \n",
    "        # Über alle Buchstabenordner iterieren\n",
    "        for letter in alphabet:\n",
    "            letter_dir = os.path.join(DATASET_PATH, letter)\n",
    "            if not os.path.isdir(letter_dir):\n",
    "                print(f\"Ordner für Buchstabe {letter} nicht gefunden: {letter_dir}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Verarbeite Buchstabe: {letter}\")\n",
    "            \n",
    "            # Alle PNG-Dateien im Ordner finden\n",
    "            image_files = [f for f in os.listdir(letter_dir) if f.endswith('.png')]\n",
    "            stats[letter]['total'] = len(image_files)\n",
    "            \n",
    "            # Über alle Bilder im Ordner iterieren mit Fortschrittsbalken\n",
    "            for idx, image_file in enumerate(tqdm(image_files, desc=f\"Buchstabe {letter}\")):\n",
    "                image_path = os.path.join(letter_dir, image_file)\n",
    "                \n",
    "                # Keypoints aus dem Bild extrahieren\n",
    "                result = process_image(image_path, hands)\n",
    "                if result is None:\n",
    "                    stats[letter]['not_detected'] += 1\n",
    "                    continue\n",
    "                    \n",
    "                keypoints, mp_results = result\n",
    "                \n",
    "                # Nur speichern wenn Hand erkannt wurde\n",
    "                if not np.all(keypoints == 0):\n",
    "                    # Keypoints mit Label und Dateinamen speichern\n",
    "                    keypoint_data = {\n",
    "                        'letter': letter,\n",
    "                        'filename': image_file,\n",
    "                        'keypoints': keypoints\n",
    "                    }\n",
    "                    all_keypoints.append(keypoint_data)\n",
    "                else:\n",
    "                    stats[letter]['not_detected'] += 1\n",
    "                \n",
    "                # Optional: Visualisiere jedes 50. Bild\n",
    "                if visualize and idx % 50 == 0:\n",
    "                    save_visualization(image_path, mp_results, letter, idx)\n",
    "    \n",
    "    print(f\"\\nInsgesamt {len(all_keypoints)} Bilder erfolgreich verarbeitet.\")\n",
    "    \n",
    "    # Speichern der extrahierten Keypoints\n",
    "    keypoints_df = pd.DataFrame(all_keypoints)\n",
    "    \n",
    "    # CSV-Datei mit Metadaten speichern\n",
    "    metadata_df = keypoints_df[['letter', 'filename']].copy()\n",
    "    metadata_df.to_csv(os.path.join(OUTPUT_PATH, 'metadata.csv'), index=False)\n",
    "    \n",
    "    # Numpy-Datei mit allen Keypoints speichern\n",
    "    keypoints_array = np.array([data['keypoints'] for data in all_keypoints])\n",
    "    # Anpassen der Labels auf den Index im Alphabet\n",
    "    labels = np.array([alphabet.index(data['letter']) for data in all_keypoints])\n",
    "    \n",
    "    np.savez(os.path.join(OUTPUT_PATH, 'asl_keypoints.npz'),\n",
    "             keypoints=keypoints_array,\n",
    "             labels=labels)\n",
    "    \n",
    "    print(f\"\\nKeypoints wurden gespeichert unter: {OUTPUT_PATH}\")\n",
    "    print(\"\\nStatistiken pro Buchstabe:\")\n",
    "    print(\"Buchstabe | Gesamt | Nicht erkannt | Erkennungsrate\")\n",
    "    print(\"-\" * 50)\n",
    "    for letter in alphabet:\n",
    "        total = stats[letter]['total']\n",
    "        not_detected = stats[letter]['not_detected']\n",
    "        detection_rate = ((total - not_detected) / total * 100) if total > 0 else 0\n",
    "        print(f\"{letter:^9} | {total:^6} | {not_detected:^12} | {detection_rate:^6.1f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(visualize=False)  # Setze auf True für Visualisierungen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Lade die Keypoints\n",
    "data = np.load('/workspaces/asl_detection/machine_learning/datasets/asl_now/Keypoints/asl_keypoints.npz')\n",
    "keypoints = data['keypoints']\n",
    "labels = data['labels']\n",
    "\n",
    "# Buchstaben-Mapping\n",
    "alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "\n",
    "print(\"Grundlegende Informationen:\")\n",
    "print(f\"Anzahl Samples: {len(keypoints)}\")\n",
    "print(f\"Shape der Keypoints: {keypoints.shape}\")\n",
    "print(f\"Samples pro Buchstabe:\")\n",
    "for i, letter in enumerate(alphabet):\n",
    "    count = np.sum(labels == i)\n",
    "    print(f\"{letter}: {count} Samples\")\n",
    "\n",
    "# Analyse der Keypoint-Verteilung pro Buchstabe\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Durchschnittliche Keypoint-Position pro Buchstabe\n",
    "plt.subplot(221)\n",
    "for i, letter in enumerate(alphabet):\n",
    "    letter_keypoints = keypoints[labels == i]\n",
    "    mean_pos = letter_keypoints.reshape(-1, 21, 3)[:, :, :2].mean(axis=0)\n",
    "    plt.scatter(mean_pos[:, 0], mean_pos[:, 1], label=letter, alpha=0.6)\n",
    "plt.title('Durchschnittliche Keypoint-Positionen')\n",
    "plt.xlabel('x-Koordinate')\n",
    "plt.ylabel('y-Koordinate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: Verteilung der z-Werte\n",
    "plt.subplot(222)\n",
    "for i, letter in enumerate(alphabet):\n",
    "    letter_keypoints = keypoints[labels == i]\n",
    "    z_values = letter_keypoints.reshape(-1, 21, 3)[:, :, 2]\n",
    "    plt.hist(z_values.flatten(), bins=30, alpha=0.3, label=letter)\n",
    "plt.title('Verteilung der Z-Werte')\n",
    "plt.xlabel('Z-Koordinate')\n",
    "plt.ylabel('Häufigkeit')\n",
    "plt.legend()\n",
    "\n",
    "# Plot 3: Keypoint-Varianz\n",
    "plt.subplot(223)\n",
    "variances = []\n",
    "for i, letter in enumerate(alphabet):\n",
    "    letter_keypoints = keypoints[labels == i]\n",
    "    var = letter_keypoints.reshape(-1, 21, 3).var(axis=0)\n",
    "    variances.append(var.mean(axis=1))\n",
    "\n",
    "plt.boxplot([v for v in variances], labels=alphabet)\n",
    "plt.title('Keypoint-Varianz pro Buchstabe')\n",
    "plt.ylabel('Varianz')\n",
    "\n",
    "# Plot 4: Konsistenz-Matrix\n",
    "plt.subplot(224)\n",
    "consistency = np.zeros((len(alphabet), len(alphabet)))\n",
    "for i, letter1 in enumerate(alphabet):\n",
    "    kp1 = keypoints[labels == i].reshape(-1, 21, 3)\n",
    "    mean1 = kp1.mean(axis=0)\n",
    "    for j, letter2 in enumerate(alphabet):\n",
    "        kp2 = keypoints[labels == j].reshape(-1, 21, 3)\n",
    "        mean2 = kp2.mean(axis=0)\n",
    "        # Berechne Ähnlichkeit basierend auf euklidischer Distanz\n",
    "        consistency[i, j] = np.linalg.norm(mean1 - mean2)\n",
    "\n",
    "sns.heatmap(consistency, annot=True, fmt='.2f', \n",
    "            xticklabels=alphabet, yticklabels=alphabet)\n",
    "plt.title('Unterscheidbarkeits-Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('keypoint_analysis_detailed.png')\n",
    "print(\"\\nDetailierte Analyse wurde als 'keypoint_analysis_detailed.png' gespeichert.\")\n",
    "\n",
    "# Zusätzliche statistische Analysen\n",
    "print(\"\\nStatistische Analyse:\")\n",
    "print(\"-\" * 50)\n",
    "for i, letter in enumerate(alphabet):\n",
    "    letter_keypoints = keypoints[labels == i]\n",
    "    print(f\"\\nBuchstabe {letter}:\")\n",
    "    print(f\"Min/Max X: {letter_keypoints[:, ::3].min():.3f}/{letter_keypoints[:, ::3].max():.3f}\")\n",
    "    print(f\"Min/Max Y: {letter_keypoints[:, 1::3].min():.3f}/{letter_keypoints[:, 1::3].max():.3f}\")\n",
    "    print(f\"Min/Max Z: {letter_keypoints[:, 2::3].min():.3f}/{letter_keypoints[:, 2::3].max():.3f}\")\n",
    "    print(f\"Durchschnittliche Varianz: {letter_keypoints.var():.3f}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
