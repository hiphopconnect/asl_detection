{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Configure paths\n",
    "DATASET_PATH = \"/workspaces/asl_detection/machine_learning/datasets/asl_now/Combined_Dataset\"\n",
    "OUTPUT_PATH = \"/workspaces/asl_detection/machine_learning/datasets/asl_now/Combined_Keypoints\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "def extract_hand_keypoints(results):\n",
    "    \"\"\"\n",
    "    Extracts keypoints of the signing hand (right hand from the viewer's perspective)\n",
    "    \"\"\"\n",
    "    # Initialize array for the signing hand (21 keypoints with x, y, z)\n",
    "    hand_keypoints = np.zeros(21 * 3)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        # If multiple hands are detected, find the correct hand\n",
    "        for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            # Hand classification is from the camera's perspective\n",
    "            handedness = results.multi_handedness[hand_idx].classification[0].label\n",
    "            if handedness == \"Right\":  # We are looking for the right hand from the camera's perspective\n",
    "                hand_keypoints = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]).flatten()\n",
    "                break\n",
    "        # If no right hand was found, take the first detected hand\n",
    "        if np.all(hand_keypoints == 0) and results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            hand_keypoints = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]).flatten()\n",
    "    \n",
    "    return hand_keypoints\n",
    "\n",
    "def process_image(image_path, hands):\n",
    "    \"\"\"\n",
    "    Processes a single image and extracts hand keypoints\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Convert color space for MediaPipe (without additional transformations)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Extract keypoints with MediaPipe Hands\n",
    "    results = hands.process(image_rgb)\n",
    "    \n",
    "    # If no hand is detected, try with flipped image\n",
    "    if not results.multi_hand_landmarks:\n",
    "        image_flipped = cv2.flip(image_rgb, 1)\n",
    "        results = hands.process(image_flipped)\n",
    "    \n",
    "    # Extract hand keypoints\n",
    "    keypoints = extract_hand_keypoints(results)\n",
    "    \n",
    "    return keypoints, results\n",
    "\n",
    "def save_visualization(image_path, results, letter, idx):\n",
    "    \"\"\"\n",
    "    Saves a visualization of the hand detection\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    # Save the visualized image\n",
    "    vis_dir = os.path.join(OUTPUT_PATH, \"visualizations\", letter)\n",
    "    os.makedirs(vis_dir, exist_ok=True)\n",
    "    output_path = os.path.join(vis_dir, f\"{idx:04d}.png\")\n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "def main(visualize=False):\n",
    "    # Alphabet with all letters except 'j' and 'z'\n",
    "    alphabet = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "    \n",
    "    # List for extracted keypoints\n",
    "    all_keypoints = []\n",
    "    # Dictionary for statistics\n",
    "    stats = {letter: {'total': 0, 'not_detected': 0} for letter in alphabet}\n",
    "    \n",
    "    # Initialize MediaPipe Hands with adjusted detection accuracy\n",
    "    with mp_hands.Hands(\n",
    "            static_image_mode=True,\n",
    "            max_num_hands=2,\n",
    "            min_detection_confidence=0.2,\n",
    "            min_tracking_confidence=0.2) as hands:\n",
    "        \n",
    "        # Iterate over all letter folders\n",
    "        for letter in alphabet:\n",
    "            letter_dir = os.path.join(DATASET_PATH, letter)\n",
    "            if not os.path.isdir(letter_dir):\n",
    "                print(f\"Folder for letter {letter} not found: {letter_dir}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"Processing letter: {letter}\")\n",
    "            \n",
    "            # Find all PNG files in the folder\n",
    "            image_files = [f for f in os.listdir(letter_dir) if f.endswith('.png')]\n",
    "            stats[letter]['total'] = len(image_files)\n",
    "            \n",
    "            # Iterate over all images in the folder with progress bar\n",
    "            for idx, image_file in enumerate(tqdm(image_files, desc=f\"Letter {letter}\")):\n",
    "                image_path = os.path.join(letter_dir, image_file)\n",
    "                \n",
    "                # Extract keypoints from the image\n",
    "                result = process_image(image_path, hands)\n",
    "                if result is None:\n",
    "                    stats[letter]['not_detected'] += 1\n",
    "                    continue\n",
    "                    \n",
    "                keypoints, mp_results = result\n",
    "                \n",
    "                # Save only if a hand was detected\n",
    "                if not np.all(keypoints == 0):\n",
    "                    # Save keypoints with label and filename\n",
    "                    keypoint_data = {\n",
    "                        'letter': letter,\n",
    "                        'filename': image_file,\n",
    "                        'keypoints': keypoints\n",
    "                    }\n",
    "                    all_keypoints.append(keypoint_data)\n",
    "                else:\n",
    "                    stats[letter]['not_detected'] += 1\n",
    "                \n",
    "                # Optionally visualize every 50th image\n",
    "                if visualize and idx % 50 == 0:\n",
    "                    save_visualization(image_path, mp_results, letter, idx)\n",
    "    \n",
    "    print(f\"\\nSuccessfully processed {len(all_keypoints)} images.\")\n",
    "    \n",
    "    # Save extracted keypoints\n",
    "    keypoints_df = pd.DataFrame(all_keypoints)\n",
    "    \n",
    "    # Save CSV file with metadata\n",
    "    metadata_df = keypoints_df[['letter', 'filename']].copy()\n",
    "    metadata_df.to_csv(os.path.join(OUTPUT_PATH, 'metadata.csv'), index=False)\n",
    "    \n",
    "    # Save NumPy file with all keypoints\n",
    "    keypoints_array = np.array([data['keypoints'] for data in all_keypoints])\n",
    "    # Adjust labels to the index in the alphabet\n",
    "    labels = np.array([alphabet.index(data['letter']) for data in all_keypoints])\n",
    "    \n",
    "    np.savez(os.path.join(OUTPUT_PATH, 'asl_keypoints.npz'),\n",
    "             keypoints=keypoints_array,\n",
    "             labels=labels)\n",
    "    \n",
    "    print(f\"\\nKeypoints saved under: {OUTPUT_PATH}\")\n",
    "    print(\"\\nStatistics per letter:\")\n",
    "    print(\"Letter | Total | Not detected | Detection rate\")\n",
    "    print(\"-\" * 50)\n",
    "    for letter in alphabet:\n",
    "        total = stats[letter]['total']\n",
    "        not_detected = stats[letter]['not_detected']\n",
    "        detection_rate = ((total - not_detected) / total * 100) if total > 0 else 0\n",
    "        print(f\"{letter:^9} | {total:^6} | {not_detected:^12} | {detection_rate:^6.1f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(visualize=False)  # Set to True for visualizations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
