{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unavailable videos and change names (uncommented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "json_file = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/WLASL_v0.3.json\"\n",
    "\n",
    "with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "video_labels = {}\n",
    "for entry in data:\n",
    "    gloss = entry[\"gloss\"]\n",
    "    for instance in entry[\"instances\"]:\n",
    "        video_id = str(instance[\"video_id\"])  \n",
    "        if video_id not in video_labels:\n",
    "            video_labels[video_id] = []\n",
    "        video_labels[video_id].append(gloss)\n",
    "\n",
    "video_folder = Path(video_folder)\n",
    "\n",
    "if not video_folder.exists():\n",
    "    raise FileNotFoundError(f\"Der Ordner {video_folder} wurde nicht gefunden.\")\n",
    "\n",
    "video_files = list(video_folder.glob(\"*\"))\n",
    "\n",
    "\n",
    "deleted_videos = []\n",
    "renamed_videos = []\n",
    "\n",
    "def is_video_valid(video_path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return False  \n",
    "    ret, _ = cap.read()\n",
    "    cap.release()\n",
    "    return ret \n",
    "\n",
    "for video_file in video_files:\n",
    "    if not video_file.is_file():\n",
    "        continue\n",
    "\n",
    "    video_id = video_file.stem \n",
    "\n",
    "    if os.path.getsize(video_file) == 0 or not is_video_valid(video_file):\n",
    "        deleted_videos.append(video_file.name)\n",
    "        os.remove(video_file)\n",
    "        continue\n",
    "\n",
    "    # labels = video_labels.get(video_id, [])\n",
    "    # if labels:\n",
    "    #     new_name = f\"{video_id}_{'_'.join(labels)}{video_file.suffix}\"\n",
    "    #     new_path = video_file.parent / new_name\n",
    "    #     os.rename(video_file, new_path)\n",
    "    #     renamed_videos.append((video_file.name, new_name))\n",
    "\n",
    "print(\"Gelöschte Videos:\", deleted_videos)\n",
    "print(\"Umbenannte Videos:\", renamed_videos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add frame count to video names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "\n",
    "if not os.path.exists(video_folder):\n",
    "    raise FileNotFoundError(f\"Der Ordner {video_folder} wurde nicht gefunden.\")\n",
    "\n",
    "video_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f))]\n",
    "\n",
    "def get_frame_count(video_path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return None \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return frame_count\n",
    "\n",
    "renamed_videos = []\n",
    "\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    video_id, ext = os.path.splitext(video_file) \n",
    "    \n",
    "    frame_count = get_frame_count(video_path)\n",
    "    \n",
    "    if frame_count is not None:\n",
    "        new_name = f\"{video_id}_{frame_count}{ext}\"\n",
    "        new_path = os.path.join(video_folder, new_name)\n",
    "        os.rename(video_path, new_path)\n",
    "        renamed_videos.append((video_file, new_name))\n",
    "\n",
    "print(\"Umbenannte Videos mit Frames:\", renamed_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informations about videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "\n",
    "if not os.path.exists(video_folder):\n",
    "    raise FileNotFoundError(f\"Der Ordner {video_folder} wurde nicht gefunden.\")\n",
    "\n",
    "video_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f))]\n",
    "\n",
    "label_counter = Counter()\n",
    "\n",
    "for video_file in video_files:\n",
    "    filename, _ = os.path.splitext(video_file) \n",
    "    parts = filename.split(\"_\") \n",
    "\n",
    "    if len(parts) == 3:  \n",
    "        label = parts[1]  \n",
    "        label_counter[label] += 1\n",
    "\n",
    "print(f\"Anzahl der verschiedenen Labels: {len(label_counter)}\")\n",
    "print(\"Top 10 häufigste Labels:\")\n",
    "for label, count in label_counter.most_common(10):\n",
    "    print(f\"{label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups per videos per label\n",
    "from collections import Counter\n",
    "\n",
    "label_distribution = Counter(label_counter.values())\n",
    "\n",
    "print(\"Anzahl der Labels mit bestimmter Anzahl von Videos:\")\n",
    "for num_videos, num_labels in sorted(label_distribution.items()):\n",
    "    print(f\"{num_labels} Labels haben {num_videos} Videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete videos with less than min_videos_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Directory containing videos\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "\n",
    "# Retrieve list of all videos\n",
    "video_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f))]\n",
    "\n",
    "# Extract and count labels\n",
    "label_counter = Counter()\n",
    "\n",
    "for video_file in video_files:\n",
    "    filename, _ = os.path.splitext(video_file)  # Remove file extension\n",
    "    parts = filename.split(\"_\")  # Split by \"_\"\n",
    "    \n",
    "    if len(parts) >= 3:  # Ensure correct format\n",
    "        label = parts[1]  # Middle element is the label\n",
    "        label_counter[label] += 1\n",
    "\n",
    "# Minimum number of videos per label\n",
    "min_videos_per_label = 8\n",
    "\n",
    "# Delete files with too few videos\n",
    "deleted_count = 0\n",
    "\n",
    "for video_file in video_files:\n",
    "    filename, _ = os.path.splitext(video_file)\n",
    "    parts = filename.split(\"_\")\n",
    "\n",
    "    if len(parts) >= 3:\n",
    "        label = parts[1]\n",
    "        if label_counter[label] < min_videos_per_label:\n",
    "            os.remove(os.path.join(video_folder, video_file))\n",
    "            deleted_count += 1\n",
    "\n",
    "print(f\"{deleted_count} videos were deleted because their label had fewer than {min_videos_per_label} videos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> start here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Frames again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "# Directory containing videos\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_augmented\"\n",
    "\n",
    "if not os.path.exists(video_folder):\n",
    "    raise FileNotFoundError(f\"❌ The folder {video_folder} was not found.\")\n",
    "\n",
    "# Function to determine the current frame count\n",
    "def get_frame_count(video_path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return None \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return frame_count\n",
    "\n",
    "# Regex to find the frame count in the filename (e.g., `00624_accident_109_bright.mp4`)\n",
    "frame_pattern = re.compile(r\"_(\\d+)(?:_[a-zA-Z]+)?\\.mp4$\")\n",
    "\n",
    "renamed_videos = []\n",
    "\n",
    "for video_file in os.listdir(video_folder):\n",
    "    if not video_file.endswith(\".mp4\"):\n",
    "        continue\n",
    "\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "\n",
    "    # Extract the actual frame count\n",
    "    frame_count = get_frame_count(video_path)\n",
    "    if frame_count is None:\n",
    "        print(f\"⚠️ Warning: Could not determine frames for {video_file}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Check if a frame count already exists in the name\n",
    "    match = frame_pattern.search(video_file)\n",
    "    \n",
    "    if match:\n",
    "        existing_frame_count = int(match.group(1))\n",
    "        \n",
    "        # Rename if the frame count does not match\n",
    "        if existing_frame_count != frame_count:\n",
    "            new_name = re.sub(frame_pattern, f\"_{frame_count}.mp4\", video_file)\n",
    "            new_path = os.path.join(video_folder, new_name)\n",
    "            os.rename(video_path, new_path)\n",
    "            renamed_videos.append((video_file, new_name))\n",
    "            print(f\"🔄 {video_file} → {new_name} (Frames updated)\")\n",
    "    else:\n",
    "        # If no frame count is present, add it\n",
    "        name_parts = video_file.rsplit(\".\", 1)\n",
    "        new_name = f\"{name_parts[0]}_{frame_count}.mp4\"\n",
    "        new_path = os.path.join(video_folder, new_name)\n",
    "        os.rename(video_path, new_path)\n",
    "        renamed_videos.append((video_file, new_name))\n",
    "        print(f\"➕ {video_file} → {new_name} (Frames added)\")\n",
    "\n",
    "print(\"\\n✅ All frame counts have been checked and updated if necessary!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print videos with less than 40 min_videos_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Directories containing videos\n",
    "raw_video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "augmented_video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_augmented\"\n",
    "\n",
    "# Count labels\n",
    "label_counter = Counter()\n",
    "\n",
    "for folder in [raw_video_folder, augmented_video_folder]:\n",
    "    for video_file in os.listdir(folder):\n",
    "        if not video_file.endswith(\".mp4\"):\n",
    "            continue\n",
    "\n",
    "        parts = video_file.split(\"_\")\n",
    "        if len(parts) >= 3:  # Ensure the name is correct\n",
    "            label = parts[1]  # The second element is now the label\n",
    "            label_counter[label] += 1\n",
    "\n",
    "# Sort labels by number of videos (descending order)\n",
    "sorted_labels = sorted(label_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Number of available labels\n",
    "print(f\"Number of remaining labels: {len(sorted_labels)}\")\n",
    "\n",
    "# Display top 10 most common labels\n",
    "print(\"\\nTop 10 most common labels:\")\n",
    "for label, count in sorted_labels[:10]:\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "# Display all labels with the number of videos\n",
    "print(\"\\nNumber of videos per label:\")\n",
    "for label, count in sorted_labels:\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate maximum number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Directories containing videos\n",
    "original_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "augmented_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_augmented\"\n",
    "\n",
    "# Determine the maximum number of frames across both folders\n",
    "max_frames = 0\n",
    "\n",
    "for folder in [original_folder, augmented_folder]:\n",
    "    for video_file in os.listdir(folder):\n",
    "        if not video_file.endswith(\".mp4\"):\n",
    "            continue\n",
    "\n",
    "        parts = video_file.replace(\".mp4\", \"\").split(\"_\")\n",
    "        \n",
    "        if len(parts) >= 3:  # Ensure enough parts are present\n",
    "            try:\n",
    "                frame_count = int(parts[2])  # Frame count is at position 2\n",
    "                max_frames = max(max_frames, frame_count)\n",
    "            except ValueError:\n",
    "                print(f\"⚠️ Warning: Could not extract frame count from {video_file}\")\n",
    "\n",
    "print(f\"✅ Maximum number of frames (across all videos): {max_frames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce number of videos per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Directories containing videos\n",
    "original_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "augmented_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_augmented\"\n",
    "\n",
    "# Target number of videos per label\n",
    "target_videos_per_label = 36\n",
    "\n",
    "# Count the number of videos per label\n",
    "label_counter = Counter()\n",
    "\n",
    "for folder in [original_folder, augmented_folder]:\n",
    "    for video_file in os.listdir(folder):\n",
    "        parts = video_file.split(\"_\")\n",
    "        if len(parts) >= 3:\n",
    "            label = parts[1]  # The label is the second element\n",
    "            label_counter[label] += 1\n",
    "\n",
    "# Check if labels have fewer than 36 videos\n",
    "for label, count in label_counter.items():\n",
    "    if count < target_videos_per_label:\n",
    "        print(f\"⚠️ WARNING: Label '{label}' has only {count} videos and cannot be increased to 36!\")\n",
    "\n",
    "# Remove excess augmented videos randomly\n",
    "for label, count in label_counter.items():\n",
    "    if count > target_videos_per_label:\n",
    "        # Find all augmented videos for this label\n",
    "        label_videos = [f for f in os.listdir(augmented_folder) if f.split(\"_\")[1] == label]\n",
    "\n",
    "        # Warn if there are not enough augmented videos to delete\n",
    "        if len(label_videos) < (count - target_videos_per_label):\n",
    "            print(f\"⚠️ WARNING: Not enough augmented videos to delete for label '{label}'!\")\n",
    "\n",
    "        # Randomly select videos to delete (only augmented ones)\n",
    "        remove_videos = random.sample(label_videos, count - target_videos_per_label)\n",
    "\n",
    "        # Delete the videos\n",
    "        for video_file in remove_videos:\n",
    "            os.remove(os.path.join(augmented_folder, video_file))\n",
    "            print(f\"🗑️ Deleted: {video_file}\")\n",
    "\n",
    "print(\"✅ All labels now have exactly 36 videos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Directories\n",
    "original_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "augmented_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_augmented\"\n",
    "processed_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_processed\"\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# Determine the maximum number of frames if not defined\n",
    "if \"max_frames\" not in locals():\n",
    "    max_frames = 195  # Default value if not previously calculated\n",
    "\n",
    "# Function to extract frames as Torch tensors\n",
    "def extract_frames(video_path, device=\"cuda\"):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"⚠️ Warning: Could not open video: {video_path}\")\n",
    "        return torch.zeros((1, 3, 224, 224), dtype=torch.float32, device=device)  # Dummy frame\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (224, 224))  # Resize frames to uniform size\n",
    "        frame = torch.tensor(frame, dtype=torch.float32, device=device).permute(2, 0, 1)  # [H, W, C] → [C, H, W]\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if not frames:\n",
    "        print(f\"⚠️ Warning: No frames extracted for {video_path}\")\n",
    "        return torch.zeros((1, 3, 224, 224), dtype=torch.float32, device=device)  # If empty, return dummy frame\n",
    "\n",
    "    return torch.stack(frames, dim=0)\n",
    "\n",
    "# Function for padding with GPU support\n",
    "def pad_frames(frames, target_length, device=\"cuda\"):\n",
    "    num_frames = frames.shape[0]\n",
    "\n",
    "    if num_frames < target_length:\n",
    "        padding = torch.zeros((target_length - num_frames, 3, 224, 224), dtype=torch.float32, device=device)\n",
    "        return torch.cat((frames, padding), dim=0)\n",
    "    else:\n",
    "        return frames[:target_length]  # Trim if too long\n",
    "\n",
    "# Process all videos (Original + Augmented)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for folder in [original_folder, augmented_folder]:\n",
    "    for video_file in os.listdir(folder):\n",
    "        if not video_file.endswith(\".mp4\"):\n",
    "            continue\n",
    "\n",
    "        video_path = os.path.join(folder, video_file)\n",
    "\n",
    "        try:\n",
    "            # Extract frames and load to GPU\n",
    "            frames = extract_frames(video_path, device=device)\n",
    "\n",
    "            # Pad/Trim to `max_frames`\n",
    "            padded_frames = pad_frames(frames, max_frames, device=device)\n",
    "\n",
    "            # Save as `.npy` file (convert back to CPU)\n",
    "            npy_path = os.path.join(processed_folder, video_file.replace(\".mp4\", \".npy\"))\n",
    "            np.save(npy_path, padded_frames.cpu().numpy())\n",
    "\n",
    "            print(f\"✅ {video_file} processed and saved as {npy_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {video_file}: {e}\")\n",
    "\n",
    "print(\"🚀 GPU-based normalization completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
