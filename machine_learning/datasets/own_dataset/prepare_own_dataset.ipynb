{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unavailable videos and change names (uncommented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "json_file = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/WLASL_v0.3.json\"\n",
    "\n",
    "with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "video_labels = {}\n",
    "for entry in data:\n",
    "    gloss = entry[\"gloss\"]\n",
    "    for instance in entry[\"instances\"]:\n",
    "        video_id = str(instance[\"video_id\"])  \n",
    "        if video_id not in video_labels:\n",
    "            video_labels[video_id] = []\n",
    "        video_labels[video_id].append(gloss)\n",
    "\n",
    "video_folder = Path(video_folder)\n",
    "\n",
    "if not video_folder.exists():\n",
    "    raise FileNotFoundError(f\"Der Ordner {video_folder} wurde nicht gefunden.\")\n",
    "\n",
    "video_files = list(video_folder.glob(\"*\"))\n",
    "\n",
    "\n",
    "deleted_videos = []\n",
    "renamed_videos = []\n",
    "\n",
    "def is_video_valid(video_path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return False  \n",
    "    ret, _ = cap.read()\n",
    "    cap.release()\n",
    "    return ret \n",
    "\n",
    "for video_file in video_files:\n",
    "    if not video_file.is_file():\n",
    "        continue\n",
    "\n",
    "    video_id = video_file.stem \n",
    "\n",
    "    if os.path.getsize(video_file) == 0 or not is_video_valid(video_file):\n",
    "        deleted_videos.append(video_file.name)\n",
    "        os.remove(video_file)\n",
    "        continue\n",
    "\n",
    "    # labels = video_labels.get(video_id, [])\n",
    "    # if labels:\n",
    "    #     new_name = f\"{video_id}_{'_'.join(labels)}{video_file.suffix}\"\n",
    "    #     new_path = video_file.parent / new_name\n",
    "    #     os.rename(video_file, new_path)\n",
    "    #     renamed_videos.append((video_file.name, new_name))\n",
    "\n",
    "print(\"Gelöschte Videos:\", deleted_videos)\n",
    "print(\"Umbenannte Videos:\", renamed_videos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add frame count to video names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "\n",
    "if not os.path.exists(video_folder):\n",
    "    raise FileNotFoundError(f\"Der Ordner {video_folder} wurde nicht gefunden.\")\n",
    "\n",
    "video_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f))]\n",
    "\n",
    "def get_frame_count(video_path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return None \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return frame_count\n",
    "\n",
    "renamed_videos = []\n",
    "\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    video_id, ext = os.path.splitext(video_file) \n",
    "    \n",
    "    frame_count = get_frame_count(video_path)\n",
    "    \n",
    "    if frame_count is not None:\n",
    "        new_name = f\"{video_id}_{frame_count}{ext}\"\n",
    "        new_path = os.path.join(video_folder, new_name)\n",
    "        os.rename(video_path, new_path)\n",
    "        renamed_videos.append((video_file, new_name))\n",
    "\n",
    "print(\"Umbenannte Videos mit Frames:\", renamed_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informations about videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "\n",
    "if not os.path.exists(video_folder):\n",
    "    raise FileNotFoundError(f\"Der Ordner {video_folder} wurde nicht gefunden.\")\n",
    "\n",
    "video_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f))]\n",
    "\n",
    "label_counter = Counter()\n",
    "\n",
    "for video_file in video_files:\n",
    "    filename, _ = os.path.splitext(video_file) \n",
    "    parts = filename.split(\"_\") \n",
    "\n",
    "    if len(parts) == 3:  \n",
    "        label = parts[1]  \n",
    "        label_counter[label] += 1\n",
    "\n",
    "print(f\"Anzahl der verschiedenen Labels: {len(label_counter)}\")\n",
    "print(\"Top 10 häufigste Labels:\")\n",
    "for label, count in label_counter.most_common(10):\n",
    "    print(f\"{label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groups per videos per label\n",
    "from collections import Counter\n",
    "\n",
    "label_distribution = Counter(label_counter.values())\n",
    "\n",
    "print(\"Anzahl der Labels mit bestimmter Anzahl von Videos:\")\n",
    "for num_videos, num_labels in sorted(label_distribution.items()):\n",
    "    print(f\"{num_labels} Labels haben {num_videos} Videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete videos with less than min_videos_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Directory containing videos\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "\n",
    "# Retrieve list of all videos\n",
    "video_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f))]\n",
    "\n",
    "# Extract and count labels\n",
    "label_counter = Counter()\n",
    "\n",
    "for video_file in video_files:\n",
    "    filename, _ = os.path.splitext(video_file)  # Remove file extension\n",
    "    parts = filename.split(\"_\")  # Split by \"_\"\n",
    "    \n",
    "    if len(parts) >= 3:  # Ensure correct format\n",
    "        label = parts[1]  # Middle element is the label\n",
    "        label_counter[label] += 1\n",
    "\n",
    "# Minimum number of videos per label\n",
    "min_videos_per_label = 8\n",
    "\n",
    "# Delete files with too few videos\n",
    "deleted_count = 0\n",
    "\n",
    "for video_file in video_files:\n",
    "    filename, _ = os.path.splitext(video_file)\n",
    "    parts = filename.split(\"_\")\n",
    "\n",
    "    if len(parts) >= 3:\n",
    "        label = parts[1]\n",
    "        if label_counter[label] < min_videos_per_label:\n",
    "            os.remove(os.path.join(video_folder, video_file))\n",
    "            deleted_count += 1\n",
    "\n",
    "print(f\"{deleted_count} videos were deleted because their label had fewer than {min_videos_per_label} videos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> start here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count videos per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Define the source directories\n",
    "VIDEO_DIR = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/full_dataset\"\n",
    "AUGMENTED_DIR = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/augmented_dataset\"\n",
    "\n",
    "def get_video_stats(directories):\n",
    "    \"\"\"Retrieve the number of videos per label and the maximum number of frames across multiple directories.\"\"\"\n",
    "    video_counts = defaultdict(int)\n",
    "    max_frames = 0\n",
    "    \n",
    "    for directory in directories:\n",
    "        for file in glob.glob(os.path.join(directory, \"*.mp4\")):\n",
    "            filename = os.path.basename(file)\n",
    "            parts = filename.rsplit(\"_\", 3)  # Split by underscores, accounting for augmentations\n",
    "            \n",
    "            if len(parts) >= 3:\n",
    "                video_id, label, frames_ext = parts[:3]  # Extract ID, label, and frames\n",
    "                frames = int(frames_ext.split(\".\")[0])  # Convert frames to integer\n",
    "                video_counts[label] += 1\n",
    "                max_frames = max(max_frames, frames)\n",
    "    \n",
    "    return video_counts, max_frames\n",
    "\n",
    "# Get video statistics from both original and augmented datasets\n",
    "video_counts, max_frames = get_video_stats([VIDEO_DIR, AUGMENTED_DIR])\n",
    "\n",
    "# Print label and video count\n",
    "for label, count in sorted(video_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "print(f\"Maximum number of frames in any video: {max_frames}\")\n",
    "\n",
    "print(f\"Maximum number of frames in any video: {max_frames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Directories\n",
    "VIDEO_DIRS = [\n",
    "    \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/full_dataset\",\n",
    "    \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/augmented_dataset\"\n",
    "]\n",
    "PROCESSED_DIR = \"/home/haggenmueller/asl_detection/machine_learning/datasets/processed_npy\"\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Determine the maximum number of frames if not defined\n",
    "MAX_FRAMES = 102  # Fixed length for all videos\n",
    "FRAME_SIZE = (128, 128)  # Resize frames to this size\n",
    "\n",
    "# Function to extract frames as Torch tensors\n",
    "def extract_frames(video_path, device=\"cuda\"):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"⚠️ Warning: Could not open video: {video_path}\")\n",
    "        return torch.zeros((1, 3, *FRAME_SIZE), dtype=torch.float32, device=device)  # Dummy frame\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, FRAME_SIZE)  # Resize frames\n",
    "        frame = torch.tensor(frame, dtype=torch.float32, device=device).permute(2, 0, 1)  # [H, W, C] → [C, H, W]\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if not frames:\n",
    "        print(f\"⚠️ Warning: No frames extracted for {video_path}\")\n",
    "        return torch.zeros((1, 3, *FRAME_SIZE), dtype=torch.float32, device=device)  # If empty, return dummy frame\n",
    "\n",
    "    return torch.stack(frames, dim=0)\n",
    "\n",
    "# Function for padding with GPU support\n",
    "def pad_frames(frames, target_length, device=\"cuda\"):\n",
    "    num_frames = frames.shape[0]\n",
    "    if num_frames < target_length:\n",
    "        padding = torch.zeros((target_length - num_frames, 3, *FRAME_SIZE), dtype=torch.float32, device=device)\n",
    "        return torch.cat((frames, padding), dim=0)\n",
    "    else:\n",
    "        return frames[:target_length]  # Trim if too long\n",
    "\n",
    "# Process all videos (Original + Augmented)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for video_dir in VIDEO_DIRS:\n",
    "    for video_file in os.listdir(video_dir):\n",
    "        if not video_file.endswith(\".mp4\"):\n",
    "            continue\n",
    "\n",
    "        video_path = os.path.join(video_dir, video_file)\n",
    "\n",
    "        try:\n",
    "            # Extract frames and load to GPU\n",
    "            frames = extract_frames(video_path, device=device)\n",
    "\n",
    "            # Pad/Trim to `MAX_FRAMES`\n",
    "            padded_frames = pad_frames(frames, MAX_FRAMES, device=device)\n",
    "\n",
    "            # Save as `.npy` file (convert back to CPU)\n",
    "            npy_path = os.path.join(PROCESSED_DIR, video_file.replace(\".mp4\", \".npy\"))\n",
    "            np.save(npy_path, padded_frames.cpu().numpy())\n",
    "\n",
    "            print(f\"✅ {video_file} processed and saved as {npy_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {video_file}: {e}\")\n",
    "\n",
    "print(\"🚀 GPU-based normalization completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
