{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unavailable videos and change names (uncommented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "json_file = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/WLASL_v0.3.json\"\n",
    "\n",
    "with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "video_labels = {}\n",
    "for entry in data:\n",
    "    gloss = entry[\"gloss\"]\n",
    "    for instance in entry[\"instances\"]:\n",
    "        video_id = str(instance[\"video_id\"])  \n",
    "        if video_id not in video_labels:\n",
    "            video_labels[video_id] = []\n",
    "        video_labels[video_id].append(gloss)\n",
    "\n",
    "video_folder = Path(video_folder)\n",
    "\n",
    "if not video_folder.exists():\n",
    "    raise FileNotFoundError(f\"Der Ordner {video_folder} wurde nicht gefunden.\")\n",
    "\n",
    "video_files = list(video_folder.glob(\"*\"))\n",
    "\n",
    "\n",
    "deleted_videos = []\n",
    "renamed_videos = []\n",
    "\n",
    "def is_video_valid(video_path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return False  \n",
    "    ret, _ = cap.read()\n",
    "    cap.release()\n",
    "    return ret \n",
    "\n",
    "for video_file in video_files:\n",
    "    if not video_file.is_file():\n",
    "        continue\n",
    "\n",
    "    video_id = video_file.stem \n",
    "\n",
    "    if os.path.getsize(video_file) == 0 or not is_video_valid(video_file):\n",
    "        deleted_videos.append(video_file.name)\n",
    "        os.remove(video_file)\n",
    "        continue\n",
    "\n",
    "    # labels = video_labels.get(video_id, [])\n",
    "    # if labels:\n",
    "    #     new_name = f\"{video_id}_{'_'.join(labels)}{video_file.suffix}\"\n",
    "    #     new_path = video_file.parent / new_name\n",
    "    #     os.rename(video_file, new_path)\n",
    "    #     renamed_videos.append((video_file.name, new_name))\n",
    "\n",
    "print(\"Gel√∂schte Videos:\", deleted_videos)\n",
    "print(\"Umbenannte Videos:\", renamed_videos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add frame count to video names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "\n",
    "if not os.path.exists(video_folder):\n",
    "    raise FileNotFoundError(f\"Der Ordner {video_folder} wurde nicht gefunden.\")\n",
    "\n",
    "video_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f))]\n",
    "\n",
    "def get_frame_count(video_path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return None \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return frame_count\n",
    "\n",
    "renamed_videos = []\n",
    "\n",
    "for video_file in video_files:\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "    video_id, ext = os.path.splitext(video_file) \n",
    "    \n",
    "    frame_count = get_frame_count(video_path)\n",
    "    \n",
    "    if frame_count is not None:\n",
    "        new_name = f\"{video_id}_{frame_count}{ext}\"\n",
    "        new_path = os.path.join(video_folder, new_name)\n",
    "        os.rename(video_path, new_path)\n",
    "        renamed_videos.append((video_file, new_name))\n",
    "\n",
    "print(\"Umbenannte Videos mit Frames:\", renamed_videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informations about videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "\n",
    "if not os.path.exists(video_folder):\n",
    "    raise FileNotFoundError(f\"Der Ordner {video_folder} wurde nicht gefunden.\")\n",
    "\n",
    "video_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f))]\n",
    "\n",
    "label_counter = Counter()\n",
    "\n",
    "for video_file in video_files:\n",
    "    filename, _ = os.path.splitext(video_file) \n",
    "    parts = filename.split(\"_\") \n",
    "\n",
    "    if len(parts) == 3:  \n",
    "        label = parts[1]  \n",
    "        label_counter[label] += 1\n",
    "\n",
    "print(f\"Anzahl der verschiedenen Labels: {len(label_counter)}\")\n",
    "print(\"Top 10 h√§ufigste Labels:\")\n",
    "for label, count in label_counter.most_common(10):\n",
    "    print(f\"{label}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gruppen nach Anzahl der Videos pro Label\n",
    "from collections import Counter\n",
    "\n",
    "label_distribution = Counter(label_counter.values())\n",
    "\n",
    "print(\"Anzahl der Labels mit bestimmter Anzahl von Videos:\")\n",
    "for num_videos, num_labels in sorted(label_distribution.items()):\n",
    "    print(f\"{num_labels} Labels haben {num_videos} Videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete videos with less than min_videos_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Verzeichnis mit den Videos\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "\n",
    "# Liste aller Videos abrufen\n",
    "video_files = [f for f in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder, f))]\n",
    "\n",
    "# Labels extrahieren und z√§hlen\n",
    "label_counter = Counter()\n",
    "\n",
    "for video_file in video_files:\n",
    "    filename, _ = os.path.splitext(video_file)  # Entfernt Dateiendung\n",
    "    parts = filename.split(\"_\")  # Trennt nach \"_\"\n",
    "    \n",
    "    if len(parts) >= 3:  # Sicherstellen, dass das Format korrekt ist\n",
    "        label = parts[1]  # Mittleres Element ist das Label\n",
    "        label_counter[label] += 1\n",
    "\n",
    "# Mindestanzahl an Videos pro Label\n",
    "min_videos_per_label = 8\n",
    "\n",
    "# Dateien mit zu wenigen Videos l√∂schen\n",
    "deleted_count = 0\n",
    "\n",
    "for video_file in video_files:\n",
    "    filename, _ = os.path.splitext(video_file)\n",
    "    parts = filename.split(\"_\")\n",
    "\n",
    "    if len(parts) >= 3:\n",
    "        label = parts[1]\n",
    "        if label_counter[label] < min_videos_per_label:\n",
    "            os.remove(os.path.join(video_folder, video_file))\n",
    "            deleted_count += 1\n",
    "\n",
    "print(f\"{deleted_count} Videos wurden gel√∂scht, da ihr Label weniger als {min_videos_per_label} Videos hatte.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---> start here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Frames again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "# Verzeichnis mit den Videos\n",
    "video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_augmented\"\n",
    "\n",
    "if not os.path.exists(video_folder):\n",
    "    raise FileNotFoundError(f\"‚ùå Der Ordner {video_folder} wurde nicht gefunden.\")\n",
    "\n",
    "# Funktion zur Bestimmung der aktuellen Frame-Anzahl\n",
    "def get_frame_count(video_path):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        return None \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return frame_count\n",
    "\n",
    "# Regex, um die Frame-Anzahl im Dateinamen zu finden (z.B. `00624_accident_109_bright.mp4`)\n",
    "frame_pattern = re.compile(r\"_(\\d+)(?:_[a-zA-Z]+)?\\.mp4$\")\n",
    "\n",
    "renamed_videos = []\n",
    "\n",
    "for video_file in os.listdir(video_folder):\n",
    "    if not video_file.endswith(\".mp4\"):\n",
    "        continue\n",
    "\n",
    "    video_path = os.path.join(video_folder, video_file)\n",
    "\n",
    "    # Extrahiere die tats√§chliche Frame-Anzahl\n",
    "    frame_count = get_frame_count(video_path)\n",
    "    if frame_count is None:\n",
    "        print(f\"‚ö†Ô∏è Warnung: Konnte Frames f√ºr {video_file} nicht bestimmen. √úberspringe...\")\n",
    "        continue\n",
    "\n",
    "    # Pr√ºfe, ob bereits eine Frame-Anzahl im Namen existiert\n",
    "    match = frame_pattern.search(video_file)\n",
    "    \n",
    "    if match:\n",
    "        existing_frame_count = int(match.group(1))\n",
    "        \n",
    "        # Falls die Frame-Anzahl nicht √ºbereinstimmt, umbenennen\n",
    "        if existing_frame_count != frame_count:\n",
    "            new_name = re.sub(frame_pattern, f\"_{frame_count}.mp4\", video_file)\n",
    "            new_path = os.path.join(video_folder, new_name)\n",
    "            os.rename(video_path, new_path)\n",
    "            renamed_videos.append((video_file, new_name))\n",
    "            print(f\"üîÑ {video_file} ‚Üí {new_name} (Frames aktualisiert)\")\n",
    "    else:\n",
    "        # Falls keine Frame-Anzahl vorhanden ist, hinzuf√ºgen\n",
    "        name_parts = video_file.rsplit(\".\", 1)\n",
    "        new_name = f\"{name_parts[0]}_{frame_count}.mp4\"\n",
    "        new_path = os.path.join(video_folder, new_name)\n",
    "        os.rename(video_path, new_path)\n",
    "        renamed_videos.append((video_file, new_name))\n",
    "        print(f\"‚ûï {video_file} ‚Üí {new_name} (Frames hinzugef√ºgt)\")\n",
    "\n",
    "print(\"\\n‚úÖ Alle Frame-Anzahlen wurden √ºberpr√ºft und ggf. aktualisiert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print videos with less than 40 min_videos_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Verzeichnisse mit den Videos\n",
    "raw_video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "augmented_video_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_augmented\"\n",
    "\n",
    "# Labels z√§hlen\n",
    "label_counter = Counter()\n",
    "\n",
    "for folder in [raw_video_folder, augmented_video_folder]:\n",
    "    for video_file in os.listdir(folder):\n",
    "        if not video_file.endswith(\".mp4\"):\n",
    "            continue\n",
    "\n",
    "        parts = video_file.split(\"_\")\n",
    "        if len(parts) >= 3:  # Sicherstellen, dass der Name korrekt ist\n",
    "            label = parts[1]  # Das zweite Element ist jetzt das Label\n",
    "            label_counter[label] += 1\n",
    "\n",
    "# Sortiere die Labels nach Anzahl der Videos (absteigend)\n",
    "sorted_labels = sorted(label_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Anzahl der verf√ºgbaren Labels\n",
    "print(f\"Anzahl der verbleibenden Labels: {len(sorted_labels)}\")\n",
    "\n",
    "# Top 10 h√§ufigste Labels ausgeben\n",
    "print(\"\\nTop 10 h√§ufigste Labels:\")\n",
    "for label, count in sorted_labels[:10]:\n",
    "    print(f\"{label}: {count}\")\n",
    "\n",
    "# Alle Labels mit Anzahl der Videos ausgeben\n",
    "print(\"\\nAnzahl der Videos pro Label:\")\n",
    "for label, count in sorted_labels:\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate maximum number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Verzeichnisse mit Videos\n",
    "original_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "augmented_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_augmented\"\n",
    "\n",
    "# Bestimme die maximale Anzahl an Frames √ºber beide Ordner\n",
    "max_frames = 0\n",
    "\n",
    "for folder in [original_folder, augmented_folder]:\n",
    "    for video_file in os.listdir(folder):\n",
    "        if not video_file.endswith(\".mp4\"):\n",
    "            continue\n",
    "\n",
    "        parts = video_file.replace(\".mp4\", \"\").split(\"_\")\n",
    "        \n",
    "        if len(parts) >= 3:  # Sicherstellen, dass genug Teile vorhanden sind\n",
    "            try:\n",
    "                frame_count = int(parts[2])  # Die Frame-Anzahl ist an Position 2\n",
    "                max_frames = max(max_frames, frame_count)\n",
    "            except ValueError:\n",
    "                print(f\"‚ö†Ô∏è Warnung: Konnte Frame-Anzahl nicht extrahieren aus {video_file}\")\n",
    "\n",
    "print(f\"‚úÖ Maximale Anzahl an Frames (√ºber alle Videos): {max_frames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce number of videos per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Verzeichnisse mit Videos\n",
    "original_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "augmented_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_augmented\"\n",
    "\n",
    "# Zielanzahl an Videos pro Label\n",
    "target_videos_per_label = 36\n",
    "\n",
    "# Z√§hle die Anzahl der Videos pro Label\n",
    "label_counter = Counter()\n",
    "\n",
    "for folder in [original_folder, augmented_folder]:\n",
    "    for video_file in os.listdir(folder):\n",
    "        parts = video_file.split(\"_\")\n",
    "        if len(parts) >= 3:\n",
    "            label = parts[1]  # Das Label ist das zweite Element\n",
    "            label_counter[label] += 1\n",
    "\n",
    "# √úberpr√ºfung, ob Labels weniger als 48 Videos haben\n",
    "for label, count in label_counter.items():\n",
    "    if count < target_videos_per_label:\n",
    "        print(f\"‚ö†Ô∏è WARNUNG: Label '{label}' hat nur {count} Videos und kann nicht auf 48 erh√∂ht werden!\")\n",
    "\n",
    "# Entferne √ºbersch√ºssige augmentierte Videos zuf√§llig\n",
    "for label, count in label_counter.items():\n",
    "    if count > target_videos_per_label:\n",
    "        # Finde alle augmentierten Videos f√ºr dieses Label\n",
    "        label_videos = [f for f in os.listdir(augmented_folder) if f.split(\"_\")[1] == label]\n",
    "\n",
    "        # Falls es nicht genug augmentierte Videos gibt, warnen\n",
    "        if len(label_videos) < (count - target_videos_per_label):\n",
    "            print(f\"‚ö†Ô∏è WARNUNG: Nicht genug augmentierte Videos zum L√∂schen f√ºr Label '{label}'!\")\n",
    "\n",
    "        # W√§hle zuf√§llig die zu l√∂schenden Videos (nur augmentierte)\n",
    "        remove_videos = random.sample(label_videos, count - target_videos_per_label)\n",
    "\n",
    "        # L√∂sche die Videos\n",
    "        for video_file in remove_videos:\n",
    "            os.remove(os.path.join(augmented_folder, video_file))\n",
    "            print(f\"üóëÔ∏è Gel√∂scht: {video_file}\")\n",
    "\n",
    "print(\"‚úÖ Alle Labels haben jetzt genau 36 Videos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Verzeichnisse\n",
    "original_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/wlasl/raw_videos\"\n",
    "augmented_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_augmented\"\n",
    "processed_folder = \"/home/haggenmueller/asl_detection/machine_learning/datasets/own_dataset/videos_processed\"\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "# Bestimme die maximale Anzahl an Frames falls nicht definiert\n",
    "if \"max_frames\" not in locals():\n",
    "    max_frames = 195  # Standardwert, falls nicht zuvor berechnet\n",
    "\n",
    "# Funktion zur Extraktion von Frames als Torch-Tensoren\n",
    "def extract_frames(video_path, device=\"cuda\"):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ö†Ô∏è Warnung: Konnte Video nicht √∂ffnen: {video_path}\")\n",
    "        return torch.zeros((1, 3, 224, 224), dtype=torch.float32, device=device)  # Dummy-Frame\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (224, 224))  # Frames auf gleiche Gr√∂√üe bringen\n",
    "        frame = torch.tensor(frame, dtype=torch.float32, device=device).permute(2, 0, 1)  # [H, W, C] ‚Üí [C, H, W]\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if not frames:\n",
    "        print(f\"‚ö†Ô∏è Warnung: Keine Frames extrahiert f√ºr {video_path}\")\n",
    "        return torch.zeros((1, 3, 224, 224), dtype=torch.float32, device=device)  # Falls leer, Dummy-Frame\n",
    "\n",
    "    return torch.stack(frames, dim=0)\n",
    "\n",
    "# Funktion zum Padding mit GPU-Unterst√ºtzung\n",
    "def pad_frames(frames, target_length, device=\"cuda\"):\n",
    "    num_frames = frames.shape[0]\n",
    "\n",
    "    if num_frames < target_length:\n",
    "        padding = torch.zeros((target_length - num_frames, 3, 224, 224), dtype=torch.float32, device=device)\n",
    "        return torch.cat((frames, padding), dim=0)\n",
    "    else:\n",
    "        return frames[:target_length]  # Falls zu lang, einfach abschneiden\n",
    "\n",
    "# Verarbeitung aller Videos (Original + Augmented)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for folder in [original_folder, augmented_folder]:\n",
    "    for video_file in os.listdir(folder):\n",
    "        if not video_file.endswith(\".mp4\"):\n",
    "            continue\n",
    "\n",
    "        video_path = os.path.join(folder, video_file)\n",
    "\n",
    "        try:\n",
    "            # Frames extrahieren und auf GPU laden\n",
    "            frames = extract_frames(video_path, device=device)\n",
    "\n",
    "            # Padding / K√ºrzen auf `max_frames`\n",
    "            padded_frames = pad_frames(frames, max_frames, device=device)\n",
    "\n",
    "            # Speichern als `.npy`-Datei (wieder auf CPU konvertieren)\n",
    "            npy_path = os.path.join(processed_folder, video_file.replace(\".mp4\", \".npy\"))\n",
    "            np.save(npy_path, padded_frames.cpu().numpy())\n",
    "\n",
    "            print(f\"‚úÖ {video_file} verarbeitet und gespeichert als {npy_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler beim Verarbeiten von {video_file}: {e}\")\n",
    "\n",
    "print(\"üöÄ GPU-basierte Normalisierung abgeschlossen!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
