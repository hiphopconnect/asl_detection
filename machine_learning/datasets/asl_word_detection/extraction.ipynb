{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe Setup\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base directories\n",
    "def create_directories():\n",
    "    \"\"\"Creates necessary directories if they don't exist.\"\"\"\n",
    "    try:\n",
    "        # Try to get the base directory using __file__ (works in scripts)\n",
    "        base_dir = os.path.dirname(\n",
    "            os.path.dirname(os.path.dirname(os.path.dirname(__file__)))\n",
    "        )\n",
    "    except NameError:\n",
    "        # Fallback for Jupyter notebooks\n",
    "        base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "    # Create directory structure\n",
    "    dataset_dir = os.path.join(base_dir, \"datasets\")\n",
    "    own_dataset_dir = os.path.join(dataset_dir, \"own_dataset\")\n",
    "    video_dir = os.path.join(own_dataset_dir, \"videos\")\n",
    "    keypoints_dir = os.path.join(own_dataset_dir, \"keypoints\")\n",
    "\n",
    "    # Create directories\n",
    "    for directory in [dataset_dir, own_dataset_dir, video_dir, keypoints_dir]:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        print(f\"Created directory: {directory}\")\n",
    "\n",
    "    return video_dir, keypoints_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    \"\"\"Detects landmarks in an image.\"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    \"\"\"Draws landmarks on the image.\"\"\"\n",
    "    if results.face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION\n",
    "        )\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS\n",
    "        )\n",
    "    if results.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS\n",
    "        )\n",
    "    if results.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    \"\"\"Extracts all keypoints (pose, face, hands)\"\"\"\n",
    "    # Pose (33 points * 3 coordinates)\n",
    "    pose = np.zeros(33 * 3)\n",
    "    if results.pose_landmarks:\n",
    "        for i, lm in enumerate(results.pose_landmarks.landmark):\n",
    "            pose[i * 3] = lm.x\n",
    "            pose[i * 3 + 1] = lm.y\n",
    "            pose[i * 3 + 2] = lm.z\n",
    "\n",
    "    # Face (468 points * 3 coordinates)\n",
    "    face = np.zeros(468 * 3)\n",
    "    if results.face_landmarks:\n",
    "        for i, lm in enumerate(results.face_landmarks.landmark):\n",
    "            face[i * 3] = lm.x\n",
    "            face[i * 3 + 1] = lm.y\n",
    "            face[i * 3 + 2] = lm.z\n",
    "\n",
    "    # Left hand (21 points * 3 coordinates)\n",
    "    lh = np.zeros(21 * 3)\n",
    "    if results.left_hand_landmarks:\n",
    "        for i, lm in enumerate(results.left_hand_landmarks.landmark):\n",
    "            lh[i * 3] = lm.x\n",
    "            lh[i * 3 + 1] = lm.y\n",
    "            lh[i * 3 + 2] = lm.z\n",
    "\n",
    "    # Right hand (21 points * 3 coordinates)\n",
    "    rh = np.zeros(21 * 3)\n",
    "    if results.right_hand_landmarks:\n",
    "        for i, lm in enumerate(results.right_hand_landmarks.landmark):\n",
    "            rh[i * 3] = lm.x\n",
    "            rh[i * 3 + 1] = lm.y\n",
    "            rh[i * 3 + 2] = lm.z\n",
    "\n",
    "    return np.concatenate([pose, face, lh, rh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_video_to_keypoints(\n",
    "#    video_path, output_path, action, flip=False, add_noise=False\n",
    "#):\n",
    "#    \"\"\"Processes a single video to keypoints.\"\"\"\n",
    "#    cap = cv2.VideoCapture(video_path)\n",
    "#    keypoints_sequence = []\n",
    "#\n",
    " #   with mp_holistic.Holistic(min_detection_confidence=0.5) as holistic:\n",
    "#        while cap.isOpened():\n",
    "#            ret, frame = cap.read()\n",
    "#            if not ret:\n",
    " #               break\n",
    "#\n",
    " #           # Flip image if requested\n",
    "  #          if flip:\n",
    "   #             frame = cv2.flip(frame, 1)\n",
    "#\n",
    " #           # Process frame\n",
    "  #          image, results = mediapipe_detection(frame, holistic)\n",
    "  #채          keypoints = extract_keypoints(results)\n",
    "#\n",
    " #           # Add noise if requested\n",
    "#            if add_noise:\n",
    "  #              noise = np.random.normal(0, 0.01, keypoints.shape)\n",
    " #               keypoints = keypoints + noise\n",
    "#\n",
    " #           keypoints_sequence.append(keypoints.tolist())\n",
    "#\n",
    " #   cap.release()\n",
    "#\n",
    " #   # Save keypoints\n",
    "  #  data = {\"gloss\": action, \"keypoints\": keypoints_sequence}\n",
    "#\n",
    " #   try:\n",
    "#        with open(output_path, \"w\") as f:\n",
    " #           json.dump(data, f)\n",
    "  #  except Exception as e:\n",
    "   #     print(f\"Error saving {output_path}: {str(e)}\")\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_to_keypoints(\n",
    "    video_path, output_path, action, flip=False, add_noise=False\n",
    "):\n",
    "    \"\"\"Processes a single video to keypoints.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    keypoints_sequence = []\n",
    "\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Flip image if requested\n",
    "            if flip:\n",
    "                frame = cv2.flip(frame, 1)\n",
    "\n",
    "            # Process frame\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            keypoints = extract_keypoints(results)\n",
    "\n",
    "            # Add noise if requested\n",
    "            if add_noise:\n",
    "                noise = np.random.normal(0, 0.01, keypoints.shape)\n",
    "                keypoints = keypoints + noise\n",
    "\n",
    "            keypoints_sequence.append(keypoints.tolist())\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()  # Ressourcen freigeben\n",
    "\n",
    "    # Save keypoints\n",
    "    data = {\"gloss\": action, \"keypoints\": keypoints_sequence}\n",
    "\n",
    "    try:\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(data, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {output_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_action_from_filename(filename):\n",
    "    \"\"\"Extracts the action name from a filename.\"\"\"\n",
    "    # Entferne Dateiendung\n",
    "    name = filename.replace(\".mp4\", \"\")\n",
    "\n",
    "    # Entferne bekannte Zus채tze\n",
    "    for suffix in [\"_dani\", \"_meiwand\"]:\n",
    "        name = name.replace(suffix.lower(), \"\").replace(suffix.upper(), \"\")\n",
    "\n",
    "    # Entferne Zahlen am Anfang und Ende\n",
    "    name = \"\".join([char for char in name if not char.isdigit()])\n",
    "\n",
    "    # Teile den Namen an Unterstrichen\n",
    "    parts = name.split(\"_\")\n",
    "\n",
    "    # Entferne leere Strings und f체hrende/nachfolgende Leerzeichen\n",
    "    parts = [part.strip() for part in parts if part.strip()]\n",
    "\n",
    "    if not parts:\n",
    "        return None\n",
    "\n",
    "    # Verbinde die 체brigen Teile wieder mit Unterstrichen\n",
    "    return \"_\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_from_videos():\n",
    "    \"\"\"Extracts keypoints from videos and saves them.\"\"\"\n",
    "    # Create directories and get paths\n",
    "    video_directory, keypoints_directory = create_directories()\n",
    "\n",
    "    # Check if video directory is empty\n",
    "    video_files = [f for f in os.listdir(video_directory) if f.endswith(\".mp4\")]\n",
    "    if not video_files:\n",
    "        print(f\"\\nNo .mp4 files found in {video_directory}\")\n",
    "        print(\n",
    "            \"Please add video files in the format: Action_name1.mp4, Action_name2.mp4, etc.\"\n",
    "        )\n",
    "        return []\n",
    "\n",
    "    # Extract unique actions\n",
    "    actions = set()\n",
    "    for file in video_files:\n",
    "        action = extract_action_from_filename(file)\n",
    "        if action:\n",
    "            actions.add(action)\n",
    "\n",
    "    actions = sorted(list(actions))\n",
    "\n",
    "    print(\"\\n=== Starting Video Processing ===\")\n",
    "    print(f\"\\nFound Actions: {actions}\")\n",
    "\n",
    "    # Process each action\n",
    "    for action in actions:\n",
    "        # Find all files containing this action name\n",
    "        action_videos = [\n",
    "            f for f in video_files if action in extract_action_from_filename(f) or \"\"\n",
    "        ]\n",
    "        print(f\"\\nAction '{action}':\")\n",
    "        print(f\"- Number of videos: {len(action_videos)}\")\n",
    "        print(f\"- Videos: {action_videos}\")\n",
    "\n",
    "        print(f\"\\nProcessing Action '{action}' ({len(action_videos)} videos)\")\n",
    "\n",
    "        for video_file in action_videos:\n",
    "            base_name = video_file.replace(\".mp4\", \"\")\n",
    "            video_path = os.path.join(video_directory, video_file)\n",
    "\n",
    "            # Process original video\n",
    "            output_path = os.path.join(keypoints_directory, f\"{base_name}.json\")\n",
    "            if not os.path.exists(output_path):\n",
    "                process_video_to_keypoints(video_path, output_path, action)\n",
    "\n",
    "            # Process flipped video\n",
    "            output_path = os.path.join(keypoints_directory, f\"{base_name}_flipped.json\")\n",
    "            if not os.path.exists(output_path):\n",
    "                process_video_to_keypoints(video_path, output_path, action, flip=True)\n",
    "\n",
    "            # Process video with noise\n",
    "            output_path = os.path.join(keypoints_directory, f\"{base_name}_noisy.json\")\n",
    "            if not os.path.exists(output_path):\n",
    "                process_video_to_keypoints(\n",
    "                    video_path, output_path, action, add_noise=True\n",
    "                )\n",
    "\n",
    "    return actions\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    actions = collect_data_from_videos()\n",
    "    if actions:\n",
    "        print(f\"\\nProcessed actions: {actions}\")\n",
    "    else:\n",
    "        print(\"\\nNo actions processed. Please add video files first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
